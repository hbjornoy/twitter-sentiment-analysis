{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff we actually need: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import helpers as HL\n",
    "import glove_module as GV\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data and making corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_pos = \"train_pos.txt\" \n",
    "training_set_neg = \"train_neg.txt\"\n",
    "training_set_pos_full = \"train_pos_full.txt\"\n",
    "training_set_neg_full = \"train_neg_full.txt\"\n",
    "test_set = \"test_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When testing\n",
    "inputfiles=[training_set_pos,training_set_neg,test_set]\n",
    "\n",
    "#when using full data set:\n",
    "#inputfiles=[training_set_pos_full,training_set_neg_full,test_set]\n",
    "\n",
    "full_corpus, file_lengths=HL.create_corpus(inputfiles)\n",
    "nr_pos_tweets = file_lengths[0]\n",
    "nr_neg_tweets = file_lengths[1]\n",
    "total_training_tweets =file_lengths [0]+file_lengths[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the global vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick one, the higher dimension, the better result and longer computational time. \n",
    "\n",
    "#global_vectors=GV.make_glove(\"gensim_global_vectors_25dim.txt\")\n",
    "#global_vectors=GV.make_glove(\"gensim_global_vectors_50dim.txt\")\n",
    "#global_vectors=GV.make_glove(\"gensim_global_vectors_100dim.txt\")\n",
    "global_vectors=GV.make_glove(\"gensim_global_vectors_200dim.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import neural_nets as NN\n",
    "neural_nets=[NN.deep_HB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 128000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "125952/128000 [============================>.] - ETA: 1s - loss: 0.5045 - acc: 0.7289Epoch 00001: val_loss improved from inf to 0.58342, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 69s 536us/step - loss: 0.5030 - acc: 0.7302 - val_loss: 0.5834 - val_acc: 0.7238\n",
      "Epoch 2/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3939 - acc: 0.8137Epoch 00002: val_loss improved from 0.58342 to 0.54408, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 7s 54us/step - loss: 0.3939 - acc: 0.8138 - val_loss: 0.5441 - val_acc: 0.7496\n",
      "Epoch 3/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8222Epoch 00003: val_loss improved from 0.54408 to 0.51265, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 7s 58us/step - loss: 0.3788 - acc: 0.8222 - val_loss: 0.5127 - val_acc: 0.7522\n",
      "Epoch 4/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3660 - acc: 0.8289Epoch 00004: val_loss improved from 0.51265 to 0.47440, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 8s 59us/step - loss: 0.3662 - acc: 0.8288 - val_loss: 0.4744 - val_acc: 0.7756\n",
      "Epoch 5/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.8356Epoch 00005: val_loss did not improve\n",
      "128000/128000 [==============================] - 10s 75us/step - loss: 0.3566 - acc: 0.8356 - val_loss: 0.5376 - val_acc: 0.7481\n",
      "Epoch 6/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3457 - acc: 0.8409Epoch 00006: val_loss did not improve\n",
      "128000/128000 [==============================] - 10s 77us/step - loss: 0.3458 - acc: 0.8407 - val_loss: 0.5012 - val_acc: 0.7597\n",
      "Epoch 7/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3388 - acc: 0.8455Epoch 00007: val_loss did not improve\n",
      "128000/128000 [==============================] - 8s 60us/step - loss: 0.3389 - acc: 0.8455 - val_loss: 0.4898 - val_acc: 0.7654\n",
      "Epoch 00007: early stopping\n",
      "32000/32000 [==============================] - 9s 279us/step\n",
      "Unseen score: 0.81215625\n",
      "Train on 128000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.5081 - acc: 0.7240Epoch 00001: val_loss improved from inf to 0.59407, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 17s 129us/step - loss: 0.5071 - acc: 0.7247 - val_loss: 0.5941 - val_acc: 0.7145\n",
      "Epoch 2/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3975 - acc: 0.8113Epoch 00002: val_loss improved from 0.59407 to 0.49177, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 10s 80us/step - loss: 0.3975 - acc: 0.8113 - val_loss: 0.4918 - val_acc: 0.7830\n",
      "Epoch 3/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3810 - acc: 0.8205Epoch 00003: val_loss did not improve\n",
      "128000/128000 [==============================] - 8s 63us/step - loss: 0.3809 - acc: 0.8206 - val_loss: 0.5365 - val_acc: 0.7327\n",
      "Epoch 4/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3683 - acc: 0.8276Epoch 00004: val_loss improved from 0.49177 to 0.46374, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 7s 57us/step - loss: 0.3685 - acc: 0.8274 - val_loss: 0.4637 - val_acc: 0.7784\n",
      "Epoch 5/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3593 - acc: 0.8332Epoch 00005: val_loss did not improve\n",
      "128000/128000 [==============================] - 8s 61us/step - loss: 0.3593 - acc: 0.8332 - val_loss: 0.5871 - val_acc: 0.7107\n",
      "Epoch 6/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3490 - acc: 0.8399Epoch 00006: val_loss did not improve\n",
      "128000/128000 [==============================] - 7s 55us/step - loss: 0.3491 - acc: 0.8398 - val_loss: 0.5131 - val_acc: 0.7407\n",
      "Epoch 7/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3410 - acc: 0.8444Epoch 00007: val_loss did not improve\n",
      "128000/128000 [==============================] - 7s 56us/step - loss: 0.3412 - acc: 0.8444 - val_loss: 0.5091 - val_acc: 0.7495\n",
      "Epoch 00007: early stopping\n",
      "32000/32000 [==============================] - 9s 283us/step\n",
      "Unseen score: 0.8191875\n",
      "Train on 128000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.5098 - acc: 0.7213Epoch 00001: val_loss improved from inf to 0.57006, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 14s 112us/step - loss: 0.5089 - acc: 0.7220 - val_loss: 0.5701 - val_acc: 0.7364\n",
      "Epoch 2/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8131Epoch 00002: val_loss improved from 0.57006 to 0.52014, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 7s 55us/step - loss: 0.3951 - acc: 0.8131 - val_loss: 0.5201 - val_acc: 0.7721\n",
      "Epoch 3/15\n",
      "125952/128000 [============================>.] - ETA: 0s - loss: 0.3785 - acc: 0.8222Epoch 00003: val_loss improved from 0.52014 to 0.50629, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 7s 56us/step - loss: 0.3783 - acc: 0.8222 - val_loss: 0.5063 - val_acc: 0.7530\n",
      "Epoch 4/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3658 - acc: 0.8295Epoch 00004: val_loss improved from 0.50629 to 0.44691, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 7s 55us/step - loss: 0.3659 - acc: 0.8295 - val_loss: 0.4469 - val_acc: 0.7895\n",
      "Epoch 5/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3567 - acc: 0.8345Epoch 00005: val_loss did not improve\n",
      "128000/128000 [==============================] - 7s 55us/step - loss: 0.3566 - acc: 0.8345 - val_loss: 0.5651 - val_acc: 0.7229\n",
      "Epoch 6/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3475 - acc: 0.8395Epoch 00006: val_loss did not improve\n",
      "128000/128000 [==============================] - 7s 57us/step - loss: 0.3476 - acc: 0.8393 - val_loss: 0.5060 - val_acc: 0.7452\n",
      "Epoch 7/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3385 - acc: 0.8448Epoch 00007: val_loss did not improve\n",
      "128000/128000 [==============================] - 8s 64us/step - loss: 0.3385 - acc: 0.8448 - val_loss: 0.5132 - val_acc: 0.7496\n",
      "Epoch 00007: early stopping\n",
      "32000/32000 [==============================] - 10s 303us/step\n",
      "Unseen score: 0.80784375\n",
      "Train on 128000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "125952/128000 [============================>.] - ETA: 0s - loss: 0.5075 - acc: 0.7253Epoch 00001: val_loss improved from inf to 0.52623, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 13s 103us/step - loss: 0.5057 - acc: 0.7267 - val_loss: 0.5262 - val_acc: 0.7497\n",
      "Epoch 2/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3943 - acc: 0.8134Epoch 00002: val_loss improved from 0.52623 to 0.52612, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 9s 70us/step - loss: 0.3943 - acc: 0.8135 - val_loss: 0.5261 - val_acc: 0.7676\n",
      "Epoch 3/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8223Epoch 00003: val_loss improved from 0.52612 to 0.51182, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 6s 50us/step - loss: 0.3781 - acc: 0.8222 - val_loss: 0.5118 - val_acc: 0.7536\n",
      "Epoch 4/15\n",
      "125952/128000 [============================>.] - ETA: 0s - loss: 0.3660 - acc: 0.8299Epoch 00004: val_loss improved from 0.51182 to 0.46449, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 7s 54us/step - loss: 0.3659 - acc: 0.8300 - val_loss: 0.4645 - val_acc: 0.7867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.8350Epoch 00005: val_loss did not improve\n",
      "128000/128000 [==============================] - 8s 60us/step - loss: 0.3564 - acc: 0.8351 - val_loss: 0.5646 - val_acc: 0.7258\n",
      "Epoch 6/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3469 - acc: 0.8405Epoch 00006: val_loss improved from 0.46449 to 0.46425, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 10s 75us/step - loss: 0.3471 - acc: 0.8403 - val_loss: 0.4643 - val_acc: 0.7784\n",
      "Epoch 7/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3385 - acc: 0.8453Epoch 00007: val_loss improved from 0.46425 to 0.44198, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 10s 80us/step - loss: 0.3386 - acc: 0.8452 - val_loss: 0.4420 - val_acc: 0.7949\n",
      "Epoch 8/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3301 - acc: 0.8499Epoch 00008: val_loss did not improve\n",
      "128000/128000 [==============================] - 7s 55us/step - loss: 0.3301 - acc: 0.8499 - val_loss: 0.4995 - val_acc: 0.7554\n",
      "Epoch 9/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3229 - acc: 0.8552Epoch 00009: val_loss did not improve\n",
      "128000/128000 [==============================] - 10s 78us/step - loss: 0.3226 - acc: 0.8554 - val_loss: 0.5426 - val_acc: 0.7482\n",
      "Epoch 10/15\n",
      "125952/128000 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.8596Epoch 00010: val_loss did not improve\n",
      "128000/128000 [==============================] - 6s 51us/step - loss: 0.3139 - acc: 0.8595 - val_loss: 0.4807 - val_acc: 0.7761\n",
      "Epoch 00010: early stopping\n",
      "32000/32000 [==============================] - 12s 376us/step\n",
      "Unseen score: 0.80134375\n",
      "Train on 128000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.5018 - acc: 0.7326Epoch 00001: val_loss improved from inf to 0.59284, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 20s 155us/step - loss: 0.5010 - acc: 0.7332 - val_loss: 0.5928 - val_acc: 0.7094\n",
      "Epoch 2/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3950 - acc: 0.8134Epoch 00002: val_loss improved from 0.59284 to 0.49903, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 8s 66us/step - loss: 0.3949 - acc: 0.8135 - val_loss: 0.4990 - val_acc: 0.7767\n",
      "Epoch 3/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3778 - acc: 0.8222Epoch 00003: val_loss improved from 0.49903 to 0.48177, saving model to best_neural_model_save.hdf5\n",
      "128000/128000 [==============================] - 10s 81us/step - loss: 0.3777 - acc: 0.8222 - val_loss: 0.4818 - val_acc: 0.7689\n",
      "Epoch 4/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3653 - acc: 0.8298Epoch 00004: val_loss did not improve\n",
      "128000/128000 [==============================] - 7s 52us/step - loss: 0.3654 - acc: 0.8298 - val_loss: 0.4908 - val_acc: 0.7646\n",
      "Epoch 5/15\n",
      "126976/128000 [============================>.] - ETA: 0s - loss: 0.3563 - acc: 0.8353Epoch 00005: val_loss did not improve\n",
      "128000/128000 [==============================] - 9s 68us/step - loss: 0.3562 - acc: 0.8353 - val_loss: 0.5124 - val_acc: 0.7434\n",
      "Epoch 6/15\n",
      "125952/128000 [============================>.] - ETA: 0s - loss: 0.3464 - acc: 0.8405Epoch 00006: val_loss did not improve\n",
      "128000/128000 [==============================] - 8s 60us/step - loss: 0.3466 - acc: 0.8403 - val_loss: 0.5027 - val_acc: 0.7540\n",
      "Epoch 00006: early stopping\n",
      "32000/32000 [==============================] - 9s 284us/step\n",
      "Unseen score: 0.81528125\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x0000025986D02198>\n",
      "[0.81215625000000002, 0.81918749999999996, 0.80784374999999997, 0.80134375000000002, 0.81528124999999996]\n",
      "0.81% (+/- 0.01%)\n",
      "Negative sentiment: 104.91%  Positive sentiment: 57.33%\n",
      "Percentage of positive classifications (should be 50%ish): 38.71125\n",
      "Time taken:  9.09064569870631 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracies_E=[]\n",
    "stds_E=[]\n",
    "\n",
    "for epochs_ in range(15,16):\n",
    "    model_score=GV.classify_with_neural_networks(neural_nets, global_vectors, full_corpus, total_training_tweets, nr_pos_tweets, epochs=epochs_, n_folds=5)\n",
    "    accuracies_E.append(model_score[0][0])\n",
    "    stds_E.append(model_score[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(accuracies_E) # Y\n",
    "print(stds_E) # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the example exercise dataset\n",
    "\n",
    "print(type(epoch_values))\n",
    "print(type(accuracies_E))\n",
    "print(type(stds_E))\n",
    "\n",
    "index = range(0,len(epoch_values))\n",
    "#s = pd.Series(data, index=index)\n",
    "df = pd.DataFrame({'epoch_values' : pd.Series(epoch_values, index=epoch_values),\n",
    "      'accuracies_E' : pd.Series(accuracies_E, index=epoch_values),\n",
    "      'stds_E' : pd.Series(stds_E, index=epoch_values)})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sb.set(style=\"whitegrid\")\n",
    "\n",
    "# Draw a pointplot to show pulse as a function of three categorical factors\n",
    "g = sb.factorplot(x=\"epoch_values\", y=\"accuracies_E\", data=df, ) # , capsize=.2, size=6, aspect=.75\n",
    "#g.despine(left=True)\n",
    "g.map(plt.errorbar, \"epoch_values\", \"accuracies_E\", \"stds_E\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
