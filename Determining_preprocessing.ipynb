{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining best combination of preprocessing techniques  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/havardbjornoy/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#MÅ GÅ NØYE IGJENNOM Å SJEKKE HVA SOM FAKTISK BRUKES\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# external imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import scipy\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras import backend as K\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "\n",
    "# internal imports\n",
    "import helpers as HL\n",
    "import cleaning as CL\n",
    "import glove_module as GV\n",
    "import neural_nets as NN\n",
    "import tokenizing as TO\n",
    "\n",
    "import maketextfile as MT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Data Paths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files used to create model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "#BRUKER VI DET HER??\n",
    "DATA_FOLDER = os.path.join(\"glove.twitter.27B\") \n",
    "DATA_25DIM = DATA_FOLDER + \"/glove.twitter.27B.25d.txt\"\n",
    "DATA_50DIM = DATA_FOLDER + \"/glove.twitter.27B.50d.txt\"\n",
    "DATA_100DIM = DATA_FOLDER + \"/glove.twitter.27B.100d.txt\"\n",
    "DATA_200DIM = DATA_FOLDER + \"/glove.twitter.27B.200d.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_pos = \"train_pos.txt\" \n",
    "training_set_neg = \"train_neg.txt\"\n",
    "training_set_pos_full = \"train_pos_full.txt\"\n",
    "training_set_neg_full = \"train_neg_full.txt\"\n",
    "test_set = \"test_data.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pretrained GloVe with gensim\n",
    "one can use gensims word2vec functions to check similarity and other interesting functions https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word embeddings using the created gensim-.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pick one, the higher dimension, the better result and longer computational time. \n",
    "\n",
    "#global_vectors=GV.make_glove(\"data/gensim_global_vectors_25dim.txt\")\n",
    "#global_vectors=GV.make_glove(\"gensim_global_vectors_50dim.txt\")\n",
    "#global_vectors=GV.make_glove(\"gensim_global_vectors_100dim.txt\")\n",
    "global_vectors=GV.make_glove(\"gensim_data_folder/gensim_glove_vectors_200dim.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When testing\n",
    "inputfiles=[training_set_pos,training_set_neg,test_set]\n",
    "\n",
    "#when using full data set:\n",
    "#inputfiles=[training_set_pos_full,training_set_neg_full,test_set]\n",
    "\n",
    "full_corpus, file_lengths=HL.create_corpus(inputfiles)\n",
    "nr_pos_tweets = file_lengths[0]\n",
    "nr_neg_tweets = file_lengths[1]\n",
    "total_training_tweets =file_lengths [0]+file_lengths[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural_nets=[NN.deep_HB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables to apply all preprocessing techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing vectors:\n",
    "\n",
    "corpuses=[]\n",
    "corpuses.append(full_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining names of corpuses: \n",
    "names=['original_corpus','SH_corpus','SHM_corpus','H_corpus','HK_corpus','PS_corpus','NS__corpus','OS_corpus','N_corpus','NM_corpus','ST_corpus','SP_corpus','E_corpus','SN_corpus','RS_corpus','N-2_corpus','N-3_corpus','N-4_corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining inputs to preprocessing function: \n",
    "inputs=[{'hashtag': True, 'segmentation_hash': True},\n",
    "        {'hashtag':True,'segmentation_hash': True,'hashtag_mention':True},\n",
    "        {'hearts':True},\n",
    "        {'hugs_and_kisses':True},\n",
    "        {'pos_smilies':True},\n",
    "        {'neg_smilies':True},\n",
    "        {'other_smilies':True},\n",
    "        {'numbers':True},\n",
    "        {'numbers':True,'number_mention':True},\n",
    "        {'stemming':True},\n",
    "        {'spelling':True},#Warning: When True, it takes forever. Recomended to always have as false \n",
    "        {'elongation':True},\n",
    "        {'set_to_not':True},\n",
    "        {'remove_signs':True}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying all preprocessing techniques to the original corpus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Time in min before starting first for loop: 0.1617306669553121\n",
      "Time in min after 1  tweets: 0.16198389530181884\n",
      "Time in min after 25001  tweets: 0.30229872862497964\n",
      "Time in min after 50001  tweets: 0.41871701876322426\n",
      "Time in min after 75001  tweets: 0.5374351302782695\n",
      "Time in min after 100001  tweets: 0.6650677680969238\n",
      "Time in min after 125001  tweets: 0.7544985810915629\n",
      "Time in min after 150001  tweets: 0.8679561018943787\n",
      "Time in min after 175001  tweets: 0.9501758495966593\n",
      "Time in min after 200001  tweets: 1.0365543007850646\n",
      "Time in min total: 1.0756685972213744\n",
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Time in min before starting first for loop: 0.16107724905014037\n",
      "Time in min after 1  tweets: 0.1611544688542684\n",
      "Time in min after 25001  tweets: 0.3606411655743917\n",
      "Time in min after 50001  tweets: 0.4720538338025411\n",
      "Time in min after 75001  tweets: 0.5838240186373392\n",
      "Time in min after 100001  tweets: 0.6974303483963012\n",
      "Time in min after 125001  tweets: 0.7891739130020141\n",
      "Time in min after 150001  tweets: 1.0021500865618387\n",
      "Time in min after 175001  tweets: 1.1089177012443543\n",
      "Time in min after 200001  tweets: 1.2002949833869934\n",
      "Time in min total: 1.2434874176979065\n",
      "Time in min before starting first for loop: 1.5497207641601563e-07\n",
      "Time in min after 1  tweets: 8.217493693033855e-06\n",
      "Time in min after 25001  tweets: 0.035367953777313235\n",
      "Time in min after 50001  tweets: 0.07393205563227336\n",
      "Time in min after 75001  tweets: 0.10837345520655314\n",
      "Time in min after 100001  tweets: 0.14301760196685792\n",
      "Time in min after 125001  tweets: 0.18073891798655192\n",
      "Time in min after 150001  tweets: 0.21972646713256835\n",
      "Time in min after 175001  tweets: 0.2562983194986979\n",
      "Time in min after 200001  tweets: 0.2943601369857788\n",
      "Time in min total: 0.30939448277155557\n",
      "Time in min before starting first for loop: 7.947285970052083e-08\n",
      "Time in min after 1  tweets: 0.0001556118329366048\n",
      "Time in min after 25001  tweets: 0.032649930318196616\n",
      "Time in min after 50001  tweets: 0.06352041165033977\n",
      "Time in min after 75001  tweets: 0.09573008219401041\n",
      "Time in min after 100001  tweets: 0.13134389718373615\n",
      "Time in min after 125001  tweets: 0.1868117133776347\n",
      "Time in min after 150001  tweets: 0.2310044487317403\n",
      "Time in min after 175001  tweets: 0.27306119600931805\n",
      "Time in min after 200001  tweets: 0.31056319872538246\n",
      "Time in min total: 0.32752453088760375\n",
      "Time in min before starting first for loop: 1.1523564656575521e-07\n",
      "Time in min after 1  tweets: 5.686283111572266e-06\n",
      "Time in min after 25001  tweets: 0.03394173383712769\n",
      "Time in min after 50001  tweets: 0.0709676186243693\n",
      "Time in min after 75001  tweets: 0.10476216475168863\n",
      "Time in min after 100001  tweets: 0.13854165077209474\n",
      "Time in min after 125001  tweets: 0.18275706768035888\n",
      "Time in min after 150001  tweets: 0.22348419825236002\n",
      "Time in min after 175001  tweets: 0.26403605143229164\n",
      "Time in min after 200001  tweets: 0.3034960826237996\n",
      "Time in min total: 0.3200525164604187\n",
      "Time in min before starting first for loop: 8.344650268554687e-08\n",
      "Time in min after 1  tweets: 8.865197499593098e-06\n",
      "Time in min after 25001  tweets: 0.031936617692311604\n",
      "Time in min after 50001  tweets: 0.06256709893544515\n",
      "Time in min after 75001  tweets: 0.09372862974802652\n",
      "Time in min after 100001  tweets: 0.12474571466445923\n",
      "Time in min after 125001  tweets: 0.16302708387374878\n",
      "Time in min after 150001  tweets: 0.20247830152511598\n",
      "Time in min after 175001  tweets: 0.24152604738871256\n",
      "Time in min after 200001  tweets: 0.280294668674469\n",
      "Time in min total: 0.30167283217112223\n",
      "Time in min before starting first for loop: 8.344650268554687e-08\n",
      "Time in min after 1  tweets: 1.1118253072102864e-05\n",
      "Time in min after 25001  tweets: 0.03640686670939128\n",
      "Time in min after 50001  tweets: 0.06851253112157187\n",
      "Time in min after 75001  tweets: 0.10051390329996744\n",
      "Time in min after 100001  tweets: 0.13277913331985475\n",
      "Time in min after 125001  tweets: 0.17195666631062825\n",
      "Time in min after 150001  tweets: 0.21721141735712687\n",
      "Time in min after 175001  tweets: 0.259191099802653\n",
      "Time in min after 200001  tweets: 0.29782104889551797\n",
      "Time in min total: 0.3135853846867879\n",
      "Time in min before starting first for loop: 6.357828776041667e-08\n",
      "Time in min after 1  tweets: 8.73406728108724e-06\n",
      "Time in min after 25001  tweets: 0.03421571254730225\n",
      "Time in min after 50001  tweets: 0.06659549872080485\n",
      "Time in min after 75001  tweets: 0.09774918556213379\n",
      "Time in min after 100001  tweets: 0.12870246569315594\n",
      "Time in min after 125001  tweets: 0.16587023337682089\n",
      "Time in min after 150001  tweets: 0.20368079741795858\n",
      "Time in min after 175001  tweets: 0.24949931303660075\n",
      "Time in min after 200001  tweets: 0.286208963394165\n",
      "Time in min total: 0.30084433158238727\n",
      "Time in min before starting first for loop: 8.344650268554687e-08\n",
      "Time in min after 1  tweets: 7.64926274617513e-06\n",
      "Time in min after 25001  tweets: 0.030639219284057616\n",
      "Time in min after 50001  tweets: 0.0643109679222107\n",
      "Time in min after 75001  tweets: 0.09430546760559082\n",
      "Time in min after 100001  tweets: 0.12482784986495972\n",
      "Time in min after 125001  tweets: 0.16266976992289225\n",
      "Time in min after 150001  tweets: 0.19913966258366902\n",
      "Time in min after 175001  tweets: 0.23711700042088826\n",
      "Time in min after 200001  tweets: 0.27407741943995156\n",
      "Time in min total: 0.28865944941838584\n",
      "Time in min before starting first for loop: 0.00013506412506103516\n",
      "Time in min after 1  tweets: 0.00020045042037963867\n",
      "Time in min after 25001  tweets: 0.14907041788101197\n",
      "Time in min after 50001  tweets: 0.2951819976170858\n",
      "Time in min after 75001  tweets: 0.44259876807530724\n",
      "Time in min after 100001  tweets: 0.5884080012639363\n",
      "Time in min after 125001  tweets: 0.7696406165758769\n",
      "Time in min after 150001  tweets: 0.9466047366460164\n",
      "Time in min after 175001  tweets: 1.1220719337463378\n",
      "Time in min after 200001  tweets: 1.2965904672940571\n",
      "Time in min total: 1.3660954038302104\n",
      "Reading english - 1grams ...\n",
      "generating binary file for faster loading...\n",
      "reading ngrams /Users/havardbjornoy/anaconda3/lib/python3.6/site-packages/ekphrasis/stats/english/counts_1grams.txt\n",
      "Time in min before starting first for loop: 0.03280615011850993\n",
      "Time in min after 1  tweets: 0.03528776566187541\n",
      "Time in min after 25001  tweets: 18.514053801695507\n",
      "Time in min after 50001  tweets: 36.908837985992434\n",
      "Time in min after 75001  tweets: 54.15736381610235\n",
      "Time in min after 100001  tweets: 70.9865527510643\n",
      "Time in min after 125001  tweets: 90.33664288520814\n",
      "Time in min after 150001  tweets: 108.85263093312581\n",
      "Time in min after 175001  tweets: 126.096178150177\n",
      "Time in min after 200001  tweets: 142.95241071780524\n",
      "Time in min total: 149.44627511898676\n",
      "Time in min before starting first for loop: 0.0008353670438130697\n",
      "Time in min after 1  tweets: 0.0008685151735941569\n",
      "Time in min after 25001  tweets: 0.11829150120417277\n",
      "Time in min after 50001  tweets: 0.2370463490486145\n",
      "Time in min after 75001  tweets: 0.35731256802876793\n",
      "Time in min after 100001  tweets: 0.4764329195022583\n",
      "Time in min after 125001  tweets: 0.6170652667681377\n",
      "Time in min after 150001  tweets: 0.7557015975316366\n",
      "Time in min after 175001  tweets: 0.8942784349123637\n",
      "Time in min after 200001  tweets: 1.0327417492866515\n",
      "Time in min total: 1.087442151705424\n",
      "Time in min before starting first for loop: 8.344650268554687e-08\n",
      "Time in min after 1  tweets: 8.002916971842449e-06\n",
      "Time in min after 25001  tweets: 0.0315367857615153\n",
      "Time in min after 50001  tweets: 0.06298558314641317\n",
      "Time in min after 75001  tweets: 0.09343980153401693\n",
      "Time in min after 100001  tweets: 0.12381616830825806\n",
      "Time in min after 125001  tweets: 0.16170655488967894\n",
      "Time in min after 150001  tweets: 0.19905920028686525\n",
      "Time in min after 175001  tweets: 0.2363289515177409\n",
      "Time in min after 200001  tweets: 0.2728566845258077\n",
      "Time in min total: 0.28808953364690143\n",
      "Time in min before starting first for loop: 6.75519307454427e-08\n",
      "Time in min after 1  tweets: 5.535284678141276e-06\n",
      "Time in min after 25001  tweets: 0.03145263195037842\n",
      "Time in min after 50001  tweets: 0.062444651126861574\n",
      "Time in min after 75001  tweets: 0.09406118392944336\n",
      "Time in min after 100001  tweets: 0.12566758394241334\n",
      "Time in min after 125001  tweets: 0.1639017343521118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in min after 150001  tweets: 0.20171878337860108\n",
      "Time in min after 175001  tweets: 0.2400106986363729\n",
      "Time in min after 200001  tweets: 0.2774257024129232\n",
      "Time in min total: 0.2929166316986084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for input_ in inputs: \n",
    "        corpus=TO.preprocess_corpus(full_corpus, **input_)\n",
    "        corpuses.append(corpus)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns=[2,3,4]\n",
    "for n in ns: \n",
    "    corpus=HL.creating_n_grams_corpus(n,full_corpus)\n",
    "    corpuses.append(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 1: Testing all preprocessing techniques: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 7s 51us/step - loss: 0.4925 - acc: 0.7579 - val_loss: 0.4089 - val_acc: 0.8067\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3977 - acc: 0.8128 - val_loss: 0.3935 - val_acc: 0.8165\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3836 - acc: 0.8212 - val_loss: 0.3892 - val_acc: 0.8183\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3729 - acc: 0.8268 - val_loss: 0.3860 - val_acc: 0.8200\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3632 - acc: 0.8325 - val_loss: 0.3806 - val_acc: 0.8232\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 30us/step - loss: 0.3558 - acc: 0.8364 - val_loss: 0.3841 - val_acc: 0.8221\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 30us/step - loss: 0.3487 - acc: 0.8413 - val_loss: 0.3813 - val_acc: 0.8232\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 30us/step - loss: 0.3413 - acc: 0.8447 - val_loss: 0.3836 - val_acc: 0.8224\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 2s 37us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 5s 39us/step - loss: 0.4915 - acc: 0.7637 - val_loss: 0.4067 - val_acc: 0.8090\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3966 - acc: 0.8139 - val_loss: 0.3927 - val_acc: 0.8155\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3830 - acc: 0.8209 - val_loss: 0.3896 - val_acc: 0.8178\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3707 - acc: 0.8280 - val_loss: 0.3868 - val_acc: 0.8186\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3617 - acc: 0.8334 - val_loss: 0.3809 - val_acc: 0.8207\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3525 - acc: 0.8384 - val_loss: 0.3829 - val_acc: 0.8211\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3458 - acc: 0.8418 - val_loss: 0.3855 - val_acc: 0.8207\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3370 - acc: 0.8460 - val_loss: 0.3867 - val_acc: 0.8209\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 3s 38us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 5s 37us/step - loss: 0.4916 - acc: 0.7641 - val_loss: 0.4101 - val_acc: 0.8060\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3946 - acc: 0.8151 - val_loss: 0.3964 - val_acc: 0.8140\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3805 - acc: 0.8225 - val_loss: 0.3891 - val_acc: 0.8165\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3701 - acc: 0.8282 - val_loss: 0.3861 - val_acc: 0.8187\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3606 - acc: 0.8335 - val_loss: 0.3826 - val_acc: 0.8202\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3525 - acc: 0.8377 - val_loss: 0.3836 - val_acc: 0.8207\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3461 - acc: 0.8418 - val_loss: 0.3814 - val_acc: 0.8225\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3364 - acc: 0.8468 - val_loss: 0.3845 - val_acc: 0.8211\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3304 - acc: 0.8500 - val_loss: 0.3863 - val_acc: 0.8216\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3228 - acc: 0.8542 - val_loss: 0.3914 - val_acc: 0.8207\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 3s 38us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x1e03b0f60>\n",
      "[0.82243355133254958, 0.8208532085302972, 0.82073320733564958]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 78.49%  Positive sentiment: 85.78%\n",
      "Percentage of positive classifications (should be 50%ish): 53.6420208505\n",
      "Time taken:  2.1915696183840434 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 6s 45us/step - loss: 0.4895 - acc: 0.7604 - val_loss: 0.4071 - val_acc: 0.8073\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3930 - acc: 0.8159 - val_loss: 0.3870 - val_acc: 0.8191\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3789 - acc: 0.8238 - val_loss: 0.3833 - val_acc: 0.8213\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3677 - acc: 0.8298 - val_loss: 0.3809 - val_acc: 0.8226\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3582 - acc: 0.8357 - val_loss: 0.3749 - val_acc: 0.8259\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3513 - acc: 0.8384 - val_loss: 0.3776 - val_acc: 0.8246\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3441 - acc: 0.8432 - val_loss: 0.3764 - val_acc: 0.8266\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3369 - acc: 0.8469 - val_loss: 0.3783 - val_acc: 0.8258\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 3s 44us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 35s 263us/step - loss: 0.4879 - acc: 0.7660 - val_loss: 0.4024 - val_acc: 0.8115\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3917 - acc: 0.8169 - val_loss: 0.3884 - val_acc: 0.8180\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3779 - acc: 0.8240 - val_loss: 0.3851 - val_acc: 0.8204\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3657 - acc: 0.8309 - val_loss: 0.3839 - val_acc: 0.8211\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3567 - acc: 0.8363 - val_loss: 0.3776 - val_acc: 0.8237\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3480 - acc: 0.8405 - val_loss: 0.3797 - val_acc: 0.8239\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3410 - acc: 0.8447 - val_loss: 0.3815 - val_acc: 0.8235\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3330 - acc: 0.8488 - val_loss: 0.3815 - val_acc: 0.8240\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 3s 42us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 44us/step - loss: 0.4883 - acc: 0.7667 - val_loss: 0.4048 - val_acc: 0.8087\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3896 - acc: 0.8179 - val_loss: 0.3917 - val_acc: 0.8160\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3754 - acc: 0.8258 - val_loss: 0.3836 - val_acc: 0.8190\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3646 - acc: 0.8321 - val_loss: 0.3818 - val_acc: 0.8202\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3554 - acc: 0.8362 - val_loss: 0.3766 - val_acc: 0.8219\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3472 - acc: 0.8403 - val_loss: 0.3776 - val_acc: 0.8235\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3413 - acc: 0.8449 - val_loss: 0.3771 - val_acc: 0.8259\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3313 - acc: 0.8493 - val_loss: 0.3805 - val_acc: 0.8244\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 3s 43us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x1e0382a58>\n",
      "[0.82583848322675923, 0.82397323973060921, 0.82436324363601265]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 79.10%  Positive sentiment: 85.84%\n",
      "Percentage of positive classifications (should be 50%ish): 53.3715144405\n",
      "Time taken:  2.5824588179588317 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 7s 53us/step - loss: 0.4883 - acc: 0.7607 - val_loss: 0.4068 - val_acc: 0.8079\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3925 - acc: 0.8164 - val_loss: 0.3863 - val_acc: 0.8196\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3785 - acc: 0.8240 - val_loss: 0.3836 - val_acc: 0.8217\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3672 - acc: 0.8305 - val_loss: 0.3798 - val_acc: 0.8237\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 5s 36us/step - loss: 0.3578 - acc: 0.8360 - val_loss: 0.3746 - val_acc: 0.8257\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3502 - acc: 0.8393 - val_loss: 0.3815 - val_acc: 0.8238\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3432 - acc: 0.8435 - val_loss: 0.3761 - val_acc: 0.8269\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3357 - acc: 0.8474 - val_loss: 0.3793 - val_acc: 0.8256\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 3s 52us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 5s 41us/step - loss: 0.4877 - acc: 0.7665 - val_loss: 0.4020 - val_acc: 0.8116\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3915 - acc: 0.8170 - val_loss: 0.3880 - val_acc: 0.8181\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3773 - acc: 0.8243 - val_loss: 0.3844 - val_acc: 0.8216\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3653 - acc: 0.8306 - val_loss: 0.3834 - val_acc: 0.8212\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3563 - acc: 0.8370 - val_loss: 0.3765 - val_acc: 0.8239\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 37us/step - loss: 0.3476 - acc: 0.8405 - val_loss: 0.3793 - val_acc: 0.8225\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3409 - acc: 0.8445 - val_loss: 0.3801 - val_acc: 0.8235\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3328 - acc: 0.8484 - val_loss: 0.3797 - val_acc: 0.8253\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 3s 44us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 47us/step - loss: 0.4893 - acc: 0.7664 - val_loss: 0.4048 - val_acc: 0.8093\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3899 - acc: 0.8169 - val_loss: 0.3918 - val_acc: 0.8158\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3760 - acc: 0.8257 - val_loss: 0.3836 - val_acc: 0.8187\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3658 - acc: 0.8312 - val_loss: 0.3807 - val_acc: 0.8213\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3562 - acc: 0.8360 - val_loss: 0.3769 - val_acc: 0.8232\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3479 - acc: 0.8400 - val_loss: 0.3781 - val_acc: 0.8237\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3421 - acc: 0.8446 - val_loss: 0.3761 - val_acc: 0.8255\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3321 - acc: 0.8489 - val_loss: 0.3810 - val_acc: 0.8250\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 30us/step - loss: 0.3260 - acc: 0.8529 - val_loss: 0.3812 - val_acc: 0.8226\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3179 - acc: 0.8577 - val_loss: 0.3872 - val_acc: 0.8240\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 3s 43us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x21856b400>\n",
      "[0.82558348833380957, 0.82526325263610267, 0.82398823988597514]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 78.95%  Positive sentiment: 86.04%\n",
      "Percentage of positive classifications (should be 50%ish): 53.5445224855\n",
      "Time taken:  2.303837335109711 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 12s 93us/step - loss: 0.4932 - acc: 0.7573 - val_loss: 0.4096 - val_acc: 0.8061\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 37us/step - loss: 0.3982 - acc: 0.8130 - val_loss: 0.3937 - val_acc: 0.8162\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 5s 36us/step - loss: 0.3842 - acc: 0.8213 - val_loss: 0.3897 - val_acc: 0.8186\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 36us/step - loss: 0.3739 - acc: 0.8268 - val_loss: 0.3857 - val_acc: 0.8201\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 5s 37us/step - loss: 0.3638 - acc: 0.8330 - val_loss: 0.3803 - val_acc: 0.8221\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3567 - acc: 0.8364 - val_loss: 0.3816 - val_acc: 0.8226\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3493 - acc: 0.8407 - val_loss: 0.3814 - val_acc: 0.8233\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3422 - acc: 0.8449 - val_loss: 0.3834 - val_acc: 0.8231\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 4s 56us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 47us/step - loss: 0.4923 - acc: 0.7631 - val_loss: 0.4074 - val_acc: 0.8083\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 37us/step - loss: 0.3972 - acc: 0.8139 - val_loss: 0.3935 - val_acc: 0.8153\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3838 - acc: 0.8207 - val_loss: 0.3899 - val_acc: 0.8167\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3717 - acc: 0.8274 - val_loss: 0.3881 - val_acc: 0.8186\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 36us/step - loss: 0.3628 - acc: 0.8325 - val_loss: 0.3825 - val_acc: 0.8198\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3539 - acc: 0.8376 - val_loss: 0.3853 - val_acc: 0.8190\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3469 - acc: 0.8415 - val_loss: 0.3856 - val_acc: 0.8202\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3390 - acc: 0.8451 - val_loss: 0.3869 - val_acc: 0.8214\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 3s 50us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133334/133334 [==============================] - 6s 46us/step - loss: 0.4920 - acc: 0.7637 - val_loss: 0.4107 - val_acc: 0.8053\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3946 - acc: 0.8154 - val_loss: 0.3967 - val_acc: 0.8141\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3803 - acc: 0.8228 - val_loss: 0.3908 - val_acc: 0.8159\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3698 - acc: 0.8286 - val_loss: 0.3857 - val_acc: 0.8180\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3605 - acc: 0.8338 - val_loss: 0.3828 - val_acc: 0.8197\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3525 - acc: 0.8385 - val_loss: 0.3823 - val_acc: 0.8213\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3463 - acc: 0.8419 - val_loss: 0.3834 - val_acc: 0.8206\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3367 - acc: 0.8467 - val_loss: 0.3856 - val_acc: 0.8213\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3309 - acc: 0.8509 - val_loss: 0.3852 - val_acc: 0.8205\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 3s 51us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x22e238f98>\n",
      "[0.82310853782566717, 0.8213782137803497, 0.82046320463025812]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 79.49%  Positive sentiment: 84.84%\n",
      "Percentage of positive classifications (should be 50%ish): 52.6710194353\n",
      "Time taken:  2.5076117316881814 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 36s 274us/step - loss: 0.4922 - acc: 0.7591 - val_loss: 0.4109 - val_acc: 0.8062\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3979 - acc: 0.8129 - val_loss: 0.3938 - val_acc: 0.8161\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3844 - acc: 0.8211 - val_loss: 0.3895 - val_acc: 0.8182\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3733 - acc: 0.8270 - val_loss: 0.3855 - val_acc: 0.8208\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3641 - acc: 0.8322 - val_loss: 0.3816 - val_acc: 0.8221\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 31us/step - loss: 0.3564 - acc: 0.8359 - val_loss: 0.3846 - val_acc: 0.8221\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3489 - acc: 0.8413 - val_loss: 0.3817 - val_acc: 0.8231\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3418 - acc: 0.8447 - val_loss: 0.3830 - val_acc: 0.8229\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 4s 53us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 5s 41us/step - loss: 0.4916 - acc: 0.7637 - val_loss: 0.4071 - val_acc: 0.8087\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3969 - acc: 0.8137 - val_loss: 0.3933 - val_acc: 0.8153\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3834 - acc: 0.8212 - val_loss: 0.3899 - val_acc: 0.8173\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3711 - acc: 0.8278 - val_loss: 0.3873 - val_acc: 0.8184\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3622 - acc: 0.8330 - val_loss: 0.3814 - val_acc: 0.8209\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3533 - acc: 0.8372 - val_loss: 0.3837 - val_acc: 0.8198\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3467 - acc: 0.8415 - val_loss: 0.3849 - val_acc: 0.8200\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3384 - acc: 0.8460 - val_loss: 0.3856 - val_acc: 0.8219\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 3s 50us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 42us/step - loss: 0.4911 - acc: 0.7645 - val_loss: 0.4112 - val_acc: 0.8062\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3943 - acc: 0.8152 - val_loss: 0.3961 - val_acc: 0.8144\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3801 - acc: 0.8231 - val_loss: 0.3902 - val_acc: 0.8160\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3696 - acc: 0.8283 - val_loss: 0.3860 - val_acc: 0.8182\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3606 - acc: 0.8331 - val_loss: 0.3829 - val_acc: 0.8197\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3526 - acc: 0.8378 - val_loss: 0.3815 - val_acc: 0.8207\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3463 - acc: 0.8414 - val_loss: 0.3831 - val_acc: 0.8221\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3365 - acc: 0.8467 - val_loss: 0.3863 - val_acc: 0.8214\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3306 - acc: 0.8503 - val_loss: 0.3865 - val_acc: 0.8206\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 4s 54us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x1c6dd5470>\n",
      "[0.8229435411256012, 0.82188821888040065, 0.82061320613384947]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 79.60%  Positive sentiment: 84.76%\n",
      "Percentage of positive classifications (should be 50%ish): 52.5815124354\n",
      "Time taken:  2.7139715989430746 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 11s 80us/step - loss: 0.4923 - acc: 0.7581 - val_loss: 0.4106 - val_acc: 0.8058\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3977 - acc: 0.8130 - val_loss: 0.3933 - val_acc: 0.8169\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3837 - acc: 0.8211 - val_loss: 0.3890 - val_acc: 0.8192\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3729 - acc: 0.8267 - val_loss: 0.3856 - val_acc: 0.8207\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3634 - acc: 0.8326 - val_loss: 0.3810 - val_acc: 0.8220\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 5s 36us/step - loss: 0.3562 - acc: 0.8363 - val_loss: 0.3822 - val_acc: 0.8225\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3489 - acc: 0.8408 - val_loss: 0.3819 - val_acc: 0.8237\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3417 - acc: 0.8446 - val_loss: 0.3828 - val_acc: 0.8232\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 4s 58us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 45us/step - loss: 0.4916 - acc: 0.7634 - val_loss: 0.4071 - val_acc: 0.8087\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 37us/step - loss: 0.3968 - acc: 0.8139 - val_loss: 0.3930 - val_acc: 0.8156\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3833 - acc: 0.8210 - val_loss: 0.3896 - val_acc: 0.8170\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3712 - acc: 0.8274 - val_loss: 0.3876 - val_acc: 0.8188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3623 - acc: 0.8334 - val_loss: 0.3816 - val_acc: 0.8207\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3532 - acc: 0.8378 - val_loss: 0.3841 - val_acc: 0.8201\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3465 - acc: 0.8408 - val_loss: 0.3851 - val_acc: 0.8211\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3383 - acc: 0.8459 - val_loss: 0.3857 - val_acc: 0.8213\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 4s 59us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 48us/step - loss: 0.4916 - acc: 0.7642 - val_loss: 0.4102 - val_acc: 0.8057\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3945 - acc: 0.8150 - val_loss: 0.3963 - val_acc: 0.8141\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3804 - acc: 0.8228 - val_loss: 0.3899 - val_acc: 0.8162\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3700 - acc: 0.8282 - val_loss: 0.3857 - val_acc: 0.8191\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3605 - acc: 0.8336 - val_loss: 0.3826 - val_acc: 0.8192\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3523 - acc: 0.8376 - val_loss: 0.3830 - val_acc: 0.8211\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3460 - acc: 0.8416 - val_loss: 0.3811 - val_acc: 0.8222\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3362 - acc: 0.8466 - val_loss: 0.3855 - val_acc: 0.8226\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3303 - acc: 0.8506 - val_loss: 0.3841 - val_acc: 0.8217\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3227 - acc: 0.8541 - val_loss: 0.3900 - val_acc: 0.8218\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 4s 58us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x2274f5be0>\n",
      "[0.82315353692568516, 0.82130321303034215, 0.82182821828575914]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 78.71%  Positive sentiment: 85.70%\n",
      "Percentage of positive classifications (should be 50%ish): 53.4945240555\n",
      "Time taken:  2.481143267949422 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 37s 281us/step - loss: 0.4927 - acc: 0.7581 - val_loss: 0.4097 - val_acc: 0.8058\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3977 - acc: 0.8128 - val_loss: 0.3936 - val_acc: 0.8164\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3835 - acc: 0.8214 - val_loss: 0.3892 - val_acc: 0.8192\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3729 - acc: 0.8271 - val_loss: 0.3856 - val_acc: 0.8207\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3632 - acc: 0.8327 - val_loss: 0.3807 - val_acc: 0.8220\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3558 - acc: 0.8363 - val_loss: 0.3820 - val_acc: 0.8231\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3481 - acc: 0.8416 - val_loss: 0.3820 - val_acc: 0.8230\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3409 - acc: 0.8453 - val_loss: 0.3818 - val_acc: 0.8232\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 4s 60us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 44us/step - loss: 0.4916 - acc: 0.7633 - val_loss: 0.4072 - val_acc: 0.8087\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3969 - acc: 0.8136 - val_loss: 0.3932 - val_acc: 0.8154\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3833 - acc: 0.8210 - val_loss: 0.3897 - val_acc: 0.8170\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3712 - acc: 0.8273 - val_loss: 0.3872 - val_acc: 0.8185\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3622 - acc: 0.8333 - val_loss: 0.3816 - val_acc: 0.8203\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3532 - acc: 0.8374 - val_loss: 0.3842 - val_acc: 0.8193\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3465 - acc: 0.8409 - val_loss: 0.3855 - val_acc: 0.8209\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3380 - acc: 0.8455 - val_loss: 0.3867 - val_acc: 0.8206\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 4s 63us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 44us/step - loss: 0.4918 - acc: 0.7641 - val_loss: 0.4106 - val_acc: 0.8056\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3946 - acc: 0.8154 - val_loss: 0.3963 - val_acc: 0.8138\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3803 - acc: 0.8226 - val_loss: 0.3919 - val_acc: 0.8151\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3698 - acc: 0.8283 - val_loss: 0.3871 - val_acc: 0.8184\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3605 - acc: 0.8335 - val_loss: 0.3830 - val_acc: 0.8195\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3525 - acc: 0.8376 - val_loss: 0.3821 - val_acc: 0.8210\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3461 - acc: 0.8410 - val_loss: 0.3821 - val_acc: 0.8213\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3367 - acc: 0.8465 - val_loss: 0.3859 - val_acc: 0.8215\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 31us/step - loss: 0.3310 - acc: 0.8503 - val_loss: 0.3842 - val_acc: 0.8216\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3230 - acc: 0.8548 - val_loss: 0.3885 - val_acc: 0.8221\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 4s 57us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x22fe00d30>\n",
      "[0.82322853543286767, 0.82056820568026867, 0.82214322143042617]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 78.57%  Positive sentiment: 85.82%\n",
      "Percentage of positive classifications (should be 50%ish): 53.6250228255\n",
      "Time taken:  2.866720402240753 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 15s 110us/step - loss: 0.4926 - acc: 0.7579 - val_loss: 0.4094 - val_acc: 0.8061\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3978 - acc: 0.8129 - val_loss: 0.3936 - val_acc: 0.8164\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3838 - acc: 0.8211 - val_loss: 0.3889 - val_acc: 0.8190\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3732 - acc: 0.8266 - val_loss: 0.3858 - val_acc: 0.8203\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3633 - acc: 0.8328 - val_loss: 0.3808 - val_acc: 0.8219\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3561 - acc: 0.8365 - val_loss: 0.3822 - val_acc: 0.8227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3485 - acc: 0.8415 - val_loss: 0.3815 - val_acc: 0.8232\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3411 - acc: 0.8446 - val_loss: 0.3826 - val_acc: 0.8229\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 5s 70us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 48us/step - loss: 0.4914 - acc: 0.7637 - val_loss: 0.4067 - val_acc: 0.8090\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3965 - acc: 0.8139 - val_loss: 0.3928 - val_acc: 0.8158\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3830 - acc: 0.8212 - val_loss: 0.3898 - val_acc: 0.8167\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3706 - acc: 0.8276 - val_loss: 0.3879 - val_acc: 0.8182\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3617 - acc: 0.8337 - val_loss: 0.3811 - val_acc: 0.8210\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3526 - acc: 0.8373 - val_loss: 0.3839 - val_acc: 0.8206\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3462 - acc: 0.8410 - val_loss: 0.3852 - val_acc: 0.8208\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3379 - acc: 0.8458 - val_loss: 0.3875 - val_acc: 0.8218\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 4s 66us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 47us/step - loss: 0.4915 - acc: 0.7643 - val_loss: 0.4099 - val_acc: 0.8059\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3944 - acc: 0.8156 - val_loss: 0.3961 - val_acc: 0.8146\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3801 - acc: 0.8226 - val_loss: 0.3910 - val_acc: 0.8158\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3697 - acc: 0.8280 - val_loss: 0.3863 - val_acc: 0.8182\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3605 - acc: 0.8333 - val_loss: 0.3824 - val_acc: 0.8203\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3524 - acc: 0.8376 - val_loss: 0.3819 - val_acc: 0.8213\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3457 - acc: 0.8420 - val_loss: 0.3819 - val_acc: 0.8216\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3361 - acc: 0.8469 - val_loss: 0.3847 - val_acc: 0.8225\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3294 - acc: 0.8511 - val_loss: 0.3845 - val_acc: 0.8217\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 4s 61us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x22394dd68>\n",
      "[0.82285354293271762, 0.82176821768575314, 0.82167821678037967]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 79.37%  Positive sentiment: 85.05%\n",
      "Percentage of positive classifications (should be 50%ish): 52.8380168004\n",
      "Time taken:  2.499856166044871 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 43s 319us/step - loss: 0.4925 - acc: 0.7583 - val_loss: 0.4102 - val_acc: 0.8058\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 37us/step - loss: 0.3977 - acc: 0.8128 - val_loss: 0.3934 - val_acc: 0.8167\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3837 - acc: 0.8210 - val_loss: 0.3889 - val_acc: 0.8193\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3730 - acc: 0.8268 - val_loss: 0.3856 - val_acc: 0.8203\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3636 - acc: 0.8327 - val_loss: 0.3807 - val_acc: 0.8225\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3565 - acc: 0.8361 - val_loss: 0.3822 - val_acc: 0.8224\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3490 - acc: 0.8411 - val_loss: 0.3821 - val_acc: 0.8230\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3420 - acc: 0.8441 - val_loss: 0.3827 - val_acc: 0.8230\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 5s 69us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 47us/step - loss: 0.4916 - acc: 0.7633 - val_loss: 0.4071 - val_acc: 0.8090\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3969 - acc: 0.8138 - val_loss: 0.3930 - val_acc: 0.8154\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3833 - acc: 0.8210 - val_loss: 0.3900 - val_acc: 0.8163\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3712 - acc: 0.8275 - val_loss: 0.3872 - val_acc: 0.8186\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3623 - acc: 0.8331 - val_loss: 0.3813 - val_acc: 0.8209\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3533 - acc: 0.8373 - val_loss: 0.3835 - val_acc: 0.8201\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3468 - acc: 0.8410 - val_loss: 0.3853 - val_acc: 0.8206\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3383 - acc: 0.8451 - val_loss: 0.3869 - val_acc: 0.8211\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 5s 68us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 47us/step - loss: 0.4916 - acc: 0.7641 - val_loss: 0.4101 - val_acc: 0.8060\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3946 - acc: 0.8151 - val_loss: 0.3964 - val_acc: 0.8140\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3805 - acc: 0.8225 - val_loss: 0.3891 - val_acc: 0.8165\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3701 - acc: 0.8282 - val_loss: 0.3861 - val_acc: 0.8187\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3606 - acc: 0.8335 - val_loss: 0.3826 - val_acc: 0.8202\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3525 - acc: 0.8377 - val_loss: 0.3836 - val_acc: 0.8207\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3461 - acc: 0.8418 - val_loss: 0.3814 - val_acc: 0.8225\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3364 - acc: 0.8468 - val_loss: 0.3845 - val_acc: 0.8211\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3304 - acc: 0.8500 - val_loss: 0.3863 - val_acc: 0.8216\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 5s 38us/step - loss: 0.3228 - acc: 0.8542 - val_loss: 0.3914 - val_acc: 0.8207\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 5s 69us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x21a3bc908>\n",
      "[0.82297354053276561, 0.8210632106321063, 0.82073320733564958]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 78.51%  Positive sentiment: 85.81%\n",
      "Percentage of positive classifications (should be 50%ish): 53.6470257005\n",
      "Time taken:  3.1053319334983827 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133332/133332 [==============================] - 17s 129us/step - loss: 0.4925 - acc: 0.7579 - val_loss: 0.4089 - val_acc: 0.8067\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3977 - acc: 0.8128 - val_loss: 0.3935 - val_acc: 0.8165\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3836 - acc: 0.8212 - val_loss: 0.3892 - val_acc: 0.8183\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3729 - acc: 0.8268 - val_loss: 0.3860 - val_acc: 0.8200\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 5s 37us/step - loss: 0.3632 - acc: 0.8325 - val_loss: 0.3806 - val_acc: 0.8232\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3558 - acc: 0.8364 - val_loss: 0.3841 - val_acc: 0.8221\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3487 - acc: 0.8413 - val_loss: 0.3813 - val_acc: 0.8232\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 32us/step - loss: 0.3413 - acc: 0.8447 - val_loss: 0.3836 - val_acc: 0.8224\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 4s 67us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 6s 49us/step - loss: 0.4915 - acc: 0.7637 - val_loss: 0.4067 - val_acc: 0.8090\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3966 - acc: 0.8139 - val_loss: 0.3927 - val_acc: 0.8155\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3830 - acc: 0.8209 - val_loss: 0.3896 - val_acc: 0.8178\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3707 - acc: 0.8280 - val_loss: 0.3868 - val_acc: 0.8186\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3617 - acc: 0.8334 - val_loss: 0.3809 - val_acc: 0.8207\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3525 - acc: 0.8384 - val_loss: 0.3829 - val_acc: 0.8211\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3458 - acc: 0.8418 - val_loss: 0.3855 - val_acc: 0.8207\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3370 - acc: 0.8460 - val_loss: 0.3867 - val_acc: 0.8209\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 4s 67us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 7s 50us/step - loss: 0.4914 - acc: 0.7643 - val_loss: 0.4106 - val_acc: 0.8059\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3944 - acc: 0.8154 - val_loss: 0.3963 - val_acc: 0.8144\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 6s 42us/step - loss: 0.3802 - acc: 0.8226 - val_loss: 0.3909 - val_acc: 0.8156\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 36us/step - loss: 0.3697 - acc: 0.8283 - val_loss: 0.3865 - val_acc: 0.8186\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3605 - acc: 0.8332 - val_loss: 0.3836 - val_acc: 0.8191\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3524 - acc: 0.8379 - val_loss: 0.3823 - val_acc: 0.8205\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3462 - acc: 0.8415 - val_loss: 0.3822 - val_acc: 0.8214\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3366 - acc: 0.8464 - val_loss: 0.3856 - val_acc: 0.8218\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3308 - acc: 0.8503 - val_loss: 0.3861 - val_acc: 0.8212\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3231 - acc: 0.8537 - val_loss: 0.3927 - val_acc: 0.8204\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 5s 68us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x21dc16978>\n",
      "[0.82243355133254958, 0.8208532085302972, 0.82038820388025069]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 78.30%  Positive sentiment: 85.94%\n",
      "Percentage of positive classifications (should be 50%ish): 53.8175226055\n",
      "Time taken:  2.686080002784729 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 47s 351us/step - loss: 0.5095 - acc: 0.7456 - val_loss: 0.4275 - val_acc: 0.7949\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.4154 - acc: 0.8020 - val_loss: 0.4108 - val_acc: 0.8060\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.4004 - acc: 0.8110 - val_loss: 0.4055 - val_acc: 0.8081\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 38us/step - loss: 0.3873 - acc: 0.8175 - val_loss: 0.4024 - val_acc: 0.8087\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3762 - acc: 0.8253 - val_loss: 0.3957 - val_acc: 0.8126\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3682 - acc: 0.8301 - val_loss: 0.4012 - val_acc: 0.8103\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3601 - acc: 0.8340 - val_loss: 0.3959 - val_acc: 0.8135\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 36us/step - loss: 0.3513 - acc: 0.8393 - val_loss: 0.4024 - val_acc: 0.8123\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 5s 73us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 7s 54us/step - loss: 0.5113 - acc: 0.7478 - val_loss: 0.4288 - val_acc: 0.7939\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.4148 - acc: 0.8021 - val_loss: 0.4108 - val_acc: 0.8038\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3993 - acc: 0.8106 - val_loss: 0.4102 - val_acc: 0.8032\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3870 - acc: 0.8174 - val_loss: 0.4045 - val_acc: 0.8072\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3771 - acc: 0.8237 - val_loss: 0.3993 - val_acc: 0.8093\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3674 - acc: 0.8296 - val_loss: 0.3996 - val_acc: 0.8111\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3609 - acc: 0.8324 - val_loss: 0.4005 - val_acc: 0.8101\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.3512 - acc: 0.8386 - val_loss: 0.3995 - val_acc: 0.8113\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 5s 75us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 7s 51us/step - loss: 0.5102 - acc: 0.7497 - val_loss: 0.4290 - val_acc: 0.7939\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.4137 - acc: 0.8034 - val_loss: 0.4132 - val_acc: 0.8028\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3982 - acc: 0.8116 - val_loss: 0.4051 - val_acc: 0.8062\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3867 - acc: 0.8181 - val_loss: 0.4024 - val_acc: 0.8083\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3760 - acc: 0.8245 - val_loss: 0.3970 - val_acc: 0.8118\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3668 - acc: 0.8298 - val_loss: 0.3998 - val_acc: 0.8116\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3599 - acc: 0.8340 - val_loss: 0.3969 - val_acc: 0.8126\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3494 - acc: 0.8395 - val_loss: 0.4025 - val_acc: 0.8113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3429 - acc: 0.8437 - val_loss: 0.4023 - val_acc: 0.8092\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3347 - acc: 0.8487 - val_loss: 0.4041 - val_acc: 0.8112\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 5s 71us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x225103390>\n",
      "[0.81232375352492947, 0.81134311343471066, 0.81119311193469568]\n",
      "0.81% (+/- 0.00%)\n",
      "Negative sentiment: 77.92%  Positive sentiment: 84.40%\n",
      "Percentage of positive classifications (should be 50%ish): 53.2410091906\n",
      "Time taken:  3.234620213508606 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 18s 132us/step - loss: 0.4885 - acc: 0.7630 - val_loss: 0.4064 - val_acc: 0.8067\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3967 - acc: 0.8131 - val_loss: 0.3896 - val_acc: 0.8171\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3828 - acc: 0.8216 - val_loss: 0.3895 - val_acc: 0.8177\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3721 - acc: 0.8281 - val_loss: 0.3837 - val_acc: 0.8202\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3631 - acc: 0.8324 - val_loss: 0.3788 - val_acc: 0.8235\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3557 - acc: 0.8370 - val_loss: 0.3777 - val_acc: 0.8245\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3475 - acc: 0.8415 - val_loss: 0.3797 - val_acc: 0.8224\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3401 - acc: 0.8449 - val_loss: 0.3820 - val_acc: 0.8226\n",
      "Epoch 9/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3326 - acc: 0.8484 - val_loss: 0.3880 - val_acc: 0.8231\n",
      "Epoch 00009: early stopping\n",
      "66668/66668 [==============================] - 5s 76us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 8s 59us/step - loss: 0.4908 - acc: 0.7629 - val_loss: 0.4077 - val_acc: 0.8077\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3957 - acc: 0.8142 - val_loss: 0.3964 - val_acc: 0.8127\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3817 - acc: 0.8215 - val_loss: 0.3892 - val_acc: 0.8185\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3692 - acc: 0.8285 - val_loss: 0.3857 - val_acc: 0.8200\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3603 - acc: 0.8349 - val_loss: 0.3821 - val_acc: 0.8210\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3514 - acc: 0.8389 - val_loss: 0.3839 - val_acc: 0.8211\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3439 - acc: 0.8431 - val_loss: 0.3865 - val_acc: 0.8218\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3353 - acc: 0.8474 - val_loss: 0.3861 - val_acc: 0.8218\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 5s 82us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 11s 79us/step - loss: 0.4907 - acc: 0.7640 - val_loss: 0.4086 - val_acc: 0.8073\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3953 - acc: 0.8143 - val_loss: 0.3960 - val_acc: 0.8136\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3824 - acc: 0.8218 - val_loss: 0.3876 - val_acc: 0.8169\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3710 - acc: 0.8288 - val_loss: 0.3857 - val_acc: 0.8179\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3624 - acc: 0.8330 - val_loss: 0.3813 - val_acc: 0.8214\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3538 - acc: 0.8373 - val_loss: 0.3791 - val_acc: 0.8234\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3471 - acc: 0.8417 - val_loss: 0.3843 - val_acc: 0.8212\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3380 - acc: 0.8459 - val_loss: 0.3873 - val_acc: 0.8210\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3314 - acc: 0.8500 - val_loss: 0.3821 - val_acc: 0.8225\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 5s 78us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x225496390>\n",
      "[0.82313853723283159, 0.82176821768038866, 0.82253322533046513]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 79.82%  Positive sentiment: 84.68%\n",
      "Percentage of positive classifications (should be 50%ish): 52.4290155453\n",
      "Time taken:  3.320331001281738 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 18s 135us/step - loss: 0.4919 - acc: 0.7587 - val_loss: 0.4073 - val_acc: 0.8080\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3967 - acc: 0.8134 - val_loss: 0.3919 - val_acc: 0.8170\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3824 - acc: 0.8218 - val_loss: 0.3874 - val_acc: 0.8198\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 38us/step - loss: 0.3722 - acc: 0.8273 - val_loss: 0.3870 - val_acc: 0.8190\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3627 - acc: 0.8335 - val_loss: 0.3801 - val_acc: 0.8236\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 5s 38us/step - loss: 0.3556 - acc: 0.8362 - val_loss: 0.3820 - val_acc: 0.8232\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 5s 38us/step - loss: 0.3482 - acc: 0.8410 - val_loss: 0.3803 - val_acc: 0.8237\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3415 - acc: 0.8448 - val_loss: 0.3817 - val_acc: 0.8238\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 5s 75us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 9s 65us/step - loss: 0.4910 - acc: 0.7645 - val_loss: 0.4052 - val_acc: 0.8094\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3953 - acc: 0.8148 - val_loss: 0.3920 - val_acc: 0.8159\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3818 - acc: 0.8223 - val_loss: 0.3880 - val_acc: 0.8188\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3695 - acc: 0.8288 - val_loss: 0.3870 - val_acc: 0.8194\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3608 - acc: 0.8341 - val_loss: 0.3802 - val_acc: 0.8221\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3514 - acc: 0.8388 - val_loss: 0.3850 - val_acc: 0.8193\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3449 - acc: 0.8421 - val_loss: 0.3831 - val_acc: 0.8222\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3364 - acc: 0.8471 - val_loss: 0.3853 - val_acc: 0.8220\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 5s 79us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 8s 59us/step - loss: 0.4910 - acc: 0.7649 - val_loss: 0.4090 - val_acc: 0.8062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3935 - acc: 0.8160 - val_loss: 0.3947 - val_acc: 0.8150\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3790 - acc: 0.8239 - val_loss: 0.3911 - val_acc: 0.8158\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3687 - acc: 0.8291 - val_loss: 0.3848 - val_acc: 0.8189\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3593 - acc: 0.8339 - val_loss: 0.3812 - val_acc: 0.8203\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3515 - acc: 0.8389 - val_loss: 0.3809 - val_acc: 0.8225\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3445 - acc: 0.8429 - val_loss: 0.3809 - val_acc: 0.8229\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3351 - acc: 0.8478 - val_loss: 0.3846 - val_acc: 0.8224\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3285 - acc: 0.8519 - val_loss: 0.3853 - val_acc: 0.8214\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 6s 89us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x22a7791d0>\n",
      "[0.82379852402594322, 0.82202322023577867, 0.82137821377856146]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 79.72%  Positive sentiment: 84.76%\n",
      "Percentage of positive classifications (should be 50%ish): 52.5220147354\n",
      "Time taken:  2.8150415341059367 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 48s 362us/step - loss: 0.4897 - acc: 0.7610 - val_loss: 0.4053 - val_acc: 0.8097\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3944 - acc: 0.8153 - val_loss: 0.3888 - val_acc: 0.8197\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 5s 37us/step - loss: 0.3799 - acc: 0.8234 - val_loss: 0.3848 - val_acc: 0.8223\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3689 - acc: 0.8303 - val_loss: 0.3805 - val_acc: 0.8247\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3598 - acc: 0.8355 - val_loss: 0.3759 - val_acc: 0.8262\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3522 - acc: 0.8393 - val_loss: 0.3800 - val_acc: 0.8248\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3452 - acc: 0.8434 - val_loss: 0.3761 - val_acc: 0.8259\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3379 - acc: 0.8475 - val_loss: 0.3780 - val_acc: 0.8262\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 7s 99us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 8s 61us/step - loss: 0.4887 - acc: 0.7660 - val_loss: 0.4037 - val_acc: 0.8110\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 37us/step - loss: 0.3928 - acc: 0.8164 - val_loss: 0.3898 - val_acc: 0.8167\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3791 - acc: 0.8236 - val_loss: 0.3862 - val_acc: 0.8192\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3666 - acc: 0.8307 - val_loss: 0.3843 - val_acc: 0.8215\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 37us/step - loss: 0.3578 - acc: 0.8358 - val_loss: 0.3779 - val_acc: 0.8242\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3488 - acc: 0.8399 - val_loss: 0.3815 - val_acc: 0.8226\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3423 - acc: 0.8436 - val_loss: 0.3831 - val_acc: 0.8234\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3337 - acc: 0.8487 - val_loss: 0.3822 - val_acc: 0.8251\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 6s 85us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 8s 63us/step - loss: 0.4894 - acc: 0.7662 - val_loss: 0.4071 - val_acc: 0.8084\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3910 - acc: 0.8178 - val_loss: 0.3930 - val_acc: 0.8154\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3768 - acc: 0.8256 - val_loss: 0.3864 - val_acc: 0.8173\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3660 - acc: 0.8318 - val_loss: 0.3826 - val_acc: 0.8205\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3566 - acc: 0.8367 - val_loss: 0.3781 - val_acc: 0.8222\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3483 - acc: 0.8409 - val_loss: 0.3791 - val_acc: 0.8231\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3416 - acc: 0.8446 - val_loss: 0.3776 - val_acc: 0.8243\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3314 - acc: 0.8508 - val_loss: 0.3816 - val_acc: 0.8248\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3256 - acc: 0.8536 - val_loss: 0.3812 - val_acc: 0.8238\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3176 - acc: 0.8584 - val_loss: 0.3844 - val_acc: 0.8244\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 6s 89us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x22f10b3c8>\n",
      "[0.8262434751269212, 0.82508325083608469, 0.82443824438065572]\n",
      "0.83% (+/- 0.00%)\n",
      "Negative sentiment: 79.40%  Positive sentiment: 85.65%\n",
      "Percentage of positive classifications (should be 50%ish): 53.1265205554\n",
      "Time taken:  3.4465322494506836 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 21s 160us/step - loss: 0.5048 - acc: 0.7480 - val_loss: 0.4266 - val_acc: 0.7970\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.4135 - acc: 0.8046 - val_loss: 0.4082 - val_acc: 0.8067\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3996 - acc: 0.8125 - val_loss: 0.4047 - val_acc: 0.8094\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 37us/step - loss: 0.3886 - acc: 0.8186 - val_loss: 0.4000 - val_acc: 0.8120\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3788 - acc: 0.8248 - val_loss: 0.3959 - val_acc: 0.8149\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3713 - acc: 0.8288 - val_loss: 0.3988 - val_acc: 0.8145\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3640 - acc: 0.8340 - val_loss: 0.4008 - val_acc: 0.8136\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3569 - acc: 0.8365 - val_loss: 0.4009 - val_acc: 0.8137\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 6s 89us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 8s 61us/step - loss: 0.5025 - acc: 0.7564 - val_loss: 0.4216 - val_acc: 0.7992\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.4115 - acc: 0.8046 - val_loss: 0.4092 - val_acc: 0.8061\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 36us/step - loss: 0.3981 - acc: 0.8128 - val_loss: 0.4057 - val_acc: 0.8089\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3855 - acc: 0.8197 - val_loss: 0.4024 - val_acc: 0.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 37us/step - loss: 0.3767 - acc: 0.8251 - val_loss: 0.3964 - val_acc: 0.8140\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3676 - acc: 0.8300 - val_loss: 0.3970 - val_acc: 0.8138\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3610 - acc: 0.8334 - val_loss: 0.3986 - val_acc: 0.8126\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.3532 - acc: 0.8378 - val_loss: 0.3988 - val_acc: 0.8122\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 6s 91us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 11s 80us/step - loss: 0.5024 - acc: 0.7571 - val_loss: 0.4238 - val_acc: 0.7987\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.4105 - acc: 0.8062 - val_loss: 0.4094 - val_acc: 0.8059\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3967 - acc: 0.8137 - val_loss: 0.4053 - val_acc: 0.8079\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3861 - acc: 0.8191 - val_loss: 0.4016 - val_acc: 0.8104\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3762 - acc: 0.8247 - val_loss: 0.3963 - val_acc: 0.8129\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3684 - acc: 0.8291 - val_loss: 0.3975 - val_acc: 0.8138\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3613 - acc: 0.8338 - val_loss: 0.3964 - val_acc: 0.8140\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3519 - acc: 0.8388 - val_loss: 0.4011 - val_acc: 0.8136\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 6s 94us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x2397fbc50>\n",
      "[0.81373372532191723, 0.81222812227943464, 0.81363813638315197]\n",
      "0.81% (+/- 0.00%)\n",
      "Negative sentiment: 78.78%  Positive sentiment: 83.86%\n",
      "Percentage of positive classifications (should be 50%ish): 52.5400230003\n",
      "Time taken:  3.431625485420227 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 22s 163us/step - loss: 0.4908 - acc: 0.7581 - val_loss: 0.4034 - val_acc: 0.8071\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 41us/step - loss: 0.3951 - acc: 0.8132 - val_loss: 0.3902 - val_acc: 0.8165\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3811 - acc: 0.8221 - val_loss: 0.3866 - val_acc: 0.8191\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3702 - acc: 0.8282 - val_loss: 0.3814 - val_acc: 0.8215\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 5s 37us/step - loss: 0.3614 - acc: 0.8343 - val_loss: 0.3781 - val_acc: 0.8246\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3534 - acc: 0.8375 - val_loss: 0.3786 - val_acc: 0.8234\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3471 - acc: 0.8423 - val_loss: 0.3798 - val_acc: 0.8226\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3391 - acc: 0.8479 - val_loss: 0.3855 - val_acc: 0.8207\n",
      "Epoch 00008: early stopping\n",
      "66668/66668 [==============================] - 7s 100us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 10s 74us/step - loss: 0.4895 - acc: 0.7641 - val_loss: 0.4036 - val_acc: 0.8093\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3937 - acc: 0.8147 - val_loss: 0.3897 - val_acc: 0.8162\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3805 - acc: 0.8221 - val_loss: 0.3851 - val_acc: 0.8187\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 38us/step - loss: 0.3679 - acc: 0.8291 - val_loss: 0.3860 - val_acc: 0.8184\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3591 - acc: 0.8348 - val_loss: 0.3782 - val_acc: 0.8212\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3502 - acc: 0.8388 - val_loss: 0.3807 - val_acc: 0.8212\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3440 - acc: 0.8434 - val_loss: 0.3812 - val_acc: 0.8218\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3350 - acc: 0.8488 - val_loss: 0.3863 - val_acc: 0.8213\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 6s 92us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 8s 62us/step - loss: 0.4893 - acc: 0.7648 - val_loss: 0.4065 - val_acc: 0.8068\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3907 - acc: 0.8167 - val_loss: 0.3927 - val_acc: 0.8151\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3771 - acc: 0.8238 - val_loss: 0.3894 - val_acc: 0.8163\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3669 - acc: 0.8296 - val_loss: 0.3856 - val_acc: 0.8184\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3582 - acc: 0.8352 - val_loss: 0.3792 - val_acc: 0.8212\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3500 - acc: 0.8389 - val_loss: 0.3794 - val_acc: 0.8232\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3438 - acc: 0.8432 - val_loss: 0.3787 - val_acc: 0.8233\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3340 - acc: 0.8482 - val_loss: 0.3865 - val_acc: 0.8206\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3283 - acc: 0.8518 - val_loss: 0.3830 - val_acc: 0.8214\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3206 - acc: 0.8565 - val_loss: 0.3879 - val_acc: 0.8212\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 6s 91us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x2328f3390>\n",
      "[0.82069358613185361, 0.82125821258570209, 0.82124321243033616]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 78.71%  Positive sentiment: 85.50%\n",
      "Percentage of positive classifications (should be 50%ish): 53.3945412053\n",
      "Time taken:  3.1421970168749493 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 60s 447us/step - loss: 0.4921 - acc: 0.7557 - val_loss: 0.4043 - val_acc: 0.8061\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 38us/step - loss: 0.3970 - acc: 0.8128 - val_loss: 0.3920 - val_acc: 0.8156\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3833 - acc: 0.8207 - val_loss: 0.3876 - val_acc: 0.8185\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3727 - acc: 0.8268 - val_loss: 0.3843 - val_acc: 0.8195\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 5s 37us/step - loss: 0.3637 - acc: 0.8325 - val_loss: 0.3800 - val_acc: 0.8228\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 6s 42us/step - loss: 0.3562 - acc: 0.8365 - val_loss: 0.3813 - val_acc: 0.8222\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 5s 35us/step - loss: 0.3499 - acc: 0.8412 - val_loss: 0.3793 - val_acc: 0.8216\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3414 - acc: 0.8452 - val_loss: 0.3856 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3362 - acc: 0.8481 - val_loss: 0.3830 - val_acc: 0.8228\n",
      "Epoch 10/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3287 - acc: 0.8532 - val_loss: 0.3842 - val_acc: 0.8224\n",
      "Epoch 00010: early stopping\n",
      "66668/66668 [==============================] - 7s 102us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 8s 64us/step - loss: 0.4918 - acc: 0.7610 - val_loss: 0.4049 - val_acc: 0.8081\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3957 - acc: 0.8126 - val_loss: 0.3917 - val_acc: 0.8148\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3832 - acc: 0.8198 - val_loss: 0.3868 - val_acc: 0.8170\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3710 - acc: 0.8273 - val_loss: 0.3903 - val_acc: 0.8150\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3620 - acc: 0.8328 - val_loss: 0.3809 - val_acc: 0.8199\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3542 - acc: 0.8363 - val_loss: 0.3825 - val_acc: 0.8204\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3471 - acc: 0.8405 - val_loss: 0.3822 - val_acc: 0.8210\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3392 - acc: 0.8457 - val_loss: 0.3861 - val_acc: 0.8197\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 6s 97us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 9s 65us/step - loss: 0.4896 - acc: 0.7632 - val_loss: 0.4095 - val_acc: 0.8048\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3928 - acc: 0.8145 - val_loss: 0.3948 - val_acc: 0.8134\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3796 - acc: 0.8226 - val_loss: 0.3902 - val_acc: 0.8149\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3693 - acc: 0.8285 - val_loss: 0.3868 - val_acc: 0.8168\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3606 - acc: 0.8332 - val_loss: 0.3811 - val_acc: 0.8192\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3524 - acc: 0.8379 - val_loss: 0.3804 - val_acc: 0.8219\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3463 - acc: 0.8421 - val_loss: 0.3811 - val_acc: 0.8218\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3372 - acc: 0.8467 - val_loss: 0.3860 - val_acc: 0.8199\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3306 - acc: 0.8506 - val_loss: 0.3850 - val_acc: 0.8206\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 7s 104us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x234715208>\n",
      "[0.82235855283251957, 0.81965319653017721, 0.82059820598384803]\n",
      "0.82% (+/- 0.00%)\n",
      "Negative sentiment: 79.03%  Positive sentiment: 85.14%\n",
      "Percentage of positive classifications (should be 50%ish): 53.0530177954\n",
      "Time taken:  3.857132701079051 \n",
      "\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133332/133332 [==============================] - 61s 457us/step - loss: 0.4957 - acc: 0.7515 - val_loss: 0.4107 - val_acc: 0.8026\n",
      "Epoch 2/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.4039 - acc: 0.8077 - val_loss: 0.3988 - val_acc: 0.8104\n",
      "Epoch 3/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3905 - acc: 0.8157 - val_loss: 0.3950 - val_acc: 0.8131\n",
      "Epoch 4/100\n",
      "133332/133332 [==============================] - 5s 34us/step - loss: 0.3812 - acc: 0.8203 - val_loss: 0.3920 - val_acc: 0.8154\n",
      "Epoch 5/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3716 - acc: 0.8267 - val_loss: 0.3868 - val_acc: 0.8174\n",
      "Epoch 6/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3644 - acc: 0.8307 - val_loss: 0.3881 - val_acc: 0.8173\n",
      "Epoch 7/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3579 - acc: 0.8352 - val_loss: 0.3867 - val_acc: 0.8165\n",
      "Epoch 8/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3502 - acc: 0.8384 - val_loss: 0.3902 - val_acc: 0.8163\n",
      "Epoch 9/100\n",
      "133332/133332 [==============================] - 4s 34us/step - loss: 0.3434 - acc: 0.8425 - val_loss: 0.3904 - val_acc: 0.8178\n",
      "Epoch 10/100\n",
      "133332/133332 [==============================] - 4s 33us/step - loss: 0.3361 - acc: 0.8470 - val_loss: 0.3926 - val_acc: 0.8157\n",
      "Epoch 00010: early stopping\n",
      "66668/66668 [==============================] - 6s 95us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 9s 66us/step - loss: 0.4943 - acc: 0.7583 - val_loss: 0.4130 - val_acc: 0.8015\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.4027 - acc: 0.8082 - val_loss: 0.3994 - val_acc: 0.8095\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3904 - acc: 0.8147 - val_loss: 0.3945 - val_acc: 0.8121\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3791 - acc: 0.8220 - val_loss: 0.3956 - val_acc: 0.8119\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3715 - acc: 0.8254 - val_loss: 0.3885 - val_acc: 0.8151\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3633 - acc: 0.8305 - val_loss: 0.3887 - val_acc: 0.8158\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3567 - acc: 0.8344 - val_loss: 0.3892 - val_acc: 0.8164\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.3487 - acc: 0.8395 - val_loss: 0.3907 - val_acc: 0.8158\n",
      "Epoch 00008: early stopping\n",
      "66666/66666 [==============================] - 7s 103us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133334/133334 [==============================] - 9s 65us/step - loss: 0.4942 - acc: 0.7599 - val_loss: 0.4143 - val_acc: 0.8016\n",
      "Epoch 2/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3997 - acc: 0.8100 - val_loss: 0.4015 - val_acc: 0.8085\n",
      "Epoch 3/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3876 - acc: 0.8169 - val_loss: 0.3985 - val_acc: 0.8088\n",
      "Epoch 4/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3785 - acc: 0.8222 - val_loss: 0.3936 - val_acc: 0.8123\n",
      "Epoch 5/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3702 - acc: 0.8267 - val_loss: 0.3896 - val_acc: 0.8134\n",
      "Epoch 6/100\n",
      "133334/133334 [==============================] - 4s 34us/step - loss: 0.3621 - acc: 0.8316 - val_loss: 0.3897 - val_acc: 0.8161\n",
      "Epoch 7/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3556 - acc: 0.8364 - val_loss: 0.3893 - val_acc: 0.8153\n",
      "Epoch 8/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3470 - acc: 0.8405 - val_loss: 0.3931 - val_acc: 0.8163\n",
      "Epoch 9/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3400 - acc: 0.8447 - val_loss: 0.3929 - val_acc: 0.8147\n",
      "Epoch 10/100\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.3324 - acc: 0.8486 - val_loss: 0.4000 - val_acc: 0.8134\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 7s 103us/step\n",
      "Model:  deep_HB\n",
      "<keras.callbacks.History object at 0x2360ef8d0>\n",
      "[0.81565368692983764, 0.81579815798515609, 0.81339813398491612]\n",
      "0.81% (+/- 0.00%)\n",
      "Negative sentiment: 76.97%  Positive sentiment: 86.02%\n",
      "Percentage of positive classifications (should be 50%ish): 54.5280284806\n",
      "Time taken:  3.915279217561086 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "stds=[]\n",
    "\n",
    "for corpus in corpuses: \n",
    "    model_score=GV.classify_with_neural_networks(neural_nets, global_vectors, corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "    accuracies.append(model_score[0][0])\n",
    "    stds.append(model_score[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the data\n",
    "#simpleprocessing = { \"corpus\": corpuses, \"accuracies\":accuracies, \"stds\":stds, \"names\":names }\n",
    "pickle.dump(simpleprocessing, open( \"simpleprocessing.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82133998906616545, 0.82472498886446033, 0.82494499361862905, 0.82164998541209167, 0.82181498871328384, 0.82209498941392889, 0.82197998751452073, 0.82209999246628351, 0.82158998616684054, 0.82122498791436582, 0.8116199929647786, 0.82247999341456168, 0.82239998601342779, 0.82525499011455372, 0.81319999466150128, 0.82106500371596403, 0.82086998511551501, 0.81494999296663673]\n"
     ]
    }
   ],
   "source": [
    "# pickle the data\n",
    "# FORMAT OF DATA: { \"corpus\": corpuses, \"accuracies\":accuracies, \"stds\":stds, \"names\":names }\n",
    "jesus_processing = pickle.load(open( \"simpleprocessing.pkl\", \"rb\"))\n",
    "print(jesus_processing['accuracies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to determine which preprocessing techniques that improved the accuracy, and keep them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original corpus gave accuracy of:  0.821339989066 \n",
      "\n",
      "IMPROVED:   SH_corpus , score: 0.824724988864 std: 0.000803296554916\n",
      "IMPROVED:   SHM_corpus , score: 0.824944993619 std: 0.000689043300155\n",
      "IMPROVED:   H_corpus , score: 0.821649985412 std: 0.00109691743644\n",
      "IMPROVED:   HK_corpus , score: 0.821814988713 std: 0.000952763449648\n",
      "IMPROVED:   PS_corpus , score: 0.822094989414 std: 0.000778588361733\n",
      "IMPROVED:   NS__corpus , score: 0.821979987515 std: 0.00109219124748\n",
      "IMPROVED:   OS_corpus , score: 0.822099992466 std: 0.000534105963169\n",
      "IMPROVED:   N_corpus , score: 0.821589986167 std: 0.000987553393163\n",
      "Not better: NM_corpus , score: 0.821224987914 std: 0.000875414752358\n",
      "Not better: ST_corpus , score: 0.811619992965 std: 0.000501387612544\n",
      "IMPROVED:   SP_corpus , score: 0.822479993415 std: 0.000560695488719\n",
      "IMPROVED:   E_corpus , score: 0.822399986013 std: 0.00102337342868\n",
      "IMPROVED:   SN_corpus , score: 0.825254990115 std: 0.000746920476196\n",
      "Not better: RS_corpus , score: 0.813199994662 std: 0.000688324660109\n",
      "Not better: N-2_corpus , score: 0.821065003716 std: 0.000262703276854\n",
      "Not better: N-3_corpus , score: 0.820869985116 std: 0.00112105191761\n",
      "Not better: N-4_corpus , score: 0.814949992967 std: 0.00109891391711\n"
     ]
    }
   ],
   "source": [
    "corpuses_1=[]\n",
    "names_1=[]\n",
    "stds_1=[]\n",
    "acc_1=[]\n",
    "print('The original corpus gave accuracy of: ',accuracies[0],'\\n')\n",
    "for i in range(1,len(accuracies)):\n",
    "    if accuracies[i]>=accuracies[0]:\n",
    "        corpuses_1.append(corpuses[i])\n",
    "        names_1.append(names[i])\n",
    "        stds_1.append(stds[i])\n",
    "        acc_1.append(accuracies[i])\n",
    "        print('IMPROVED:  ',names[i],', score:',accuracies[i],'std:',stds[i])\n",
    "    else:\n",
    "        print('Not better:',names[i],', score:',accuracies[i],'std:',stds[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SH_corpus', 'SHM_corpus', 'H_corpus', 'HK_corpus', 'PS_corpus', 'NS__corpus', 'OS_corpus', 'N_corpus', 'SP_corpus', 'E_corpus', 'SN_corpus']\n"
     ]
    }
   ],
   "source": [
    "print(names_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 2: apply best preprocessing technique to all other techniques that imporved the accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to determine which preprocessing technique-combinations that improved the accuracy, and keep them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 3: apply best preprocessing technique-combination to all other techniques that imporved the accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords= CL.get_dynamic_stopwords(full_corpus, MinDf=0.01, MaxDf=0.99,sublinearTF=True,useIDF=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopword_corpus=CL.remove_stopwords(full_corpus, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpuses.append(stopword_corpus)\n",
    "names.append('stopword_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing \"best preprocessing\" with full dataset: \n",
    "\n",
    "Som før for å lage en keggle! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_corpus=TO.preprocess_corpus(full_corpus, segmentation_hash=True, hashtag=True, hashtag_mention=True, set_to_not=True,elongation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_score=GV.classify_with_neural_networks(neural_nets, global_vectors, final_corpus, total_training_tweets, nr_pos_tweets, epochs=6, n_folds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making kaggle submission: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_name=\"keggle_glove_13_12_full.csv\"\n",
    "#final_corpus=n_grams_corpus\n",
    "\n",
    "pred= GV.get_prediction(NN.deep_HB, global_vectors, final_corpus, total_training_tweets, nr_pos_tweets,kaggle_name, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sum(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
