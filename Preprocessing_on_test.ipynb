{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Best Combination of Preprocessing Techniques on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HeddaVik/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# internal imports\n",
    "import helpers as HL\n",
    "import glove_module as GV\n",
    "import neural_nets as NN\n",
    "import validation_and_prediction as VP\n",
    "import tokenizing as TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word embeddings using the created gensim-.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pick one, the higher dimension, the better result and longer computational time. \n",
    "global_vectors=HL.get_global_vectors(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating corpus:\n",
    "In addition to the acutal corpus, some additional information is needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_corpus, nr_pos_tweets, nr_neg_tweets, total_training_tweets=HL.get_corpus(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the neural net\n",
    "At this stage, we want to use the simple neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural_nets=[NN.basic_model_adam]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables to apply all preprocessing techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing vectors:\n",
    "corpuses=[]\n",
    "corpuses.append(full_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining names of corpuses: \n",
    "names=['original_corpus','SH_corpus','SHM_corpus','H_corpus','HK_corpus','PS_corpus','NS__corpus','OS_corpus','N_corpus','NM_corpus','ST_corpus','SP_corpus','E_corpus','SN_corpus','RS_corpus','EX_corpus','N-2_corpus','N-3_corpus','N-4_corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining inputs to preprocessing function: \n",
    "inputs=[{'hashtag': True, 'segmentation_hash': True},\n",
    "        {'hashtag':True,'segmentation_hash': True,'hashtag_mention':True},\n",
    "        {'hearts':True},\n",
    "        {'hugs_and_kisses':True},\n",
    "        {'pos_smilies':True},\n",
    "        {'neg_smilies':True},\n",
    "        {'other_smilies':True},\n",
    "        {'numbers':True},\n",
    "        {'numbers':True,'number_mention':True},\n",
    "        {'stemming':True},\n",
    "        {'spelling':True},#Warning: When True, it takes app  2.5 h on test set. Recomended to always set to false \n",
    "        {'elongation':True},\n",
    "        {'set_to_not':True},\n",
    "        {'remove_signs':True},\n",
    "        {'exclamation':True}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying all preprocessing techniques to the original corpus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Time in min before starting first for loop: 0.1436559518178304\n",
      "Time in min after 1  tweets: 0.14389031728108723\n",
      "Time in min after 25001  tweets: 0.30348013242085775\n",
      "Time in min after 50001  tweets: 0.43382955392201744\n",
      "Time in min after 75001  tweets: 0.558660888671875\n",
      "Time in min after 100001  tweets: 0.688304070631663\n",
      "Time in min after 125001  tweets: 0.7780535181363424\n",
      "Time in min after 150001  tweets: 0.8791473507881165\n",
      "Time in min after 175001  tweets: 0.9658855517705282\n",
      "Time in min after 200001  tweets: 1.0498501340548196\n",
      "Time in min total: 1.088587518533071\n",
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Time in min before starting first for loop: 0.14544553756713868\n",
      "Time in min after 1  tweets: 0.14553653399149577\n",
      "Time in min after 25001  tweets: 0.36271895170211793\n",
      "Time in min after 50001  tweets: 0.48187756538391113\n",
      "Time in min after 75001  tweets: 0.6029905160268147\n",
      "Time in min after 100001  tweets: 0.7281522313753764\n",
      "Time in min after 125001  tweets: 0.824855101108551\n",
      "Time in min after 150001  tweets: 0.9295561194419861\n",
      "Time in min after 175001  tweets: 1.0864377816518147\n",
      "Time in min after 200001  tweets: 1.179166603088379\n",
      "Time in min total: 1.2214224020640054\n",
      "Time in min before starting first for loop: 1.986821492513021e-07\n",
      "Time in min after 1  tweets: 1.1066595713297525e-05\n",
      "Time in min after 25001  tweets: 0.036681199073791505\n",
      "Time in min after 50001  tweets: 0.08183350165685017\n",
      "Time in min after 75001  tweets: 0.12411334911982218\n",
      "Time in min after 100001  tweets: 0.16018033425013226\n",
      "Time in min after 125001  tweets: 0.2153873324394226\n",
      "Time in min after 150001  tweets: 0.2625072479248047\n",
      "Time in min after 175001  tweets: 0.30550899902979534\n",
      "Time in min after 200001  tweets: 0.34981273412704467\n",
      "Time in min total: 0.3665616512298584\n",
      "Time in min before starting first for loop: 2.3444493611653645e-07\n",
      "Time in min after 1  tweets: 9.985764821370443e-06\n",
      "Time in min after 25001  tweets: 0.039212135473887126\n",
      "Time in min after 50001  tweets: 0.0747536857922872\n",
      "Time in min after 75001  tweets: 0.10981480280558269\n",
      "Time in min after 100001  tweets: 0.1449432651201884\n",
      "Time in min after 125001  tweets: 0.1890914003054301\n",
      "Time in min after 150001  tweets: 0.23168223698933918\n",
      "Time in min after 175001  tweets: 0.2735080679257711\n",
      "Time in min after 200001  tweets: 0.3156483848889669\n",
      "Time in min total: 0.33231285015741985\n",
      "Time in min before starting first for loop: 5.1657358805338543e-08\n",
      "Time in min after 1  tweets: 1.0482470194498698e-05\n",
      "Time in min after 25001  tweets: 0.03705546458562215\n",
      "Time in min after 50001  tweets: 0.07720609903335571\n",
      "Time in min after 75001  tweets: 0.11368538538614908\n",
      "Time in min after 100001  tweets: 0.15132960081100463\n",
      "Time in min after 125001  tweets: 0.19682021538416544\n",
      "Time in min after 150001  tweets: 0.2404235323270162\n",
      "Time in min after 175001  tweets: 0.283683717250824\n",
      "Time in min after 200001  tweets: 0.3272354006767273\n",
      "Time in min total: 0.34498658577601116\n",
      "Time in min before starting first for loop: 9.934107462565105e-08\n",
      "Time in min after 1  tweets: 1.4917055765787761e-05\n",
      "Time in min after 25001  tweets: 0.03606611887613932\n",
      "Time in min after 50001  tweets: 0.07045566240946452\n",
      "Time in min after 75001  tweets: 0.10504428148269654\n",
      "Time in min after 100001  tweets: 0.13978913227717082\n",
      "Time in min after 125001  tweets: 0.18047536611557008\n",
      "Time in min after 150001  tweets: 0.22287368377049763\n",
      "Time in min after 175001  tweets: 0.26526919603347776\n",
      "Time in min after 200001  tweets: 0.3065086285273234\n",
      "Time in min total: 0.3234136501948039\n",
      "Time in min before starting first for loop: 5.1657358805338543e-08\n",
      "Time in min after 1  tweets: 1.2469291687011718e-05\n",
      "Time in min after 25001  tweets: 0.035004301865895586\n",
      "Time in min after 50001  tweets: 0.06929828723271687\n",
      "Time in min after 75001  tweets: 0.10434546868006388\n",
      "Time in min after 100001  tweets: 0.13944608370463055\n",
      "Time in min after 125001  tweets: 0.1821918527285258\n",
      "Time in min after 150001  tweets: 0.22387633323669434\n",
      "Time in min after 175001  tweets: 0.2664627552032471\n",
      "Time in min after 200001  tweets: 0.3079224189122518\n",
      "Time in min total: 0.32483073870340984\n",
      "Time in min before starting first for loop: 8.344650268554687e-08\n",
      "Time in min after 1  tweets: 6.735324859619141e-06\n",
      "Time in min after 25001  tweets: 0.03259623448053996\n",
      "Time in min after 50001  tweets: 0.06572908560434977\n",
      "Time in min after 75001  tweets: 0.09914958079655965\n",
      "Time in min after 100001  tweets: 0.1320775310198466\n",
      "Time in min after 125001  tweets: 0.17361761728922526\n",
      "Time in min after 150001  tweets: 0.21472488244374593\n",
      "Time in min after 175001  tweets: 0.25475576321283977\n",
      "Time in min after 200001  tweets: 0.29412871996561685\n",
      "Time in min total: 0.3098848978678385\n",
      "Time in min before starting first for loop: 2.3444493611653645e-07\n",
      "Time in min after 1  tweets: 1.441637674967448e-05\n",
      "Time in min after 25001  tweets: 0.03439921538035075\n",
      "Time in min after 50001  tweets: 0.06756931940714518\n",
      "Time in min after 75001  tweets: 0.10130543311436971\n",
      "Time in min after 100001  tweets: 0.1343284209569295\n",
      "Time in min after 125001  tweets: 0.17505690256754558\n",
      "Time in min after 150001  tweets: 0.21505904992421468\n",
      "Time in min after 175001  tweets: 0.25519610246022545\n",
      "Time in min after 200001  tweets: 0.2957972208658854\n",
      "Time in min total: 0.3111751159032186\n",
      "Time in min before starting first for loop: 3.635883331298828e-06\n",
      "Time in min after 1  tweets: 8.583863576253256e-05\n",
      "Time in min after 25001  tweets: 0.16376915375391643\n",
      "Time in min after 50001  tweets: 0.33275983333587644\n",
      "Time in min after 75001  tweets: 0.49913777112960817\n",
      "Time in min after 100001  tweets: 0.6666138569513956\n",
      "Time in min after 125001  tweets: 0.8682217359542846\n",
      "Time in min after 150001  tweets: 1.070938221613566\n",
      "Time in min after 175001  tweets: 1.2717960556348165\n",
      "Time in min after 200001  tweets: 1.4712692181269327\n",
      "Time in min total: 1.55093963543574\n",
      "Reading english - 1grams ...\n",
      "Time in min before starting first for loop: 0.01388164758682251\n",
      "Time in min after 1  tweets: 0.017032114664713542\n",
      "Time in min after 25001  tweets: 20.19349333445231\n",
      "Time in min after 50001  tweets: 40.48593374490738\n",
      "Time in min after 75001  tweets: 59.45620791514715\n",
      "Time in min after 100001  tweets: 78.07600614627202\n",
      "Time in min after 125001  tweets: 99.36792829831441\n",
      "Time in min after 150001  tweets: 119.6522124171257\n",
      "Time in min after 175001  tweets: 138.66170159578323\n",
      "Time in min after 200001  tweets: 157.25536909898122\n",
      "Time in min total: 164.43695551554362\n",
      "Time in min before starting first for loop: 0.0010034521420796713\n",
      "Time in min after 1  tweets: 0.0010468721389770507\n",
      "Time in min after 25001  tweets: 0.14110540548960368\n",
      "Time in min after 50001  tweets: 0.27995618581771853\n",
      "Time in min after 75001  tweets: 0.42334138552347816\n",
      "Time in min after 100001  tweets: 0.5639538526535034\n",
      "Time in min after 125001  tweets: 0.7303165038426717\n",
      "Time in min after 150001  tweets: 0.8945788502693176\n",
      "Time in min after 175001  tweets: 1.0580472389856974\n",
      "Time in min after 200001  tweets: 1.2217705845832825\n",
      "Time in min total: 1.2869434197743734\n",
      "Time in min before starting first for loop: 9.934107462565105e-08\n",
      "Time in min after 1  tweets: 7.80026117960612e-06\n",
      "Time in min after 25001  tweets: 0.03499529759089152\n",
      "Time in min after 50001  tweets: 0.0696573813756307\n",
      "Time in min after 75001  tweets: 0.1042669177055359\n",
      "Time in min after 100001  tweets: 0.13850518465042114\n",
      "Time in min after 125001  tweets: 0.18059913317362467\n",
      "Time in min after 150001  tweets: 0.22157548268636068\n",
      "Time in min after 175001  tweets: 0.2637664993604024\n",
      "Time in min after 200001  tweets: 0.30549081563949587\n",
      "Time in min total: 0.3221431533495585\n",
      "Time in min before starting first for loop: 1.1523564656575521e-07\n",
      "Time in min after 1  tweets: 1.1797746022542318e-05\n",
      "Time in min after 25001  tweets: 0.03666576941808065\n",
      "Time in min after 50001  tweets: 0.07264928023020427\n",
      "Time in min after 75001  tweets: 0.10947771469751993\n",
      "Time in min after 100001  tweets: 0.14807653427124023\n",
      "Time in min after 125001  tweets: 0.19276991685231526\n",
      "Time in min after 150001  tweets: 0.23616008361180624\n",
      "Time in min after 175001  tweets: 0.27958924770355226\n",
      "Time in min after 200001  tweets: 0.3219693342844645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in min total: 0.3391306519508362\n",
      "Time in min before starting first for loop: 1.0331471761067709e-07\n",
      "Time in min after 1  tweets: 2.296765645345052e-05\n",
      "Time in min after 25001  tweets: 0.03366755247116089\n",
      "Time in min after 50001  tweets: 0.06769651571909586\n",
      "Time in min after 75001  tweets: 0.10239670276641846\n",
      "Time in min after 100001  tweets: 0.1364606499671936\n",
      "Time in min after 125001  tweets: 0.1760465661684672\n",
      "Time in min after 150001  tweets: 0.21609342098236084\n",
      "Time in min after 175001  tweets: 0.2563955863316854\n",
      "Time in min after 200001  tweets: 0.2959631681442261\n",
      "Time in min total: 0.3117439309755961\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for input_ in inputs: \n",
    "        corpus=TO.preprocess_corpus(full_corpus, **input_)\n",
    "        corpuses.append(corpus)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns=[2,3,4]\n",
    "for n in ns: \n",
    "    corpus=TO.creating_n_grams_corpus(n,full_corpus)\n",
    "    corpuses.append(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing all preprocessing techniques: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4701 - acc: 0.7652Epoch 00001: val_loss improved from inf to 0.40993, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 4s 30us/step - loss: 0.4699 - acc: 0.7653 - val_loss: 0.4099 - val_acc: 0.8052\n",
      "Epoch 2/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4091 - acc: 0.8073Epoch 00002: val_loss improved from 0.40993 to 0.39679, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.4090 - acc: 0.8072 - val_loss: 0.3968 - val_acc: 0.8118\n",
      "Epoch 3/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8156Epoch 00003: val_loss improved from 0.39679 to 0.39259, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3957 - acc: 0.8156 - val_loss: 0.3926 - val_acc: 0.8148\n",
      "Epoch 4/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8201Epoch 00004: val_loss improved from 0.39259 to 0.38873, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3876 - acc: 0.8201 - val_loss: 0.3887 - val_acc: 0.8187\n",
      "Epoch 5/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8243Epoch 00005: val_loss improved from 0.38873 to 0.38618, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3803 - acc: 0.8241 - val_loss: 0.3862 - val_acc: 0.8182\n",
      "Epoch 6/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3746 - acc: 0.8267Epoch 00006: val_loss improved from 0.38618 to 0.38460, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3745 - acc: 0.8266 - val_loss: 0.3846 - val_acc: 0.8197\n",
      "Epoch 7/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8296Epoch 00007: val_loss improved from 0.38460 to 0.38364, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3690 - acc: 0.8297 - val_loss: 0.3836 - val_acc: 0.8189\n",
      "Epoch 8/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3642 - acc: 0.8328Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3645 - acc: 0.8326 - val_loss: 0.3842 - val_acc: 0.8195\n",
      "Epoch 9/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3603 - acc: 0.8345Epoch 00009: val_loss improved from 0.38364 to 0.38302, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3604 - acc: 0.8344 - val_loss: 0.3830 - val_acc: 0.8199\n",
      "Epoch 10/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.8370Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3568 - acc: 0.8369 - val_loss: 0.3878 - val_acc: 0.8199\n",
      "Epoch 11/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8397Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3534 - acc: 0.8393 - val_loss: 0.3854 - val_acc: 0.8198\n",
      "Epoch 12/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3496 - acc: 0.8410Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3496 - acc: 0.8411 - val_loss: 0.3865 - val_acc: 0.8203\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 2s 30us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.7664Epoch 00001: val_loss improved from inf to 0.42971, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 3s 19us/step - loss: 0.4645 - acc: 0.7672 - val_loss: 0.4297 - val_acc: 0.7939\n",
      "Epoch 2/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8105Epoch 00002: val_loss improved from 0.42971 to 0.41527, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.4027 - acc: 0.8105 - val_loss: 0.4153 - val_acc: 0.8035\n",
      "Epoch 3/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3901 - acc: 0.8166Epoch 00003: val_loss improved from 0.41527 to 0.41077, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3901 - acc: 0.8165 - val_loss: 0.4108 - val_acc: 0.8040\n",
      "Epoch 4/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3818 - acc: 0.8215Epoch 00004: val_loss improved from 0.41077 to 0.40619, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 11us/step - loss: 0.3817 - acc: 0.8214 - val_loss: 0.4062 - val_acc: 0.8084\n",
      "Epoch 5/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3750 - acc: 0.8266Epoch 00005: val_loss improved from 0.40619 to 0.40319, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3749 - acc: 0.8266 - val_loss: 0.4032 - val_acc: 0.8081\n",
      "Epoch 6/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3685 - acc: 0.8297Epoch 00006: val_loss improved from 0.40319 to 0.40289, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3690 - acc: 0.8293 - val_loss: 0.4029 - val_acc: 0.8082\n",
      "Epoch 7/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8333Epoch 00007: val_loss improved from 0.40289 to 0.40077, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3639 - acc: 0.8331 - val_loss: 0.4008 - val_acc: 0.8061\n",
      "Epoch 8/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3591 - acc: 0.8351Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 11us/step - loss: 0.3589 - acc: 0.8353 - val_loss: 0.4015 - val_acc: 0.8065\n",
      "Epoch 9/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8371Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3547 - acc: 0.8374 - val_loss: 0.4017 - val_acc: 0.8135\n",
      "Epoch 10/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3510 - acc: 0.8399Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3511 - acc: 0.8397 - val_loss: 0.4014 - val_acc: 0.8085\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 2s 35us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4673 - acc: 0.7655Epoch 00001: val_loss improved from inf to 0.42746, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 3s 20us/step - loss: 0.4651 - acc: 0.7670 - val_loss: 0.4275 - val_acc: 0.7951\n",
      "Epoch 2/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4014 - acc: 0.8114Epoch 00002: val_loss improved from 0.42746 to 0.41446, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.4011 - acc: 0.8116 - val_loss: 0.4145 - val_acc: 0.8030\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8188Epoch 00003: val_loss improved from 0.41446 to 0.40798, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3876 - acc: 0.8187 - val_loss: 0.4080 - val_acc: 0.8089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3794 - acc: 0.8237Epoch 00004: val_loss improved from 0.40798 to 0.40560, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 11us/step - loss: 0.3791 - acc: 0.8237 - val_loss: 0.4056 - val_acc: 0.8102\n",
      "Epoch 5/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3726 - acc: 0.8271Epoch 00005: val_loss improved from 0.40560 to 0.40470, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 11us/step - loss: 0.3728 - acc: 0.8270 - val_loss: 0.4047 - val_acc: 0.8100\n",
      "Epoch 6/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3673 - acc: 0.8299Epoch 00006: val_loss improved from 0.40470 to 0.40184, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 11us/step - loss: 0.3672 - acc: 0.8300 - val_loss: 0.4018 - val_acc: 0.8121\n",
      "Epoch 7/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3622 - acc: 0.8333Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 11us/step - loss: 0.3619 - acc: 0.8335 - val_loss: 0.4029 - val_acc: 0.8131\n",
      "Epoch 8/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3575 - acc: 0.8352Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3575 - acc: 0.8353 - val_loss: 0.4019 - val_acc: 0.8116\n",
      "Epoch 9/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3532 - acc: 0.8378Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 11us/step - loss: 0.3530 - acc: 0.8380 - val_loss: 0.4024 - val_acc: 0.8111\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 2s 30us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.4686 - acc: 0.7665Epoch 00001: val_loss improved from inf to 0.40450, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 5s 41us/step - loss: 0.4665 - acc: 0.7681 - val_loss: 0.4045 - val_acc: 0.8096\n",
      "Epoch 2/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8095Epoch 00002: val_loss improved from 0.40450 to 0.39147, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.4046 - acc: 0.8095 - val_loss: 0.3915 - val_acc: 0.8146\n",
      "Epoch 3/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3913 - acc: 0.8177Epoch 00003: val_loss improved from 0.39147 to 0.38730, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3913 - acc: 0.8176 - val_loss: 0.3873 - val_acc: 0.8191\n",
      "Epoch 4/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3829 - acc: 0.8229Epoch 00004: val_loss improved from 0.38730 to 0.38305, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3829 - acc: 0.8230 - val_loss: 0.3831 - val_acc: 0.8196\n",
      "Epoch 5/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3756 - acc: 0.8266Epoch 00005: val_loss improved from 0.38305 to 0.38029, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3755 - acc: 0.8263 - val_loss: 0.3803 - val_acc: 0.8211\n",
      "Epoch 6/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3695 - acc: 0.8302Epoch 00006: val_loss improved from 0.38029 to 0.37894, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3694 - acc: 0.8302 - val_loss: 0.3789 - val_acc: 0.8223\n",
      "Epoch 7/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3635 - acc: 0.8331Epoch 00007: val_loss improved from 0.37894 to 0.37823, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3642 - acc: 0.8327 - val_loss: 0.3782 - val_acc: 0.8225\n",
      "Epoch 8/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3595 - acc: 0.8355Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3597 - acc: 0.8355 - val_loss: 0.3786 - val_acc: 0.8222\n",
      "Epoch 9/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.8377Epoch 00009: val_loss improved from 0.37823 to 0.37794, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3555 - acc: 0.8377 - val_loss: 0.3779 - val_acc: 0.8232\n",
      "Epoch 10/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3512 - acc: 0.8398Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3518 - acc: 0.8393 - val_loss: 0.3814 - val_acc: 0.8212\n",
      "Epoch 11/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3482 - acc: 0.8420Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3482 - acc: 0.8419 - val_loss: 0.3795 - val_acc: 0.8226\n",
      "Epoch 12/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3448 - acc: 0.8440Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3446 - acc: 0.8441 - val_loss: 0.3807 - val_acc: 0.8222\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 2s 34us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.7686Epoch 00001: val_loss improved from inf to 0.42457, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 3s 22us/step - loss: 0.4612 - acc: 0.7692 - val_loss: 0.4246 - val_acc: 0.7979\n",
      "Epoch 2/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3981 - acc: 0.8133Epoch 00002: val_loss improved from 0.42457 to 0.41039, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3981 - acc: 0.8133 - val_loss: 0.4104 - val_acc: 0.8061\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3853 - acc: 0.8197Epoch 00003: val_loss improved from 0.41039 to 0.40518, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3854 - acc: 0.8195 - val_loss: 0.4052 - val_acc: 0.8072\n",
      "Epoch 4/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3769 - acc: 0.8248Epoch 00004: val_loss improved from 0.40518 to 0.40148, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.3768 - acc: 0.8249 - val_loss: 0.4015 - val_acc: 0.8113\n",
      "Epoch 5/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3700 - acc: 0.8288Epoch 00005: val_loss improved from 0.40148 to 0.39805, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 18us/step - loss: 0.3698 - acc: 0.8289 - val_loss: 0.3980 - val_acc: 0.8106\n",
      "Epoch 6/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3636 - acc: 0.8323Epoch 00006: val_loss improved from 0.39805 to 0.39777, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3640 - acc: 0.8322 - val_loss: 0.3978 - val_acc: 0.8117\n",
      "Epoch 7/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3587 - acc: 0.8355Epoch 00007: val_loss improved from 0.39777 to 0.39563, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3589 - acc: 0.8353 - val_loss: 0.3956 - val_acc: 0.8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3537 - acc: 0.8382Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3538 - acc: 0.8381 - val_loss: 0.3958 - val_acc: 0.8107\n",
      "Epoch 9/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3501 - acc: 0.8398Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3497 - acc: 0.8401 - val_loss: 0.3963 - val_acc: 0.8168\n",
      "Epoch 10/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.8421Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3463 - acc: 0.8422 - val_loss: 0.3974 - val_acc: 0.8109\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 2s 35us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.7680Epoch 00001: val_loss improved from inf to 0.42310, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 3s 19us/step - loss: 0.4612 - acc: 0.7694 - val_loss: 0.4231 - val_acc: 0.7981\n",
      "Epoch 2/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3959 - acc: 0.8146Epoch 00002: val_loss improved from 0.42310 to 0.41015, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3960 - acc: 0.8146 - val_loss: 0.4102 - val_acc: 0.8065\n",
      "Epoch 3/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3822 - acc: 0.8219Epoch 00003: val_loss improved from 0.41015 to 0.40368, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3823 - acc: 0.8218 - val_loss: 0.4037 - val_acc: 0.8108\n",
      "Epoch 4/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3741 - acc: 0.8264Epoch 00004: val_loss improved from 0.40368 to 0.40114, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3737 - acc: 0.8266 - val_loss: 0.4011 - val_acc: 0.8131\n",
      "Epoch 5/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3671 - acc: 0.8301Epoch 00005: val_loss improved from 0.40114 to 0.40053, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3672 - acc: 0.8300 - val_loss: 0.4005 - val_acc: 0.8132\n",
      "Epoch 6/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3617 - acc: 0.8337Epoch 00006: val_loss improved from 0.40053 to 0.39731, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3616 - acc: 0.8337 - val_loss: 0.3973 - val_acc: 0.8149\n",
      "Epoch 7/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.8366Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3562 - acc: 0.8367 - val_loss: 0.3983 - val_acc: 0.8146\n",
      "Epoch 8/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3517 - acc: 0.8382Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 11us/step - loss: 0.3517 - acc: 0.8383 - val_loss: 0.3979 - val_acc: 0.8143\n",
      "Epoch 9/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3472 - acc: 0.8413Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3470 - acc: 0.8414 - val_loss: 0.3976 - val_acc: 0.8139\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 2s 34us/step\n",
      "Model:  basic_model_adam\n",
      "0.82% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4662 - acc: 0.7683Epoch 00001: val_loss improved from inf to 0.40440, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 6s 48us/step - loss: 0.4660 - acc: 0.7684 - val_loss: 0.4044 - val_acc: 0.8086\n",
      "Epoch 2/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.4043 - acc: 0.8101Epoch 00002: val_loss improved from 0.40440 to 0.39153, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.4042 - acc: 0.8101 - val_loss: 0.3915 - val_acc: 0.8145\n",
      "Epoch 3/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3908 - acc: 0.8173Epoch 00003: val_loss improved from 0.39153 to 0.38714, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3909 - acc: 0.8172 - val_loss: 0.3871 - val_acc: 0.8185\n",
      "Epoch 4/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.8231Epoch 00004: val_loss improved from 0.38714 to 0.38316, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3825 - acc: 0.8231 - val_loss: 0.3832 - val_acc: 0.8195\n",
      "Epoch 5/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3749 - acc: 0.8269Epoch 00005: val_loss improved from 0.38316 to 0.38041, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3752 - acc: 0.8266 - val_loss: 0.3804 - val_acc: 0.8214\n",
      "Epoch 6/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8304Epoch 00006: val_loss improved from 0.38041 to 0.37899, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3691 - acc: 0.8303 - val_loss: 0.3790 - val_acc: 0.8224\n",
      "Epoch 7/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.8332Epoch 00007: val_loss improved from 0.37899 to 0.37784, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3638 - acc: 0.8330 - val_loss: 0.3778 - val_acc: 0.8224\n",
      "Epoch 8/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3591 - acc: 0.8356Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3592 - acc: 0.8355 - val_loss: 0.3780 - val_acc: 0.8240\n",
      "Epoch 9/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3550 - acc: 0.8377Epoch 00009: val_loss improved from 0.37784 to 0.37771, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3551 - acc: 0.8376 - val_loss: 0.3777 - val_acc: 0.8232\n",
      "Epoch 10/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8399Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3515 - acc: 0.8400 - val_loss: 0.3818 - val_acc: 0.8212\n",
      "Epoch 11/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8419Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3480 - acc: 0.8419 - val_loss: 0.3795 - val_acc: 0.8227\n",
      "Epoch 12/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3441 - acc: 0.8446Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3441 - acc: 0.8447 - val_loss: 0.3804 - val_acc: 0.8224\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 3s 49us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.7697Epoch 00001: val_loss improved from inf to 0.42445, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 4s 29us/step - loss: 0.4608 - acc: 0.7699 - val_loss: 0.4245 - val_acc: 0.7975\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3979 - acc: 0.8133Epoch 00002: val_loss improved from 0.42445 to 0.41017, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3977 - acc: 0.8133 - val_loss: 0.4102 - val_acc: 0.8059\n",
      "Epoch 3/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3852 - acc: 0.8198Epoch 00003: val_loss improved from 0.41017 to 0.40519, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3850 - acc: 0.8197 - val_loss: 0.4052 - val_acc: 0.8077\n",
      "Epoch 4/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3765 - acc: 0.8253Epoch 00004: val_loss improved from 0.40519 to 0.40162, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3765 - acc: 0.8252 - val_loss: 0.4016 - val_acc: 0.8112\n",
      "Epoch 5/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3698 - acc: 0.8291Epoch 00005: val_loss improved from 0.40162 to 0.39798, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3696 - acc: 0.8292 - val_loss: 0.3980 - val_acc: 0.8112\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3636 - acc: 0.8326Epoch 00006: val_loss improved from 0.39798 to 0.39759, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3638 - acc: 0.8325 - val_loss: 0.3976 - val_acc: 0.8113\n",
      "Epoch 7/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3585 - acc: 0.8357Epoch 00007: val_loss improved from 0.39759 to 0.39567, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3588 - acc: 0.8355 - val_loss: 0.3957 - val_acc: 0.8104\n",
      "Epoch 8/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3537 - acc: 0.8376Epoch 00008: val_loss improved from 0.39567 to 0.39540, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3536 - acc: 0.8375 - val_loss: 0.3954 - val_acc: 0.8119\n",
      "Epoch 9/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3496 - acc: 0.8396Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3495 - acc: 0.8397 - val_loss: 0.3960 - val_acc: 0.8167\n",
      "Epoch 10/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3462 - acc: 0.8419Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3460 - acc: 0.8421 - val_loss: 0.3962 - val_acc: 0.8118\n",
      "Epoch 11/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3421 - acc: 0.8446Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3423 - acc: 0.8443 - val_loss: 0.3981 - val_acc: 0.8106\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 2s 36us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.7692Epoch 00001: val_loss improved from inf to 0.42272, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 3s 25us/step - loss: 0.4609 - acc: 0.7695 - val_loss: 0.4227 - val_acc: 0.7988\n",
      "Epoch 2/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3961 - acc: 0.8140Epoch 00002: val_loss improved from 0.42272 to 0.40980, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3958 - acc: 0.8142 - val_loss: 0.4098 - val_acc: 0.8061\n",
      "Epoch 3/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3820 - acc: 0.8220Epoch 00003: val_loss improved from 0.40980 to 0.40311, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3820 - acc: 0.8219 - val_loss: 0.4031 - val_acc: 0.8108\n",
      "Epoch 4/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3737 - acc: 0.8270Epoch 00004: val_loss improved from 0.40311 to 0.40071, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3734 - acc: 0.8271 - val_loss: 0.4007 - val_acc: 0.8132\n",
      "Epoch 5/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.8301Epoch 00005: val_loss improved from 0.40071 to 0.40001, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3669 - acc: 0.8301 - val_loss: 0.4000 - val_acc: 0.8127\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3616 - acc: 0.8334Epoch 00006: val_loss improved from 0.40001 to 0.39697, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3615 - acc: 0.8334 - val_loss: 0.3970 - val_acc: 0.8143\n",
      "Epoch 7/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3564 - acc: 0.8362Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3561 - acc: 0.8363 - val_loss: 0.3980 - val_acc: 0.8155\n",
      "Epoch 8/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8384Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3517 - acc: 0.8385 - val_loss: 0.3974 - val_acc: 0.8137\n",
      "Epoch 9/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3470 - acc: 0.8414Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3471 - acc: 0.8413 - val_loss: 0.3974 - val_acc: 0.8140\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 2s 37us/step\n",
      "Model:  basic_model_adam\n",
      "0.82% (+/- 0.00%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "129024/133332 [============================>.] - ETA: 1s - loss: 0.4723 - acc: 0.7637Epoch 00001: val_loss improved from inf to 0.40985, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 41s 310us/step - loss: 0.4703 - acc: 0.7654 - val_loss: 0.4099 - val_acc: 0.8055\n",
      "Epoch 2/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8076Epoch 00002: val_loss improved from 0.40985 to 0.39695, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.4092 - acc: 0.8075 - val_loss: 0.3970 - val_acc: 0.8113\n",
      "Epoch 3/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3956 - acc: 0.8153Epoch 00003: val_loss improved from 0.39695 to 0.39242, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3959 - acc: 0.8150 - val_loss: 0.3924 - val_acc: 0.8151\n",
      "Epoch 4/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3879 - acc: 0.8201Epoch 00004: val_loss improved from 0.39242 to 0.38886, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3879 - acc: 0.8202 - val_loss: 0.3889 - val_acc: 0.8175\n",
      "Epoch 5/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3805 - acc: 0.8243Epoch 00005: val_loss improved from 0.38886 to 0.38652, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3805 - acc: 0.8240 - val_loss: 0.3865 - val_acc: 0.8179\n",
      "Epoch 6/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.8267- ETA: 1s - loss: Epoch 00006: val_loss improved from 0.38652 to 0.38459, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3747 - acc: 0.8266 - val_loss: 0.3846 - val_acc: 0.8188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3689 - acc: 0.8299Epoch 00007: val_loss improved from 0.38459 to 0.38388, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3692 - acc: 0.8297 - val_loss: 0.3839 - val_acc: 0.8186\n",
      "Epoch 8/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3645 - acc: 0.8331Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3647 - acc: 0.8328 - val_loss: 0.3844 - val_acc: 0.8183\n",
      "Epoch 9/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3605 - acc: 0.8348Epoch 00009: val_loss improved from 0.38388 to 0.38288, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3606 - acc: 0.8346 - val_loss: 0.3829 - val_acc: 0.8199\n",
      "Epoch 10/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3567 - acc: 0.8369Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3569 - acc: 0.8368 - val_loss: 0.3880 - val_acc: 0.8181\n",
      "Epoch 11/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3530 - acc: 0.8395Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3535 - acc: 0.8391 - val_loss: 0.3854 - val_acc: 0.8196\n",
      "Epoch 12/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3499 - acc: 0.8412Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3499 - acc: 0.8413 - val_loss: 0.3866 - val_acc: 0.8197\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 3s 39us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.7665Epoch 00001: val_loss improved from inf to 0.42994, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 4s 27us/step - loss: 0.4649 - acc: 0.7671 - val_loss: 0.4299 - val_acc: 0.7940\n",
      "Epoch 2/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4031 - acc: 0.8103Epoch 00002: val_loss improved from 0.42994 to 0.41518, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.4030 - acc: 0.8103 - val_loss: 0.4152 - val_acc: 0.8032\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8165Epoch 00003: val_loss improved from 0.41518 to 0.41040, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.3904 - acc: 0.8165 - val_loss: 0.4104 - val_acc: 0.8035\n",
      "Epoch 4/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3820 - acc: 0.8216Epoch 00004: val_loss improved from 0.41040 to 0.40569, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3820 - acc: 0.8216 - val_loss: 0.4057 - val_acc: 0.8077\n",
      "Epoch 5/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3753 - acc: 0.8265Epoch 00005: val_loss improved from 0.40569 to 0.40294, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3751 - acc: 0.8266 - val_loss: 0.4029 - val_acc: 0.8081\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8291Epoch 00006: val_loss improved from 0.40294 to 0.40260, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3693 - acc: 0.8291 - val_loss: 0.4026 - val_acc: 0.8079\n",
      "Epoch 7/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8330Epoch 00007: val_loss improved from 0.40260 to 0.40067, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3642 - acc: 0.8331 - val_loss: 0.4007 - val_acc: 0.8124\n",
      "Epoch 8/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3592 - acc: 0.8354Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3592 - acc: 0.8354 - val_loss: 0.4009 - val_acc: 0.8072\n",
      "Epoch 9/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8376Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3550 - acc: 0.8377 - val_loss: 0.4008 - val_acc: 0.8117\n",
      "Epoch 10/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3514 - acc: 0.8397Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3513 - acc: 0.8398 - val_loss: 0.4009 - val_acc: 0.8095\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 3s 42us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4669 - acc: 0.7657Epoch 00001: val_loss improved from inf to 0.42773, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 4s 28us/step - loss: 0.4656 - acc: 0.7667 - val_loss: 0.4277 - val_acc: 0.7949\n",
      "Epoch 2/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4017 - acc: 0.8112Epoch 00002: val_loss improved from 0.42773 to 0.41465, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4013 - acc: 0.8115 - val_loss: 0.4146 - val_acc: 0.8029\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8185Epoch 00003: val_loss improved from 0.41465 to 0.40820, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3878 - acc: 0.8185 - val_loss: 0.4082 - val_acc: 0.8084\n",
      "Epoch 4/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8232Epoch 00004: val_loss improved from 0.40820 to 0.40587, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3794 - acc: 0.8233 - val_loss: 0.4059 - val_acc: 0.8097\n",
      "Epoch 5/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3729 - acc: 0.8269Epoch 00005: val_loss improved from 0.40587 to 0.40484, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3730 - acc: 0.8267 - val_loss: 0.4048 - val_acc: 0.8099\n",
      "Epoch 6/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3676 - acc: 0.8297Epoch 00006: val_loss improved from 0.40484 to 0.40199, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3675 - acc: 0.8298 - val_loss: 0.4020 - val_acc: 0.8122\n",
      "Epoch 7/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3623 - acc: 0.8328Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3622 - acc: 0.8329 - val_loss: 0.4030 - val_acc: 0.8133\n",
      "Epoch 8/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8354Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 3s 20us/step - loss: 0.3577 - acc: 0.8353 - val_loss: 0.4020 - val_acc: 0.8107\n",
      "Epoch 9/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3534 - acc: 0.8378Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3532 - acc: 0.8380 - val_loss: 0.4027 - val_acc: 0.8111\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 4s 54us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.00%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.7653Epoch 00001: val_loss improved from inf to 0.40996, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 9s 64us/step - loss: 0.4699 - acc: 0.7657 - val_loss: 0.4100 - val_acc: 0.8045\n",
      "Epoch 2/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.4093 - acc: 0.8073Epoch 00002: val_loss improved from 0.40996 to 0.39698, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.4092 - acc: 0.8072 - val_loss: 0.3970 - val_acc: 0.8106\n",
      "Epoch 3/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3959 - acc: 0.8156Epoch 00003: val_loss improved from 0.39698 to 0.39283, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3959 - acc: 0.8154 - val_loss: 0.3928 - val_acc: 0.8143\n",
      "Epoch 4/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8203Epoch 00004: val_loss improved from 0.39283 to 0.38892, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3878 - acc: 0.8203 - val_loss: 0.3889 - val_acc: 0.8178\n",
      "Epoch 5/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3805 - acc: 0.8239Epoch 00005: val_loss improved from 0.38892 to 0.38645, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3805 - acc: 0.8238 - val_loss: 0.3865 - val_acc: 0.8181\n",
      "Epoch 6/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.8269Epoch 00006: val_loss improved from 0.38645 to 0.38485, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3747 - acc: 0.8268 - val_loss: 0.3848 - val_acc: 0.8193\n",
      "Epoch 7/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3693 - acc: 0.8298Epoch 00007: val_loss improved from 0.38485 to 0.38431, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3692 - acc: 0.8298 - val_loss: 0.3843 - val_acc: 0.8193\n",
      "Epoch 8/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3645 - acc: 0.8330Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3647 - acc: 0.8329 - val_loss: 0.3848 - val_acc: 0.8193\n",
      "Epoch 9/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3604 - acc: 0.8353Epoch 00009: val_loss improved from 0.38431 to 0.38341, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3606 - acc: 0.8351 - val_loss: 0.3834 - val_acc: 0.8210\n",
      "Epoch 10/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3567 - acc: 0.8373Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3571 - acc: 0.8369 - val_loss: 0.3880 - val_acc: 0.8182\n",
      "Epoch 11/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3536 - acc: 0.8391Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3537 - acc: 0.8390 - val_loss: 0.3857 - val_acc: 0.8193\n",
      "Epoch 12/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3500 - acc: 0.8408Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3498 - acc: 0.8410 - val_loss: 0.3869 - val_acc: 0.8193\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 3s 47us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4663 - acc: 0.7659Epoch 00001: val_loss improved from inf to 0.42974, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 4s 28us/step - loss: 0.4645 - acc: 0.7671 - val_loss: 0.4297 - val_acc: 0.7938\n",
      "Epoch 2/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8105Epoch 00002: val_loss improved from 0.42974 to 0.41539, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.4028 - acc: 0.8105 - val_loss: 0.4154 - val_acc: 0.8045\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3902 - acc: 0.8166Epoch 00003: val_loss improved from 0.41539 to 0.41058, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3902 - acc: 0.8165 - val_loss: 0.4106 - val_acc: 0.8035\n",
      "Epoch 4/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3818 - acc: 0.8218Epoch 00004: val_loss improved from 0.41058 to 0.40621, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3817 - acc: 0.8217 - val_loss: 0.4062 - val_acc: 0.8079\n",
      "Epoch 5/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3751 - acc: 0.8269Epoch 00005: val_loss improved from 0.40621 to 0.40305, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3750 - acc: 0.8269 - val_loss: 0.4031 - val_acc: 0.8081\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3689 - acc: 0.8295Epoch 00006: val_loss improved from 0.40305 to 0.40284, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 17us/step - loss: 0.3691 - acc: 0.8295 - val_loss: 0.4028 - val_acc: 0.8084\n",
      "Epoch 7/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8330Epoch 00007: val_loss improved from 0.40284 to 0.40047, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3641 - acc: 0.8328 - val_loss: 0.4005 - val_acc: 0.8127\n",
      "Epoch 8/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3593 - acc: 0.8350Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3592 - acc: 0.8351 - val_loss: 0.4012 - val_acc: 0.8075\n",
      "Epoch 9/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3554 - acc: 0.8373Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3550 - acc: 0.8375 - val_loss: 0.4011 - val_acc: 0.8134\n",
      "Epoch 10/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3516 - acc: 0.8401Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3514 - acc: 0.8400 - val_loss: 0.4009 - val_acc: 0.8136\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 4s 59us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.7670Epoch 00001: val_loss improved from inf to 0.42747, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 5s 36us/step - loss: 0.4652 - acc: 0.7670 - val_loss: 0.4275 - val_acc: 0.7952\n",
      "Epoch 2/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4014 - acc: 0.8118Epoch 00002: val_loss improved from 0.42747 to 0.41459, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4013 - acc: 0.8118 - val_loss: 0.4146 - val_acc: 0.8032\n",
      "Epoch 3/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3879 - acc: 0.8190Epoch 00003: val_loss improved from 0.41459 to 0.40814, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 3s 20us/step - loss: 0.3879 - acc: 0.8189 - val_loss: 0.4081 - val_acc: 0.8083\n",
      "Epoch 4/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8233Epoch 00004: val_loss improved from 0.40814 to 0.40566, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3794 - acc: 0.8234 - val_loss: 0.4057 - val_acc: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3729 - acc: 0.8271Epoch 00005: val_loss improved from 0.40566 to 0.40463, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3730 - acc: 0.8271 - val_loss: 0.4046 - val_acc: 0.8097\n",
      "Epoch 6/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3676 - acc: 0.8304Epoch 00006: val_loss improved from 0.40463 to 0.40175, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3675 - acc: 0.8305 - val_loss: 0.4018 - val_acc: 0.8125\n",
      "Epoch 7/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3626 - acc: 0.8334Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3623 - acc: 0.8335 - val_loss: 0.4029 - val_acc: 0.8127\n",
      "Epoch 8/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3580 - acc: 0.8347Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3579 - acc: 0.8348 - val_loss: 0.4018 - val_acc: 0.8121\n",
      "Epoch 9/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3534 - acc: 0.8379Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 11us/step - loss: 0.3534 - acc: 0.8381 - val_loss: 0.4026 - val_acc: 0.8118\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 4s 56us/step\n",
      "Model:  basic_model_adam\n",
      "0.82% (+/- 0.00%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.7652Epoch 00001: val_loss improved from inf to 0.40979, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 13s 94us/step - loss: 0.4699 - acc: 0.7653 - val_loss: 0.4098 - val_acc: 0.8053\n",
      "Epoch 2/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.4093 - acc: 0.8071Epoch 00002: val_loss improved from 0.40979 to 0.39667, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 17us/step - loss: 0.4091 - acc: 0.8070 - val_loss: 0.3967 - val_acc: 0.8116\n",
      "Epoch 3/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3959 - acc: 0.8154Epoch 00003: val_loss improved from 0.39667 to 0.39258, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3959 - acc: 0.8153 - val_loss: 0.3926 - val_acc: 0.8149\n",
      "Epoch 4/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3879 - acc: 0.8199Epoch 00004: val_loss improved from 0.39258 to 0.38875, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3879 - acc: 0.8200 - val_loss: 0.3887 - val_acc: 0.8179\n",
      "Epoch 5/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8241Epoch 00005: val_loss improved from 0.38875 to 0.38613, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3806 - acc: 0.8238 - val_loss: 0.3861 - val_acc: 0.8176\n",
      "Epoch 6/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3749 - acc: 0.8266Epoch 00006: val_loss improved from 0.38613 to 0.38446, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3747 - acc: 0.8266 - val_loss: 0.3845 - val_acc: 0.8197\n",
      "Epoch 7/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3694 - acc: 0.8294Epoch 00007: val_loss improved from 0.38446 to 0.38361, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3694 - acc: 0.8294 - val_loss: 0.3836 - val_acc: 0.8185\n",
      "Epoch 8/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3645 - acc: 0.8332Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3648 - acc: 0.8329 - val_loss: 0.3842 - val_acc: 0.8189\n",
      "Epoch 9/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3604 - acc: 0.8349Epoch 00009: val_loss improved from 0.38361 to 0.38289, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3606 - acc: 0.8347 - val_loss: 0.3829 - val_acc: 0.8194\n",
      "Epoch 10/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3567 - acc: 0.8370Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3569 - acc: 0.8369 - val_loss: 0.3880 - val_acc: 0.8177\n",
      "Epoch 11/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3532 - acc: 0.8394Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3534 - acc: 0.8392 - val_loss: 0.3853 - val_acc: 0.8196\n",
      "Epoch 12/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3499 - acc: 0.8407Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 16us/step - loss: 0.3497 - acc: 0.8408 - val_loss: 0.3864 - val_acc: 0.8196\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 4s 56us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4645 - acc: 0.7669Epoch 00001: val_loss improved from inf to 0.42967, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 4s 32us/step - loss: 0.4643 - acc: 0.7671 - val_loss: 0.4297 - val_acc: 0.7940\n",
      "Epoch 2/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4027 - acc: 0.8107Epoch 00002: val_loss improved from 0.42967 to 0.41527, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.4027 - acc: 0.8107 - val_loss: 0.4153 - val_acc: 0.8032\n",
      "Epoch 3/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3903 - acc: 0.8166Epoch 00003: val_loss improved from 0.41527 to 0.41083, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3901 - acc: 0.8165 - val_loss: 0.4108 - val_acc: 0.8040\n",
      "Epoch 4/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3817 - acc: 0.8216Epoch 00004: val_loss improved from 0.41083 to 0.40647, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.3817 - acc: 0.8216 - val_loss: 0.4065 - val_acc: 0.8079\n",
      "Epoch 5/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3750 - acc: 0.8268Epoch 00005: val_loss improved from 0.40647 to 0.40372, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.3749 - acc: 0.8269 - val_loss: 0.4037 - val_acc: 0.8078\n",
      "Epoch 6/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.8300Epoch 00006: val_loss improved from 0.40372 to 0.40331, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3691 - acc: 0.8297 - val_loss: 0.4033 - val_acc: 0.8071\n",
      "Epoch 7/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8333Epoch 00007: val_loss improved from 0.40331 to 0.40130, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3639 - acc: 0.8333 - val_loss: 0.4013 - val_acc: 0.8062\n",
      "Epoch 8/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3590 - acc: 0.8355Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3590 - acc: 0.8355 - val_loss: 0.4017 - val_acc: 0.8066\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8373Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3548 - acc: 0.8376 - val_loss: 0.4021 - val_acc: 0.8128\n",
      "Epoch 10/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3510 - acc: 0.8401Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3511 - acc: 0.8400 - val_loss: 0.4021 - val_acc: 0.8077\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 3s 46us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4668 - acc: 0.7662Epoch 00001: val_loss improved from inf to 0.42742, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 4s 33us/step - loss: 0.4650 - acc: 0.7676 - val_loss: 0.4274 - val_acc: 0.7946\n",
      "Epoch 2/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8118Epoch 00002: val_loss improved from 0.42742 to 0.41444, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.4011 - acc: 0.8119 - val_loss: 0.4144 - val_acc: 0.8033\n",
      "Epoch 3/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3875 - acc: 0.8190Epoch 00003: val_loss improved from 0.41444 to 0.40814, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3876 - acc: 0.8190 - val_loss: 0.4081 - val_acc: 0.8084\n",
      "Epoch 4/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3795 - acc: 0.8236Epoch 00004: val_loss improved from 0.40814 to 0.40571, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3791 - acc: 0.8237 - val_loss: 0.4057 - val_acc: 0.8103\n",
      "Epoch 5/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3729 - acc: 0.8272Epoch 00005: val_loss improved from 0.40571 to 0.40484, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3728 - acc: 0.8271 - val_loss: 0.4048 - val_acc: 0.8102\n",
      "Epoch 6/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3673 - acc: 0.8300Epoch 00006: val_loss improved from 0.40484 to 0.40185, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3672 - acc: 0.8301 - val_loss: 0.4019 - val_acc: 0.8123\n",
      "Epoch 7/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8332Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3620 - acc: 0.8333 - val_loss: 0.4030 - val_acc: 0.8132\n",
      "Epoch 8/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8351Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3576 - acc: 0.8351 - val_loss: 0.4020 - val_acc: 0.8120\n",
      "Epoch 9/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3532 - acc: 0.8380Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3530 - acc: 0.8380 - val_loss: 0.4026 - val_acc: 0.8119\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 3s 47us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.7649Epoch 00001: val_loss improved from inf to 0.40995, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 12s 92us/step - loss: 0.4699 - acc: 0.7653 - val_loss: 0.4100 - val_acc: 0.8051\n",
      "Epoch 2/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8071Epoch 00002: val_loss improved from 0.40995 to 0.39694, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.4090 - acc: 0.8071 - val_loss: 0.3969 - val_acc: 0.8117\n",
      "Epoch 3/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8156Epoch 00003: val_loss improved from 0.39694 to 0.39274, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3957 - acc: 0.8155 - val_loss: 0.3927 - val_acc: 0.8150\n",
      "Epoch 4/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8199Epoch 00004: val_loss improved from 0.39274 to 0.38904, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3877 - acc: 0.8200 - val_loss: 0.3890 - val_acc: 0.8180\n",
      "Epoch 5/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8241Epoch 00005: val_loss improved from 0.38904 to 0.38662, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3804 - acc: 0.8239 - val_loss: 0.3866 - val_acc: 0.8173\n",
      "Epoch 6/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.8266Epoch 00006: val_loss improved from 0.38662 to 0.38499, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3745 - acc: 0.8266 - val_loss: 0.3850 - val_acc: 0.8193\n",
      "Epoch 7/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3686 - acc: 0.8303Epoch 00007: val_loss improved from 0.38499 to 0.38406, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3691 - acc: 0.8299 - val_loss: 0.3841 - val_acc: 0.8188\n",
      "Epoch 8/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3644 - acc: 0.8330Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3646 - acc: 0.8327 - val_loss: 0.3846 - val_acc: 0.8182\n",
      "Epoch 9/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3603 - acc: 0.8344Epoch 00009: val_loss improved from 0.38406 to 0.38338, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3604 - acc: 0.8343 - val_loss: 0.3834 - val_acc: 0.8196\n",
      "Epoch 10/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.8369Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3568 - acc: 0.8367 - val_loss: 0.3880 - val_acc: 0.8179\n",
      "Epoch 11/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8397Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3535 - acc: 0.8396 - val_loss: 0.3857 - val_acc: 0.8201\n",
      "Epoch 12/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3500 - acc: 0.8406Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 18us/step - loss: 0.3498 - acc: 0.8408 - val_loss: 0.3870 - val_acc: 0.8201\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 3s 48us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.7664Epoch 00001: val_loss improved from inf to 0.42974, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 5s 35us/step - loss: 0.4645 - acc: 0.7673 - val_loss: 0.4297 - val_acc: 0.7940\n",
      "Epoch 2/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8106Epoch 00002: val_loss improved from 0.42974 to 0.41536, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4027 - acc: 0.8106 - val_loss: 0.4154 - val_acc: 0.8035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3903 - acc: 0.8165Epoch 00003: val_loss improved from 0.41536 to 0.41075, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3902 - acc: 0.8165 - val_loss: 0.4108 - val_acc: 0.8036\n",
      "Epoch 4/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3818 - acc: 0.8216Epoch 00004: val_loss improved from 0.41075 to 0.40649, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3817 - acc: 0.8215 - val_loss: 0.4065 - val_acc: 0.8081\n",
      "Epoch 5/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3750 - acc: 0.8264Epoch 00005: val_loss improved from 0.40649 to 0.40343, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3749 - acc: 0.8264 - val_loss: 0.4034 - val_acc: 0.8081\n",
      "Epoch 6/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.8296Epoch 00006: val_loss improved from 0.40343 to 0.40338, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.3690 - acc: 0.8295 - val_loss: 0.4034 - val_acc: 0.8081\n",
      "Epoch 7/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8335Epoch 00007: val_loss improved from 0.40338 to 0.40117, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3639 - acc: 0.8334 - val_loss: 0.4012 - val_acc: 0.8068\n",
      "Epoch 8/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3590 - acc: 0.8350Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3590 - acc: 0.8351 - val_loss: 0.4020 - val_acc: 0.8064\n",
      "Epoch 9/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3549 - acc: 0.8375Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3549 - acc: 0.8376 - val_loss: 0.4018 - val_acc: 0.8086\n",
      "Epoch 10/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3512 - acc: 0.8398Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3512 - acc: 0.8397 - val_loss: 0.4015 - val_acc: 0.8091\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 3s 52us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.7657Epoch 00001: val_loss improved from inf to 0.42748, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 5s 34us/step - loss: 0.4652 - acc: 0.7670 - val_loss: 0.4275 - val_acc: 0.7950\n",
      "Epoch 2/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4014 - acc: 0.8115Epoch 00002: val_loss improved from 0.42748 to 0.41458, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4011 - acc: 0.8117 - val_loss: 0.4146 - val_acc: 0.8028\n",
      "Epoch 3/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8187Epoch 00003: val_loss improved from 0.41458 to 0.40800, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3876 - acc: 0.8185 - val_loss: 0.4080 - val_acc: 0.8083\n",
      "Epoch 4/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3794 - acc: 0.8235Epoch 00004: val_loss improved from 0.40800 to 0.40565, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3792 - acc: 0.8235 - val_loss: 0.4056 - val_acc: 0.8102\n",
      "Epoch 5/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3728 - acc: 0.8270Epoch 00005: val_loss improved from 0.40565 to 0.40459, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3728 - acc: 0.8270 - val_loss: 0.4046 - val_acc: 0.8101\n",
      "Epoch 6/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.8300Epoch 00006: val_loss improved from 0.40459 to 0.40174, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3674 - acc: 0.8300 - val_loss: 0.4017 - val_acc: 0.8122\n",
      "Epoch 7/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3622 - acc: 0.8334Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3621 - acc: 0.8335 - val_loss: 0.4028 - val_acc: 0.8131\n",
      "Epoch 8/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8350Epoch 00008: val_loss improved from 0.40174 to 0.40172, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3576 - acc: 0.8351 - val_loss: 0.4017 - val_acc: 0.8118\n",
      "Epoch 9/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8379Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3531 - acc: 0.8380 - val_loss: 0.4021 - val_acc: 0.8116\n",
      "Epoch 10/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3493 - acc: 0.8398Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3495 - acc: 0.8397 - val_loss: 0.4029 - val_acc: 0.8132\n",
      "Epoch 11/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3458 - acc: 0.8419Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3460 - acc: 0.8418 - val_loss: 0.4039 - val_acc: 0.8117\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 3s 49us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.7653Epoch 00001: val_loss improved from inf to 0.40981, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 56s 416us/step - loss: 0.4699 - acc: 0.7654 - val_loss: 0.4098 - val_acc: 0.8054\n",
      "Epoch 2/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8073Epoch 00002: val_loss improved from 0.40981 to 0.39675, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4090 - acc: 0.8073 - val_loss: 0.3968 - val_acc: 0.8118\n",
      "Epoch 3/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8155Epoch 00003: val_loss improved from 0.39675 to 0.39265, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3957 - acc: 0.8154 - val_loss: 0.3927 - val_acc: 0.8146\n",
      "Epoch 4/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8204Epoch 00004: val_loss improved from 0.39265 to 0.38871, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3876 - acc: 0.8204 - val_loss: 0.3887 - val_acc: 0.8179\n",
      "Epoch 5/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3803 - acc: 0.8244Epoch 00005: val_loss improved from 0.38871 to 0.38619, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3802 - acc: 0.8241 - val_loss: 0.3862 - val_acc: 0.8177\n",
      "Epoch 6/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3744 - acc: 0.8268Epoch 00006: val_loss improved from 0.38619 to 0.38465, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3744 - acc: 0.8269 - val_loss: 0.3846 - val_acc: 0.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.8302Epoch 00007: val_loss improved from 0.38465 to 0.38377, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3689 - acc: 0.8300 - val_loss: 0.3838 - val_acc: 0.8188\n",
      "Epoch 8/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8325Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3644 - acc: 0.8322 - val_loss: 0.3843 - val_acc: 0.8192\n",
      "Epoch 9/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3601 - acc: 0.8344Epoch 00009: val_loss improved from 0.38377 to 0.38299, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3603 - acc: 0.8344 - val_loss: 0.3830 - val_acc: 0.8198\n",
      "Epoch 10/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.8369Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3566 - acc: 0.8369 - val_loss: 0.3877 - val_acc: 0.8178\n",
      "Epoch 11/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3532 - acc: 0.8394Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3532 - acc: 0.8394 - val_loss: 0.3856 - val_acc: 0.8197\n",
      "Epoch 12/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.8413Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3494 - acc: 0.8414 - val_loss: 0.3866 - val_acc: 0.8202\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 4s 55us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4662 - acc: 0.7661Epoch 00001: val_loss improved from inf to 0.42965, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 5s 39us/step - loss: 0.4644 - acc: 0.7674 - val_loss: 0.4296 - val_acc: 0.7939\n",
      "Epoch 2/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8106Epoch 00002: val_loss improved from 0.42965 to 0.41526, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.4026 - acc: 0.8105 - val_loss: 0.4153 - val_acc: 0.8036\n",
      "Epoch 3/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3901 - acc: 0.8167Epoch 00003: val_loss improved from 0.41526 to 0.41080, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3901 - acc: 0.8167 - val_loss: 0.4108 - val_acc: 0.8039\n",
      "Epoch 4/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3817 - acc: 0.8216Epoch 00004: val_loss improved from 0.41080 to 0.40633, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3817 - acc: 0.8216 - val_loss: 0.4063 - val_acc: 0.8078\n",
      "Epoch 5/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3749 - acc: 0.8265Epoch 00005: val_loss improved from 0.40633 to 0.40345, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3748 - acc: 0.8266 - val_loss: 0.4034 - val_acc: 0.8083\n",
      "Epoch 6/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3688 - acc: 0.8298Epoch 00006: val_loss improved from 0.40345 to 0.40270, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3689 - acc: 0.8297 - val_loss: 0.4027 - val_acc: 0.8085\n",
      "Epoch 7/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3636 - acc: 0.8336Epoch 00007: val_loss improved from 0.40270 to 0.40065, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3638 - acc: 0.8334 - val_loss: 0.4006 - val_acc: 0.8073\n",
      "Epoch 8/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3588 - acc: 0.8354Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3588 - acc: 0.8354 - val_loss: 0.4017 - val_acc: 0.8069\n",
      "Epoch 9/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8376Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3547 - acc: 0.8379 - val_loss: 0.4016 - val_acc: 0.8139\n",
      "Epoch 10/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.8399Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3510 - acc: 0.8398 - val_loss: 0.4013 - val_acc: 0.8091\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 4s 53us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.7666Epoch 00001: val_loss improved from inf to 0.42731, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 5s 40us/step - loss: 0.4651 - acc: 0.7672 - val_loss: 0.4273 - val_acc: 0.7952\n",
      "Epoch 2/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8114Epoch 00002: val_loss improved from 0.42731 to 0.41437, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4010 - acc: 0.8116 - val_loss: 0.4144 - val_acc: 0.8032\n",
      "Epoch 3/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8186Epoch 00003: val_loss improved from 0.41437 to 0.40785, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3875 - acc: 0.8184 - val_loss: 0.4078 - val_acc: 0.8088\n",
      "Epoch 4/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8240Epoch 00004: val_loss improved from 0.40785 to 0.40542, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3791 - acc: 0.8240 - val_loss: 0.4054 - val_acc: 0.8097\n",
      "Epoch 5/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3728 - acc: 0.8271Epoch 00005: val_loss improved from 0.40542 to 0.40431, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3727 - acc: 0.8271 - val_loss: 0.4043 - val_acc: 0.8102\n",
      "Epoch 6/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.8301Epoch 00006: val_loss improved from 0.40431 to 0.40152, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3672 - acc: 0.8302 - val_loss: 0.4015 - val_acc: 0.8120\n",
      "Epoch 7/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3622 - acc: 0.8332Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3619 - acc: 0.8334 - val_loss: 0.4026 - val_acc: 0.8134\n",
      "Epoch 8/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3573 - acc: 0.8352Epoch 00008: val_loss improved from 0.40152 to 0.40141, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3574 - acc: 0.8352 - val_loss: 0.4014 - val_acc: 0.8117\n",
      "Epoch 9/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3531 - acc: 0.8375Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3529 - acc: 0.8376 - val_loss: 0.4020 - val_acc: 0.8115\n",
      "Epoch 10/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3491 - acc: 0.8398Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3494 - acc: 0.8396 - val_loss: 0.4029 - val_acc: 0.8128\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3460 - acc: 0.8418Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3460 - acc: 0.8418 - val_loss: 0.4037 - val_acc: 0.8115\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 4s 57us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.7640Epoch 00001: val_loss improved from inf to 0.40993, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 15s 111us/step - loss: 0.4699 - acc: 0.7653 - val_loss: 0.4099 - val_acc: 0.8052\n",
      "Epoch 2/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4091 - acc: 0.8073Epoch 00002: val_loss improved from 0.40993 to 0.39679, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4090 - acc: 0.8072 - val_loss: 0.3968 - val_acc: 0.8118\n",
      "Epoch 3/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8156Epoch 00003: val_loss improved from 0.39679 to 0.39259, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3957 - acc: 0.8156 - val_loss: 0.3926 - val_acc: 0.8148\n",
      "Epoch 4/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8202Epoch 00004: val_loss improved from 0.39259 to 0.38873, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3876 - acc: 0.8201 - val_loss: 0.3887 - val_acc: 0.8187\n",
      "Epoch 5/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3803 - acc: 0.8242Epoch 00005: val_loss improved from 0.38873 to 0.38618, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3803 - acc: 0.8241 - val_loss: 0.3862 - val_acc: 0.8182\n",
      "Epoch 6/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3746 - acc: 0.8267Epoch 00006: val_loss improved from 0.38618 to 0.38460, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3745 - acc: 0.8266 - val_loss: 0.3846 - val_acc: 0.8197\n",
      "Epoch 7/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8296Epoch 00007: val_loss improved from 0.38460 to 0.38364, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3690 - acc: 0.8297 - val_loss: 0.3836 - val_acc: 0.8189\n",
      "Epoch 8/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8329Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3645 - acc: 0.8326 - val_loss: 0.3842 - val_acc: 0.8195\n",
      "Epoch 9/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3602 - acc: 0.8345Epoch 00009: val_loss improved from 0.38364 to 0.38302, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3604 - acc: 0.8344 - val_loss: 0.3830 - val_acc: 0.8199\n",
      "Epoch 10/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.8371Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3568 - acc: 0.8369 - val_loss: 0.3878 - val_acc: 0.8199\n",
      "Epoch 11/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3534 - acc: 0.8393Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3534 - acc: 0.8393 - val_loss: 0.3854 - val_acc: 0.8198\n",
      "Epoch 12/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3496 - acc: 0.8411Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3496 - acc: 0.8411 - val_loss: 0.3865 - val_acc: 0.8203\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 4s 54us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.7670Epoch 00001: val_loss improved from inf to 0.42971, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 5s 36us/step - loss: 0.4645 - acc: 0.7672 - val_loss: 0.4297 - val_acc: 0.7939\n",
      "Epoch 2/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8105Epoch 00002: val_loss improved from 0.42971 to 0.41527, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.4027 - acc: 0.8105 - val_loss: 0.4153 - val_acc: 0.8035\n",
      "Epoch 3/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3903 - acc: 0.8165Epoch 00003: val_loss improved from 0.41527 to 0.41077, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3901 - acc: 0.8165 - val_loss: 0.4108 - val_acc: 0.8040\n",
      "Epoch 4/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3818 - acc: 0.8215Epoch 00004: val_loss improved from 0.41077 to 0.40619, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3817 - acc: 0.8214 - val_loss: 0.4062 - val_acc: 0.8084\n",
      "Epoch 5/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3750 - acc: 0.8265Epoch 00005: val_loss improved from 0.40619 to 0.40319, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3749 - acc: 0.8266 - val_loss: 0.4032 - val_acc: 0.8081\n",
      "Epoch 6/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3689 - acc: 0.8294Epoch 00006: val_loss improved from 0.40319 to 0.40289, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3690 - acc: 0.8293 - val_loss: 0.4029 - val_acc: 0.8082\n",
      "Epoch 7/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8331Epoch 00007: val_loss improved from 0.40289 to 0.40077, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3639 - acc: 0.8331 - val_loss: 0.4008 - val_acc: 0.8061\n",
      "Epoch 8/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3590 - acc: 0.8352Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3589 - acc: 0.8353 - val_loss: 0.4015 - val_acc: 0.8065\n",
      "Epoch 9/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8371Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3547 - acc: 0.8374 - val_loss: 0.4017 - val_acc: 0.8135\n",
      "Epoch 10/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3511 - acc: 0.8397Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3511 - acc: 0.8397 - val_loss: 0.4014 - val_acc: 0.8085\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 4s 54us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4673 - acc: 0.7655Epoch 00001: val_loss improved from inf to 0.42746, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 5s 38us/step - loss: 0.4651 - acc: 0.7670 - val_loss: 0.4275 - val_acc: 0.7951\n",
      "Epoch 2/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8115Epoch 00002: val_loss improved from 0.42746 to 0.41446, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.4011 - acc: 0.8116 - val_loss: 0.4145 - val_acc: 0.8030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8188Epoch 00003: val_loss improved from 0.41446 to 0.40798, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3876 - acc: 0.8187 - val_loss: 0.4080 - val_acc: 0.8089\n",
      "Epoch 4/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3796 - acc: 0.8236Epoch 00004: val_loss improved from 0.40798 to 0.40560, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3791 - acc: 0.8237 - val_loss: 0.4056 - val_acc: 0.8102\n",
      "Epoch 5/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3728 - acc: 0.8270Epoch 00005: val_loss improved from 0.40560 to 0.40470, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3728 - acc: 0.8270 - val_loss: 0.4047 - val_acc: 0.8100\n",
      "Epoch 6/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3673 - acc: 0.8300Epoch 00006: val_loss improved from 0.40470 to 0.40184, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3672 - acc: 0.8300 - val_loss: 0.4018 - val_acc: 0.8121\n",
      "Epoch 7/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3620 - acc: 0.8335Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3619 - acc: 0.8335 - val_loss: 0.4029 - val_acc: 0.8131\n",
      "Epoch 8/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3575 - acc: 0.8352Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3575 - acc: 0.8353 - val_loss: 0.4019 - val_acc: 0.8116\n",
      "Epoch 9/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3531 - acc: 0.8379Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3530 - acc: 0.8380 - val_loss: 0.4024 - val_acc: 0.8111\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 4s 55us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.7650Epoch 00001: val_loss improved from inf to 0.40980, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 54s 407us/step - loss: 0.4699 - acc: 0.7654 - val_loss: 0.4098 - val_acc: 0.8060\n",
      "Epoch 2/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.4093 - acc: 0.8069Epoch 00002: val_loss improved from 0.40980 to 0.39697, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.4091 - acc: 0.8069 - val_loss: 0.3970 - val_acc: 0.8115\n",
      "Epoch 3/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3958 - acc: 0.8151Epoch 00003: val_loss improved from 0.39697 to 0.39286, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3959 - acc: 0.8151 - val_loss: 0.3929 - val_acc: 0.8136\n",
      "Epoch 4/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8201Epoch 00004: val_loss improved from 0.39286 to 0.38876, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3877 - acc: 0.8201 - val_loss: 0.3888 - val_acc: 0.8165\n",
      "Epoch 5/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3804 - acc: 0.8242Epoch 00005: val_loss improved from 0.38876 to 0.38637, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3803 - acc: 0.8240 - val_loss: 0.3864 - val_acc: 0.8167\n",
      "Epoch 6/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3745 - acc: 0.8275Epoch 00006: val_loss improved from 0.38637 to 0.38451, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3745 - acc: 0.8275 - val_loss: 0.3845 - val_acc: 0.8177\n",
      "Epoch 7/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3689 - acc: 0.8302Epoch 00007: val_loss improved from 0.38451 to 0.38364, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3691 - acc: 0.8300 - val_loss: 0.3836 - val_acc: 0.8189\n",
      "Epoch 8/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8333Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3644 - acc: 0.8331 - val_loss: 0.3844 - val_acc: 0.8186\n",
      "Epoch 9/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3602 - acc: 0.8349Epoch 00009: val_loss improved from 0.38364 to 0.38304, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3604 - acc: 0.8348 - val_loss: 0.3830 - val_acc: 0.8205\n",
      "Epoch 10/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3563 - acc: 0.8369Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3566 - acc: 0.8367 - val_loss: 0.3877 - val_acc: 0.8181\n",
      "Epoch 11/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3526 - acc: 0.8397Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3531 - acc: 0.8393 - val_loss: 0.3854 - val_acc: 0.8191\n",
      "Epoch 12/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3492 - acc: 0.8408Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3492 - acc: 0.8409 - val_loss: 0.3866 - val_acc: 0.8191\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 4s 60us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.7667Epoch 00001: val_loss improved from inf to 0.43005, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 6s 45us/step - loss: 0.4645 - acc: 0.7673 - val_loss: 0.4301 - val_acc: 0.7937\n",
      "Epoch 2/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.8106Epoch 00002: val_loss improved from 0.43005 to 0.41536, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4029 - acc: 0.8106 - val_loss: 0.4154 - val_acc: 0.8032\n",
      "Epoch 3/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3905 - acc: 0.8162Epoch 00003: val_loss improved from 0.41536 to 0.41084, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3902 - acc: 0.8164 - val_loss: 0.4108 - val_acc: 0.8038\n",
      "Epoch 4/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3817 - acc: 0.8219Epoch 00004: val_loss improved from 0.41084 to 0.40692, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3817 - acc: 0.8218 - val_loss: 0.4069 - val_acc: 0.8089\n",
      "Epoch 5/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.8268Epoch 00005: val_loss improved from 0.40692 to 0.40381, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3748 - acc: 0.8268 - val_loss: 0.4038 - val_acc: 0.8084\n",
      "Epoch 6/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3685 - acc: 0.8300Epoch 00006: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.3689 - acc: 0.8296 - val_loss: 0.4042 - val_acc: 0.8077\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3636 - acc: 0.8333Epoch 00007: val_loss improved from 0.40381 to 0.40226, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3637 - acc: 0.8331 - val_loss: 0.4023 - val_acc: 0.8063\n",
      "Epoch 8/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3587 - acc: 0.8358Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3586 - acc: 0.8358 - val_loss: 0.4028 - val_acc: 0.8067\n",
      "Epoch 9/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3545 - acc: 0.8379Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3545 - acc: 0.8380 - val_loss: 0.4030 - val_acc: 0.8071\n",
      "Epoch 10/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3508 - acc: 0.8400Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3508 - acc: 0.8399 - val_loss: 0.4031 - val_acc: 0.8084\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 4s 56us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.7670Epoch 00001: val_loss improved from inf to 0.42784, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 6s 43us/step - loss: 0.4650 - acc: 0.7675 - val_loss: 0.4278 - val_acc: 0.7952\n",
      "Epoch 2/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4010 - acc: 0.8113Epoch 00002: val_loss improved from 0.42784 to 0.41481, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4011 - acc: 0.8113 - val_loss: 0.4148 - val_acc: 0.8038\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3875 - acc: 0.8184Epoch 00003: val_loss improved from 0.41481 to 0.40840, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3876 - acc: 0.8183 - val_loss: 0.4084 - val_acc: 0.8083\n",
      "Epoch 4/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3795 - acc: 0.8233Epoch 00004: val_loss improved from 0.40840 to 0.40605, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3791 - acc: 0.8234 - val_loss: 0.4061 - val_acc: 0.8102\n",
      "Epoch 5/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3727 - acc: 0.8272Epoch 00005: val_loss improved from 0.40605 to 0.40488, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3727 - acc: 0.8272 - val_loss: 0.4049 - val_acc: 0.8099\n",
      "Epoch 6/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3672 - acc: 0.8303Epoch 00006: val_loss improved from 0.40488 to 0.40205, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3671 - acc: 0.8303 - val_loss: 0.4020 - val_acc: 0.8118\n",
      "Epoch 7/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3621 - acc: 0.8330Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3618 - acc: 0.8331 - val_loss: 0.4033 - val_acc: 0.8125\n",
      "Epoch 8/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8353Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3573 - acc: 0.8354 - val_loss: 0.4021 - val_acc: 0.8116\n",
      "Epoch 9/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8378Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3529 - acc: 0.8377 - val_loss: 0.4030 - val_acc: 0.8112\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 4s 59us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.4919 - acc: 0.7492Epoch 00001: val_loss improved from inf to 0.43217, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 17s 130us/step - loss: 0.4896 - acc: 0.7511 - val_loss: 0.4322 - val_acc: 0.7870\n",
      "Epoch 2/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.4290 - acc: 0.7946Epoch 00002: val_loss improved from 0.43217 to 0.41715, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4288 - acc: 0.7947 - val_loss: 0.4172 - val_acc: 0.7947\n",
      "Epoch 3/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.4140 - acc: 0.8041Epoch 00003: val_loss improved from 0.41715 to 0.41319, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4137 - acc: 0.8043 - val_loss: 0.4132 - val_acc: 0.7987\n",
      "Epoch 4/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4048 - acc: 0.8094Epoch 00004: val_loss improved from 0.41319 to 0.40683, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4048 - acc: 0.8094 - val_loss: 0.4068 - val_acc: 0.8048\n",
      "Epoch 5/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3967 - acc: 0.8149Epoch 00005: val_loss improved from 0.40683 to 0.40416, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3967 - acc: 0.8146 - val_loss: 0.4042 - val_acc: 0.8069\n",
      "Epoch 6/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3905 - acc: 0.8181Epoch 00006: val_loss improved from 0.40416 to 0.40126, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3904 - acc: 0.8181 - val_loss: 0.4013 - val_acc: 0.8093\n",
      "Epoch 7/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3845 - acc: 0.8211Epoch 00007: val_loss improved from 0.40126 to 0.40052, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3844 - acc: 0.8212 - val_loss: 0.4005 - val_acc: 0.8096\n",
      "Epoch 8/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3794 - acc: 0.8237Epoch 00008: val_loss improved from 0.40052 to 0.40051, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3796 - acc: 0.8236 - val_loss: 0.4005 - val_acc: 0.8088\n",
      "Epoch 9/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3748 - acc: 0.8272Epoch 00009: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3750 - acc: 0.8270 - val_loss: 0.4012 - val_acc: 0.8086\n",
      "Epoch 10/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3706 - acc: 0.8292Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3711 - acc: 0.8289 - val_loss: 0.4037 - val_acc: 0.8083\n",
      "Epoch 11/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3675 - acc: 0.8317Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3674 - acc: 0.8317 - val_loss: 0.4022 - val_acc: 0.8095\n",
      "Epoch 00011: early stopping\n",
      "66668/66668 [==============================] - 4s 57us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4869 - acc: 0.7502Epoch 00001: val_loss improved from inf to 0.44865, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 5s 41us/step - loss: 0.4851 - acc: 0.7516 - val_loss: 0.4487 - val_acc: 0.7798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4227 - acc: 0.7964Epoch 00002: val_loss improved from 0.44865 to 0.43320, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.4225 - acc: 0.7965 - val_loss: 0.4332 - val_acc: 0.7891\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4078 - acc: 0.8057Epoch 00003: val_loss improved from 0.43320 to 0.42713, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.4078 - acc: 0.8058 - val_loss: 0.4271 - val_acc: 0.7927\n",
      "Epoch 4/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3979 - acc: 0.8117Epoch 00004: val_loss improved from 0.42713 to 0.42207, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3979 - acc: 0.8115 - val_loss: 0.4221 - val_acc: 0.8009\n",
      "Epoch 5/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3906 - acc: 0.8157Epoch 00005: val_loss improved from 0.42207 to 0.41838, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3905 - acc: 0.8159 - val_loss: 0.4184 - val_acc: 0.8010\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.8206Epoch 00006: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3832 - acc: 0.8204 - val_loss: 0.4194 - val_acc: 0.8018\n",
      "Epoch 7/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8232Epoch 00007: val_loss improved from 0.41838 to 0.41652, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3779 - acc: 0.8232 - val_loss: 0.4165 - val_acc: 0.8025\n",
      "Epoch 8/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3726 - acc: 0.8263Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3725 - acc: 0.8263 - val_loss: 0.4171 - val_acc: 0.8018\n",
      "Epoch 9/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3679 - acc: 0.8291Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3677 - acc: 0.8291 - val_loss: 0.4171 - val_acc: 0.8031\n",
      "Epoch 10/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8315Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3639 - acc: 0.8316 - val_loss: 0.4175 - val_acc: 0.8048\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 5s 68us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4863 - acc: 0.7500Epoch 00001: val_loss improved from inf to 0.44904, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 7s 50us/step - loss: 0.4850 - acc: 0.7509 - val_loss: 0.4490 - val_acc: 0.7806\n",
      "Epoch 2/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4211 - acc: 0.7982Epoch 00002: val_loss improved from 0.44904 to 0.43359, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.4212 - acc: 0.7981 - val_loss: 0.4336 - val_acc: 0.7903\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4054 - acc: 0.8075Epoch 00003: val_loss improved from 0.43359 to 0.42554, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.4054 - acc: 0.8076 - val_loss: 0.4255 - val_acc: 0.7968\n",
      "Epoch 4/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3956 - acc: 0.8133Epoch 00004: val_loss improved from 0.42554 to 0.42357, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 18us/step - loss: 0.3954 - acc: 0.8134 - val_loss: 0.4236 - val_acc: 0.8004\n",
      "Epoch 5/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3880 - acc: 0.8171Epoch 00005: val_loss improved from 0.42357 to 0.42104, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 18us/step - loss: 0.3883 - acc: 0.8170 - val_loss: 0.4210 - val_acc: 0.8001\n",
      "Epoch 6/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.8210Epoch 00006: val_loss improved from 0.42104 to 0.41829, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3816 - acc: 0.8209 - val_loss: 0.4183 - val_acc: 0.8025\n",
      "Epoch 7/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3761 - acc: 0.8236Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3760 - acc: 0.8237 - val_loss: 0.4198 - val_acc: 0.8003\n",
      "Epoch 8/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3706 - acc: 0.8269Epoch 00008: val_loss improved from 0.41829 to 0.41768, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3707 - acc: 0.8268 - val_loss: 0.4177 - val_acc: 0.8032\n",
      "Epoch 9/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.8290Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3660 - acc: 0.8291 - val_loss: 0.4190 - val_acc: 0.8027\n",
      "Epoch 10/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3622 - acc: 0.8314Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3624 - acc: 0.8313 - val_loss: 0.4204 - val_acc: 0.8012\n",
      "Epoch 11/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3584 - acc: 0.8337Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3584 - acc: 0.8336 - val_loss: 0.4201 - val_acc: 0.8027\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 4s 59us/step\n",
      "Model:  basic_model_adam\n",
      "0.80% (+/- 0.00%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.7671Epoch 00001: val_loss improved from inf to 0.41113, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 19s 143us/step - loss: 0.4683 - acc: 0.7671 - val_loss: 0.4111 - val_acc: 0.8021\n",
      "Epoch 2/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8073Epoch 00002: val_loss improved from 0.41113 to 0.39805, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4090 - acc: 0.8073 - val_loss: 0.3980 - val_acc: 0.8114\n",
      "Epoch 3/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3952 - acc: 0.8151Epoch 00003: val_loss improved from 0.39805 to 0.39366, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3954 - acc: 0.8149 - val_loss: 0.3937 - val_acc: 0.8155\n",
      "Epoch 4/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3874 - acc: 0.8205Epoch 00004: val_loss improved from 0.39366 to 0.38899, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3874 - acc: 0.8205 - val_loss: 0.3890 - val_acc: 0.8169\n",
      "Epoch 5/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3799 - acc: 0.8248Epoch 00005: val_loss improved from 0.38899 to 0.38723, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3797 - acc: 0.8247 - val_loss: 0.3872 - val_acc: 0.8186\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3738 - acc: 0.8275Epoch 00006: val_loss improved from 0.38723 to 0.38639, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3736 - acc: 0.8276 - val_loss: 0.3864 - val_acc: 0.8181\n",
      "Epoch 7/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3683 - acc: 0.8305Epoch 00007: val_loss improved from 0.38639 to 0.38487, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3685 - acc: 0.8303 - val_loss: 0.3849 - val_acc: 0.8196\n",
      "Epoch 8/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3635 - acc: 0.8333Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3636 - acc: 0.8333 - val_loss: 0.3861 - val_acc: 0.8187\n",
      "Epoch 9/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3596 - acc: 0.8356Epoch 00009: val_loss improved from 0.38487 to 0.38472, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3597 - acc: 0.8356 - val_loss: 0.3847 - val_acc: 0.8215\n",
      "Epoch 10/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.3554 - acc: 0.8371Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3563 - acc: 0.8365 - val_loss: 0.3891 - val_acc: 0.8166\n",
      "Epoch 11/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3523 - acc: 0.8397Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3523 - acc: 0.8398 - val_loss: 0.3864 - val_acc: 0.8187\n",
      "Epoch 12/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3488 - acc: 0.8414Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3489 - acc: 0.8414 - val_loss: 0.3874 - val_acc: 0.8202\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 4s 58us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.7684Epoch 00001: val_loss improved from inf to 0.42858, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 6s 43us/step - loss: 0.4630 - acc: 0.7685 - val_loss: 0.4286 - val_acc: 0.7948\n",
      "Epoch 2/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4027 - acc: 0.8098Epoch 00002: val_loss improved from 0.42858 to 0.41505, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.4027 - acc: 0.8098 - val_loss: 0.4151 - val_acc: 0.8033\n",
      "Epoch 3/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3900 - acc: 0.8170Epoch 00003: val_loss improved from 0.41505 to 0.41031, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3900 - acc: 0.8170 - val_loss: 0.4103 - val_acc: 0.8045\n",
      "Epoch 4/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3814 - acc: 0.8220Epoch 00004: val_loss improved from 0.41031 to 0.40565, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3813 - acc: 0.8220 - val_loss: 0.4056 - val_acc: 0.8080\n",
      "Epoch 5/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3744 - acc: 0.8262Epoch 00005: val_loss improved from 0.40565 to 0.40395, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3745 - acc: 0.8262 - val_loss: 0.4040 - val_acc: 0.8085\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3685 - acc: 0.8297Epoch 00006: val_loss improved from 0.40395 to 0.40163, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3687 - acc: 0.8295 - val_loss: 0.4016 - val_acc: 0.8079\n",
      "Epoch 7/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8322Epoch 00007: val_loss improved from 0.40163 to 0.40050, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3637 - acc: 0.8323 - val_loss: 0.4005 - val_acc: 0.8088\n",
      "Epoch 8/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3588 - acc: 0.8354Epoch 00008: val_loss improved from 0.40050 to 0.40044, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3588 - acc: 0.8354 - val_loss: 0.4004 - val_acc: 0.8084\n",
      "Epoch 9/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3547 - acc: 0.8378Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3544 - acc: 0.8379 - val_loss: 0.4009 - val_acc: 0.8138\n",
      "Epoch 10/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3512 - acc: 0.8388Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3512 - acc: 0.8388 - val_loss: 0.4016 - val_acc: 0.8095\n",
      "Epoch 11/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3475 - acc: 0.8413Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3475 - acc: 0.8414 - val_loss: 0.4007 - val_acc: 0.8134\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 4s 62us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.7675Epoch 00001: val_loss improved from inf to 0.42688, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 6s 45us/step - loss: 0.4639 - acc: 0.7678 - val_loss: 0.4269 - val_acc: 0.7948\n",
      "Epoch 2/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4019 - acc: 0.8101Epoch 00002: val_loss improved from 0.42688 to 0.41284, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4017 - acc: 0.8102 - val_loss: 0.4128 - val_acc: 0.8044\n",
      "Epoch 3/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3879 - acc: 0.8188Epoch 00003: val_loss improved from 0.41284 to 0.40725, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3881 - acc: 0.8186 - val_loss: 0.4072 - val_acc: 0.8091\n",
      "Epoch 4/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3794 - acc: 0.8233Epoch 00004: val_loss improved from 0.40725 to 0.40387, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3791 - acc: 0.8234 - val_loss: 0.4039 - val_acc: 0.8100\n",
      "Epoch 5/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3724 - acc: 0.8272Epoch 00005: val_loss improved from 0.40387 to 0.40182, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3725 - acc: 0.8270 - val_loss: 0.4018 - val_acc: 0.8110\n",
      "Epoch 6/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.8310Epoch 00006: val_loss improved from 0.40182 to 0.39909, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3668 - acc: 0.8310 - val_loss: 0.3991 - val_acc: 0.8120\n",
      "Epoch 7/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3616 - acc: 0.8332Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3613 - acc: 0.8336 - val_loss: 0.4007 - val_acc: 0.8129\n",
      "Epoch 8/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3564 - acc: 0.8359Epoch 00008: val_loss improved from 0.39909 to 0.39830, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3564 - acc: 0.8360 - val_loss: 0.3983 - val_acc: 0.8129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3521 - acc: 0.8391Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3520 - acc: 0.8392 - val_loss: 0.3992 - val_acc: 0.8131\n",
      "Epoch 10/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3481 - acc: 0.8412Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3482 - acc: 0.8411 - val_loss: 0.3999 - val_acc: 0.8124\n",
      "Epoch 11/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3444 - acc: 0.8431Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3448 - acc: 0.8430 - val_loss: 0.4019 - val_acc: 0.8131\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 4s 66us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.7662Epoch 00001: val_loss improved from inf to 0.40838, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 64s 479us/step - loss: 0.4686 - acc: 0.7662 - val_loss: 0.4084 - val_acc: 0.8066\n",
      "Epoch 2/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8084Epoch 00002: val_loss improved from 0.40838 to 0.39564, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4073 - acc: 0.8084 - val_loss: 0.3956 - val_acc: 0.8129\n",
      "Epoch 3/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3940 - acc: 0.8164Epoch 00003: val_loss improved from 0.39564 to 0.39112, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3940 - acc: 0.8163 - val_loss: 0.3911 - val_acc: 0.8159\n",
      "Epoch 4/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8214Epoch 00004: val_loss improved from 0.39112 to 0.38757, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3860 - acc: 0.8214 - val_loss: 0.3876 - val_acc: 0.8184\n",
      "Epoch 5/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3785 - acc: 0.8254Epoch 00005: val_loss improved from 0.38757 to 0.38551, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3788 - acc: 0.8251 - val_loss: 0.3855 - val_acc: 0.8184\n",
      "Epoch 6/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3730 - acc: 0.8284Epoch 00006: val_loss improved from 0.38551 to 0.38370, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 17us/step - loss: 0.3728 - acc: 0.8283 - val_loss: 0.3837 - val_acc: 0.8202\n",
      "Epoch 7/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3675 - acc: 0.8315Epoch 00007: val_loss improved from 0.38370 to 0.38285, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3675 - acc: 0.8315 - val_loss: 0.3829 - val_acc: 0.8192\n",
      "Epoch 8/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3625 - acc: 0.8341Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 15us/step - loss: 0.3628 - acc: 0.8339 - val_loss: 0.3835 - val_acc: 0.8188\n",
      "Epoch 9/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3587 - acc: 0.8360Epoch 00009: val_loss improved from 0.38285 to 0.38211, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3588 - acc: 0.8359 - val_loss: 0.3821 - val_acc: 0.8206\n",
      "Epoch 10/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.8376Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3553 - acc: 0.8376 - val_loss: 0.3876 - val_acc: 0.8178\n",
      "Epoch 11/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3518 - acc: 0.8400Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3520 - acc: 0.8399 - val_loss: 0.3851 - val_acc: 0.8196\n",
      "Epoch 12/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3480 - acc: 0.8422Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 12us/step - loss: 0.3480 - acc: 0.8422 - val_loss: 0.3861 - val_acc: 0.8187\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 5s 69us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.7667Epoch 00001: val_loss improved from inf to 0.42842, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 7s 55us/step - loss: 0.4631 - acc: 0.7678 - val_loss: 0.4284 - val_acc: 0.7950\n",
      "Epoch 2/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4010 - acc: 0.8118Epoch 00002: val_loss improved from 0.42842 to 0.41384, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4008 - acc: 0.8118 - val_loss: 0.4138 - val_acc: 0.8041\n",
      "Epoch 3/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8178Epoch 00003: val_loss improved from 0.41384 to 0.40954, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3883 - acc: 0.8178 - val_loss: 0.4095 - val_acc: 0.8047\n",
      "Epoch 4/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3799 - acc: 0.8228Epoch 00004: val_loss improved from 0.40954 to 0.40509, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3799 - acc: 0.8227 - val_loss: 0.4051 - val_acc: 0.8094\n",
      "Epoch 5/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3734 - acc: 0.8275Epoch 00005: val_loss improved from 0.40509 to 0.40214, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3730 - acc: 0.8278 - val_loss: 0.4021 - val_acc: 0.8093\n",
      "Epoch 6/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3669 - acc: 0.8306Epoch 00006: val_loss improved from 0.40214 to 0.40172, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3672 - acc: 0.8305 - val_loss: 0.4017 - val_acc: 0.8092\n",
      "Epoch 7/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8340Epoch 00007: val_loss improved from 0.40172 to 0.39985, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3622 - acc: 0.8340 - val_loss: 0.3998 - val_acc: 0.8084\n",
      "Epoch 8/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3573 - acc: 0.8359Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3573 - acc: 0.8360 - val_loss: 0.4001 - val_acc: 0.8070\n",
      "Epoch 9/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8389Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3531 - acc: 0.8390 - val_loss: 0.4008 - val_acc: 0.8092\n",
      "Epoch 10/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8410Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3494 - acc: 0.8410 - val_loss: 0.4005 - val_acc: 0.8093\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 5s 74us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.7664Epoch 00001: val_loss improved from inf to 0.42585, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 7s 53us/step - loss: 0.4640 - acc: 0.7678 - val_loss: 0.4258 - val_acc: 0.7963\n",
      "Epoch 2/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3999 - acc: 0.8121Epoch 00002: val_loss improved from 0.42585 to 0.41236, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3996 - acc: 0.8124 - val_loss: 0.4124 - val_acc: 0.8048\n",
      "Epoch 3/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8197Epoch 00003: val_loss improved from 0.41236 to 0.40630, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3862 - acc: 0.8195 - val_loss: 0.4063 - val_acc: 0.8093\n",
      "Epoch 4/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8241Epoch 00004: val_loss improved from 0.40630 to 0.40341, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3777 - acc: 0.8242 - val_loss: 0.4034 - val_acc: 0.8118\n",
      "Epoch 5/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3714 - acc: 0.8282Epoch 00005: val_loss improved from 0.40341 to 0.40283, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3715 - acc: 0.8282 - val_loss: 0.4028 - val_acc: 0.8113\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.8308Epoch 00006: val_loss improved from 0.40283 to 0.39935, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3660 - acc: 0.8309 - val_loss: 0.3994 - val_acc: 0.8141\n",
      "Epoch 7/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.8339Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3607 - acc: 0.8341 - val_loss: 0.4012 - val_acc: 0.8141\n",
      "Epoch 8/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3562 - acc: 0.8363Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3564 - acc: 0.8365 - val_loss: 0.3994 - val_acc: 0.8129\n",
      "Epoch 9/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3520 - acc: 0.8386Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3518 - acc: 0.8387 - val_loss: 0.4004 - val_acc: 0.8129\n",
      "Epoch 00009: early stopping\n",
      "66666/66666 [==============================] - 5s 69us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.00%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4673 - acc: 0.7674Epoch 00001: val_loss improved from inf to 0.40634, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 69s 517us/step - loss: 0.4672 - acc: 0.7675 - val_loss: 0.4063 - val_acc: 0.8087\n",
      "Epoch 2/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4055 - acc: 0.8098Epoch 00002: val_loss improved from 0.40634 to 0.39293, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.4054 - acc: 0.8097 - val_loss: 0.3929 - val_acc: 0.8143\n",
      "Epoch 3/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3918 - acc: 0.8180Epoch 00003: val_loss improved from 0.39293 to 0.38902, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3921 - acc: 0.8177 - val_loss: 0.3890 - val_acc: 0.8173\n",
      "Epoch 4/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3840 - acc: 0.8224Epoch 00004: val_loss improved from 0.38902 to 0.38500, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3840 - acc: 0.8224 - val_loss: 0.3850 - val_acc: 0.8203\n",
      "Epoch 5/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3765 - acc: 0.8266Epoch 00005: val_loss improved from 0.38500 to 0.38219, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 15us/step - loss: 0.3765 - acc: 0.8265 - val_loss: 0.3822 - val_acc: 0.8206\n",
      "Epoch 6/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3709 - acc: 0.8299Epoch 00006: val_loss improved from 0.38219 to 0.38085, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3707 - acc: 0.8300 - val_loss: 0.3808 - val_acc: 0.8221\n",
      "Epoch 7/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3650 - acc: 0.8326Epoch 00007: val_loss improved from 0.38085 to 0.37968, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3653 - acc: 0.8324 - val_loss: 0.3797 - val_acc: 0.8222\n",
      "Epoch 8/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3604 - acc: 0.8353Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3606 - acc: 0.8351 - val_loss: 0.3802 - val_acc: 0.8221\n",
      "Epoch 9/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.8377Epoch 00009: val_loss improved from 0.37968 to 0.37901, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3567 - acc: 0.8376 - val_loss: 0.3790 - val_acc: 0.8227\n",
      "Epoch 10/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3530 - acc: 0.8398Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3531 - acc: 0.8398 - val_loss: 0.3829 - val_acc: 0.8209\n",
      "Epoch 11/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8410Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3497 - acc: 0.8409 - val_loss: 0.3810 - val_acc: 0.8226\n",
      "Epoch 12/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3459 - acc: 0.8436Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3459 - acc: 0.8436 - val_loss: 0.3819 - val_acc: 0.8219\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 5s 71us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.7688Epoch 00001: val_loss improved from inf to 0.42656, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 8s 59us/step - loss: 0.4618 - acc: 0.7691 - val_loss: 0.4266 - val_acc: 0.7969\n",
      "Epoch 2/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3993 - acc: 0.8125Epoch 00002: val_loss improved from 0.42656 to 0.41160, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3992 - acc: 0.8124 - val_loss: 0.4116 - val_acc: 0.8054\n",
      "Epoch 3/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3866 - acc: 0.8187Epoch 00003: val_loss improved from 0.41160 to 0.40711, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3865 - acc: 0.8187 - val_loss: 0.4071 - val_acc: 0.8075\n",
      "Epoch 4/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8232Epoch 00004: val_loss improved from 0.40711 to 0.40269, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3780 - acc: 0.8233 - val_loss: 0.4027 - val_acc: 0.8109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3711 - acc: 0.8285Epoch 00005: val_loss improved from 0.40269 to 0.39928, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3711 - acc: 0.8285 - val_loss: 0.3993 - val_acc: 0.8116\n",
      "Epoch 6/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3647 - acc: 0.8318Epoch 00006: val_loss improved from 0.39928 to 0.39916, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3651 - acc: 0.8315 - val_loss: 0.3992 - val_acc: 0.8112\n",
      "Epoch 7/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3599 - acc: 0.8358Epoch 00007: val_loss improved from 0.39916 to 0.39696, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3601 - acc: 0.8356 - val_loss: 0.3970 - val_acc: 0.8111\n",
      "Epoch 8/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3550 - acc: 0.8375Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3550 - acc: 0.8376 - val_loss: 0.3972 - val_acc: 0.8126\n",
      "Epoch 9/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.8401Epoch 00009: val_loss improved from 0.39696 to 0.39667, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3508 - acc: 0.8401 - val_loss: 0.3967 - val_acc: 0.8164\n",
      "Epoch 10/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3473 - acc: 0.8423Epoch 00010: val_loss improved from 0.39667 to 0.39648, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3471 - acc: 0.8423 - val_loss: 0.3965 - val_acc: 0.8130\n",
      "Epoch 11/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3434 - acc: 0.8447Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3434 - acc: 0.8447 - val_loss: 0.3983 - val_acc: 0.8120\n",
      "Epoch 12/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3404 - acc: 0.8464Epoch 00012: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3405 - acc: 0.8463 - val_loss: 0.3968 - val_acc: 0.8131\n",
      "Epoch 13/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3368 - acc: 0.8483Epoch 00013: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3371 - acc: 0.8481 - val_loss: 0.3971 - val_acc: 0.8167\n",
      "Epoch 00013: early stopping\n",
      "66666/66666 [==============================] - 5s 79us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4625 - acc: 0.7686Epoch 00001: val_loss improved from inf to 0.42416, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 7s 54us/step - loss: 0.4624 - acc: 0.7686 - val_loss: 0.4242 - val_acc: 0.7972\n",
      "Epoch 2/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3980 - acc: 0.8139Epoch 00002: val_loss improved from 0.42416 to 0.41088, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3976 - acc: 0.8142 - val_loss: 0.4109 - val_acc: 0.8047\n",
      "Epoch 3/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3839 - acc: 0.8213Epoch 00003: val_loss improved from 0.41088 to 0.40411, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3840 - acc: 0.8212 - val_loss: 0.4041 - val_acc: 0.8104\n",
      "Epoch 4/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3759 - acc: 0.8255Epoch 00004: val_loss improved from 0.40411 to 0.40181, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3755 - acc: 0.8257 - val_loss: 0.4018 - val_acc: 0.8128\n",
      "Epoch 5/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8297Epoch 00005: val_loss improved from 0.40181 to 0.40050, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3691 - acc: 0.8297 - val_loss: 0.4005 - val_acc: 0.8128\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8325Epoch 00006: val_loss improved from 0.40050 to 0.39768, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3635 - acc: 0.8327 - val_loss: 0.3977 - val_acc: 0.8143\n",
      "Epoch 7/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3584 - acc: 0.8355Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3581 - acc: 0.8356 - val_loss: 0.3987 - val_acc: 0.8159\n",
      "Epoch 8/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3536 - acc: 0.8378Epoch 00008: val_loss improved from 0.39768 to 0.39722, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 19us/step - loss: 0.3537 - acc: 0.8377 - val_loss: 0.3972 - val_acc: 0.8150\n",
      "Epoch 9/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3490 - acc: 0.8406Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 3s 19us/step - loss: 0.3491 - acc: 0.8406 - val_loss: 0.3982 - val_acc: 0.8152\n",
      "Epoch 10/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3454 - acc: 0.8423- ETA: 0s - loss: 0.3451 - acc: 0.842Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 17us/step - loss: 0.3454 - acc: 0.8423 - val_loss: 0.3986 - val_acc: 0.8147\n",
      "Epoch 11/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3415 - acc: 0.8444Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 17us/step - loss: 0.3417 - acc: 0.8444 - val_loss: 0.4005 - val_acc: 0.8134\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 5s 71us/step\n",
      "Model:  basic_model_adam\n",
      "0.82% (+/- 0.00%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4813 - acc: 0.7563Epoch 00001: val_loss improved from inf to 0.42393, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 27s 199us/step - loss: 0.4807 - acc: 0.7567 - val_loss: 0.4239 - val_acc: 0.7963\n",
      "Epoch 2/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4229 - acc: 0.7992Epoch 00002: val_loss improved from 0.42393 to 0.41233, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 15us/step - loss: 0.4230 - acc: 0.7992 - val_loss: 0.4123 - val_acc: 0.8022\n",
      "Epoch 3/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8068Epoch 00003: val_loss improved from 0.41233 to 0.40818, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.4099 - acc: 0.8067 - val_loss: 0.4082 - val_acc: 0.8042\n",
      "Epoch 4/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4016 - acc: 0.8117Epoch 00004: val_loss improved from 0.40818 to 0.40508, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4016 - acc: 0.8116 - val_loss: 0.4051 - val_acc: 0.8088\n",
      "Epoch 5/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3945 - acc: 0.8157Epoch 00005: val_loss improved from 0.40508 to 0.40186, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3945 - acc: 0.8156 - val_loss: 0.4019 - val_acc: 0.8107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3887 - acc: 0.8192Epoch 00006: val_loss improved from 0.40186 to 0.40151, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3887 - acc: 0.8192 - val_loss: 0.4015 - val_acc: 0.8087\n",
      "Epoch 7/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3828 - acc: 0.8222Epoch 00007: val_loss improved from 0.40151 to 0.40019, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3831 - acc: 0.8220 - val_loss: 0.4002 - val_acc: 0.8104\n",
      "Epoch 8/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8247Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3790 - acc: 0.8246 - val_loss: 0.4010 - val_acc: 0.8115\n",
      "Epoch 9/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3744 - acc: 0.8276Epoch 00009: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 16us/step - loss: 0.3745 - acc: 0.8275 - val_loss: 0.4005 - val_acc: 0.8109\n",
      "Epoch 10/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3713 - acc: 0.8293Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3713 - acc: 0.8293 - val_loss: 0.4085 - val_acc: 0.8060\n",
      "Epoch 00010: early stopping\n",
      "66668/66668 [==============================] - 5s 71us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4749 - acc: 0.7594Epoch 00001: val_loss improved from inf to 0.44676, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 7s 50us/step - loss: 0.4747 - acc: 0.7595 - val_loss: 0.4468 - val_acc: 0.7844\n",
      "Epoch 2/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4164 - acc: 0.8029Epoch 00002: val_loss improved from 0.44676 to 0.43363, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4164 - acc: 0.8029 - val_loss: 0.4336 - val_acc: 0.7931\n",
      "Epoch 3/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4039 - acc: 0.8097Epoch 00003: val_loss improved from 0.43363 to 0.43159, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4037 - acc: 0.8097 - val_loss: 0.4316 - val_acc: 0.7937\n",
      "Epoch 4/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3956 - acc: 0.8149Epoch 00004: val_loss improved from 0.43159 to 0.42918, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 17us/step - loss: 0.3954 - acc: 0.8149 - val_loss: 0.4292 - val_acc: 0.7984\n",
      "Epoch 5/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8198Epoch 00005: val_loss improved from 0.42918 to 0.42663, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3883 - acc: 0.8199 - val_loss: 0.4266 - val_acc: 0.7982\n",
      "Epoch 6/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3821 - acc: 0.8228Epoch 00006: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3824 - acc: 0.8228 - val_loss: 0.4267 - val_acc: 0.7987\n",
      "Epoch 7/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3776 - acc: 0.8257Epoch 00007: val_loss improved from 0.42663 to 0.42493, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3776 - acc: 0.8255 - val_loss: 0.4249 - val_acc: 0.7995\n",
      "Epoch 8/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3730 - acc: 0.8278Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3729 - acc: 0.8280 - val_loss: 0.4268 - val_acc: 0.7979\n",
      "Epoch 9/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3692 - acc: 0.8302Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3689 - acc: 0.8304 - val_loss: 0.4251 - val_acc: 0.7986\n",
      "Epoch 10/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3652 - acc: 0.8320Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 12us/step - loss: 0.3654 - acc: 0.8320 - val_loss: 0.4276 - val_acc: 0.7972\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 5s 73us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4759 - acc: 0.7583Epoch 00001: val_loss improved from inf to 0.44067, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 7s 54us/step - loss: 0.4756 - acc: 0.7585 - val_loss: 0.4407 - val_acc: 0.7882\n",
      "Epoch 2/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4157 - acc: 0.8030Epoch 00002: val_loss improved from 0.44067 to 0.42841, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4157 - acc: 0.8030 - val_loss: 0.4284 - val_acc: 0.7954\n",
      "Epoch 3/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4024 - acc: 0.8098Epoch 00003: val_loss improved from 0.42841 to 0.42200, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.4024 - acc: 0.8096 - val_loss: 0.4220 - val_acc: 0.7989\n",
      "Epoch 4/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3941 - acc: 0.8146Epoch 00004: val_loss improved from 0.42200 to 0.41900, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3939 - acc: 0.8147 - val_loss: 0.4190 - val_acc: 0.8017\n",
      "Epoch 5/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3872 - acc: 0.8192Epoch 00005: val_loss improved from 0.41900 to 0.41827, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3872 - acc: 0.8192 - val_loss: 0.4183 - val_acc: 0.8009\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.8219Epoch 00006: val_loss improved from 0.41827 to 0.41560, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3814 - acc: 0.8220 - val_loss: 0.4156 - val_acc: 0.8024\n",
      "Epoch 7/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3766 - acc: 0.8258Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3762 - acc: 0.8260 - val_loss: 0.4171 - val_acc: 0.8029\n",
      "Epoch 8/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3716 - acc: 0.8274Epoch 00008: val_loss improved from 0.41560 to 0.41510, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3712 - acc: 0.8275 - val_loss: 0.4151 - val_acc: 0.8034\n",
      "Epoch 9/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3666 - acc: 0.8298Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3666 - acc: 0.8299 - val_loss: 0.4154 - val_acc: 0.8042\n",
      "Epoch 10/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.3632 - acc: 0.8326Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3633 - acc: 0.8325 - val_loss: 0.4170 - val_acc: 0.8029\n",
      "Epoch 11/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3594 - acc: 0.8342Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3595 - acc: 0.8342 - val_loss: 0.4173 - val_acc: 0.8031\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 5s 73us/step\n",
      "Model:  basic_model_adam\n",
      "0.80% (+/- 0.00%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.4718 - acc: 0.7642Epoch 00001: val_loss improved from inf to 0.41075, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 68s 512us/step - loss: 0.4711 - acc: 0.7646 - val_loss: 0.4107 - val_acc: 0.8044\n",
      "Epoch 2/100\n",
      "128000/133332 [===========================>..] - ETA: 0s - loss: 0.4098 - acc: 0.8068Epoch 00002: val_loss improved from 0.41075 to 0.39729, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.4094 - acc: 0.8069 - val_loss: 0.3973 - val_acc: 0.8120\n",
      "Epoch 3/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8155Epoch 00003: val_loss improved from 0.39729 to 0.39313, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3959 - acc: 0.8154 - val_loss: 0.3931 - val_acc: 0.8155\n",
      "Epoch 4/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8203Epoch 00004: val_loss improved from 0.39313 to 0.38929, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3877 - acc: 0.8203 - val_loss: 0.3893 - val_acc: 0.8178\n",
      "Epoch 5/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3802 - acc: 0.8247Epoch 00005: val_loss improved from 0.38929 to 0.38671, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3802 - acc: 0.8246 - val_loss: 0.3867 - val_acc: 0.8181\n",
      "Epoch 6/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3744 - acc: 0.8272Epoch 00006: val_loss improved from 0.38671 to 0.38515, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3743 - acc: 0.8271 - val_loss: 0.3852 - val_acc: 0.8201\n",
      "Epoch 7/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8310Epoch 00007: val_loss improved from 0.38515 to 0.38430, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3688 - acc: 0.8308 - val_loss: 0.3843 - val_acc: 0.8184\n",
      "Epoch 8/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8334Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3644 - acc: 0.8331 - val_loss: 0.3854 - val_acc: 0.8187\n",
      "Epoch 9/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3601 - acc: 0.8354Epoch 00009: val_loss improved from 0.38430 to 0.38381, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3602 - acc: 0.8351 - val_loss: 0.3838 - val_acc: 0.8191\n",
      "Epoch 10/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3568 - acc: 0.8368Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3570 - acc: 0.8367 - val_loss: 0.3890 - val_acc: 0.8165\n",
      "Epoch 11/100\n",
      "132096/133332 [============================>.] - ETA: 0s - loss: 0.3532 - acc: 0.8397Epoch 00011: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3533 - acc: 0.8397 - val_loss: 0.3870 - val_acc: 0.8188\n",
      "Epoch 12/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8408Epoch 00012: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 13us/step - loss: 0.3495 - acc: 0.8409 - val_loss: 0.3871 - val_acc: 0.8195\n",
      "Epoch 00012: early stopping\n",
      "66668/66668 [==============================] - 6s 83us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4672 - acc: 0.7654- ETA: 6s - loss: 0.512Epoch 00001: val_loss improved from inf to 0.43027, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 9s 69us/step - loss: 0.4657 - acc: 0.7664 - val_loss: 0.4303 - val_acc: 0.7935\n",
      "Epoch 2/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.8100Epoch 00002: val_loss improved from 0.43027 to 0.41566, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.4030 - acc: 0.8100 - val_loss: 0.4157 - val_acc: 0.8025\n",
      "Epoch 3/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8166Epoch 00003: val_loss improved from 0.41566 to 0.41165, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3903 - acc: 0.8165 - val_loss: 0.4116 - val_acc: 0.8033\n",
      "Epoch 4/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3819 - acc: 0.8216Epoch 00004: val_loss improved from 0.41165 to 0.40698, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.3819 - acc: 0.8215 - val_loss: 0.4070 - val_acc: 0.8076\n",
      "Epoch 5/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3752 - acc: 0.8265Epoch 00005: val_loss improved from 0.40698 to 0.40381, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3750 - acc: 0.8266 - val_loss: 0.4038 - val_acc: 0.8083\n",
      "Epoch 6/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3689 - acc: 0.8296Epoch 00006: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 16us/step - loss: 0.3692 - acc: 0.8293 - val_loss: 0.4040 - val_acc: 0.8089\n",
      "Epoch 7/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8332Epoch 00007: val_loss improved from 0.40381 to 0.40218, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3641 - acc: 0.8333 - val_loss: 0.4022 - val_acc: 0.8070\n",
      "Epoch 8/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3591 - acc: 0.8352Epoch 00008: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3591 - acc: 0.8353 - val_loss: 0.4032 - val_acc: 0.8066\n",
      "Epoch 9/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3554 - acc: 0.8375Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3550 - acc: 0.8376 - val_loss: 0.4038 - val_acc: 0.8071\n",
      "Epoch 10/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3514 - acc: 0.8390Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 15us/step - loss: 0.3514 - acc: 0.8390 - val_loss: 0.4038 - val_acc: 0.8062\n",
      "Epoch 00010: early stopping\n",
      "66666/66666 [==============================] - 6s 92us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.7653Epoch 00001: val_loss improved from inf to 0.42784, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 9s 65us/step - loss: 0.4666 - acc: 0.7653 - val_loss: 0.4278 - val_acc: 0.7950\n",
      "Epoch 2/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4017 - acc: 0.8115Epoch 00002: val_loss improved from 0.42784 to 0.41478, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.4015 - acc: 0.8115 - val_loss: 0.4148 - val_acc: 0.8034\n",
      "Epoch 3/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8195Epoch 00003: val_loss improved from 0.41478 to 0.40826, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3878 - acc: 0.8193 - val_loss: 0.4083 - val_acc: 0.8084\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8235Epoch 00004: val_loss improved from 0.40826 to 0.40574, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3794 - acc: 0.8237 - val_loss: 0.4057 - val_acc: 0.8099\n",
      "Epoch 5/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3730 - acc: 0.8271Epoch 00005: val_loss improved from 0.40574 to 0.40571, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.3730 - acc: 0.8271 - val_loss: 0.4057 - val_acc: 0.8094\n",
      "Epoch 6/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3677 - acc: 0.8299Epoch 00006: val_loss improved from 0.40571 to 0.40221, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3676 - acc: 0.8301 - val_loss: 0.4022 - val_acc: 0.8121\n",
      "Epoch 7/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8332Epoch 00007: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3622 - acc: 0.8333 - val_loss: 0.4031 - val_acc: 0.8132\n",
      "Epoch 8/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.3578 - acc: 0.8351Epoch 00008: val_loss improved from 0.40221 to 0.40175, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3578 - acc: 0.8352 - val_loss: 0.4018 - val_acc: 0.8107\n",
      "Epoch 9/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.8380Epoch 00009: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3533 - acc: 0.8381 - val_loss: 0.4028 - val_acc: 0.8124\n",
      "Epoch 10/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.3496 - acc: 0.8402Epoch 00010: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3496 - acc: 0.8401 - val_loss: 0.4043 - val_acc: 0.8112\n",
      "Epoch 11/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.3462 - acc: 0.8425Epoch 00011: val_loss did not improve\n",
      "133334/133334 [==============================] - 2s 13us/step - loss: 0.3462 - acc: 0.8424 - val_loss: 0.4046 - val_acc: 0.8111\n",
      "Epoch 00011: early stopping\n",
      "66666/66666 [==============================] - 5s 79us/step\n",
      "Model:  basic_model_adam\n",
      "0.81% (+/- 0.01%)\n",
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4707 - acc: 0.7644Epoch 00001: val_loss improved from inf to 0.41144, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 94s 706us/step - loss: 0.4706 - acc: 0.7645 - val_loss: 0.4114 - val_acc: 0.8024\n",
      "Epoch 2/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.4087 - acc: 0.8067Epoch 00002: val_loss improved from 0.41144 to 0.39714, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 17us/step - loss: 0.4085 - acc: 0.8067 - val_loss: 0.3971 - val_acc: 0.8098\n",
      "Epoch 3/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3943 - acc: 0.8155Epoch 00003: val_loss improved from 0.39714 to 0.39180, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 18us/step - loss: 0.3945 - acc: 0.8154 - val_loss: 0.3918 - val_acc: 0.8143\n",
      "Epoch 4/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8212Epoch 00004: val_loss improved from 0.39180 to 0.38774, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 18us/step - loss: 0.3861 - acc: 0.8212 - val_loss: 0.3877 - val_acc: 0.8190\n",
      "Epoch 5/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3786 - acc: 0.8245Epoch 00005: val_loss improved from 0.38774 to 0.38526, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 3s 20us/step - loss: 0.3785 - acc: 0.8243 - val_loss: 0.3853 - val_acc: 0.8196\n",
      "Epoch 6/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.3726 - acc: 0.8278Epoch 00006: val_loss improved from 0.38526 to 0.38384, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 16us/step - loss: 0.3725 - acc: 0.8279 - val_loss: 0.3838 - val_acc: 0.8209\n",
      "Epoch 7/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.8312Epoch 00007: val_loss improved from 0.38384 to 0.38321, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3671 - acc: 0.8310 - val_loss: 0.3832 - val_acc: 0.8210\n",
      "Epoch 8/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.3621 - acc: 0.8342Epoch 00008: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3623 - acc: 0.8340 - val_loss: 0.3843 - val_acc: 0.8190\n",
      "Epoch 9/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3582 - acc: 0.8354Epoch 00009: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3583 - acc: 0.8354 - val_loss: 0.3833 - val_acc: 0.8203\n",
      "Epoch 10/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.3544 - acc: 0.8383Epoch 00010: val_loss did not improve\n",
      "133332/133332 [==============================] - 2s 14us/step - loss: 0.3543 - acc: 0.8383 - val_loss: 0.3881 - val_acc: 0.8185\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "stds=[]\n",
    "\n",
    "for corpus in corpuses: \n",
    "    model_score=VP.classify_with_neural_networks(neural_nets, global_vectors, corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "    accuracies.append(model_score[0][0])\n",
    "    stds.append(model_score[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to determine which preprocessing techniques that improved the accuracy, and keep them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpuses_1=[]\n",
    "names_1=[]\n",
    "stds_1=[]\n",
    "acc_1=[]\n",
    "print('The original corpus gave accuracy of: ',accuracies[0], 'std:', stds[0],'\\n')\n",
    "for i in range(1,len(accuracies)):\n",
    "    if accuracies[i]>=accuracies[0]:\n",
    "        corpuses_1.append(corpuses[i])\n",
    "        names_1.append(names[i])\n",
    "        stds_1.append(stds[i])\n",
    "        acc_1.append(accuracies[i])\n",
    "        print('IMPROVED:  ',names[i],', score:',accuracies[i],'std:',stds[i])\n",
    "    else:\n",
    "        print('Not better:',names[i],', score:',accuracies[i],'std:',stds[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We do not keep SH, as SHM is better. \n",
    "# We do not keep N as NM is better \n",
    "# We do not keep SP due to time  (158.26 min)\n",
    "# We do not keep techniques that imporved less than 0.05 percentage points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply all techniques that contributed positively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_={'hashtag': True, 'segmentation_hash': True, 'hashtag_mention':True,\n",
    "        'hearts':True,'hugs_and_kisses':True,'elongation':True, 'set_to_not':True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applying the techniques that we have decided to keep:\n",
    "best_prepr_corpus=TO.preprocess_corpus(full_corpus, **input_)\n",
    "best_corpus=HL.creating_n_grams_corpus(2,best_prepr_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross validating:\n",
    "model_score=VP.classify_with_neural_networks(neural_nets, global_vectors, corpus, \n",
    "                                             total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy:',  model_score[0][0], 'std:',model_score[0][1],'\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mindfs= [0,2,5,10,20, 40, 60,100,140,200]\n",
    "maxdfs=[0.8] \n",
    "accuracies_stop=[]\n",
    "stds_stop=[]\n",
    "stop_lens=[]\n",
    "vocabs=[]\n",
    "\n",
    "\n",
    "for max_ in maxdfs:\n",
    "    for min_ in mindfs: \n",
    "        stopwords, vocab= TO.get_dynamic_stopwords(best_corpus, MinDf=min_, MaxDf=max_)\n",
    "        stopword_corpus=TO.remove_stopwords(best_corpus, stopwords)\n",
    "        model_score=VP.classify_with_neural_networks(neural_nets, global_vectors, stopword_corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "        accuracies_stop.append(model_score[0][0])\n",
    "        stds_stop.append(model_score[0][1])\n",
    "        stop_lens.append(len(stopwords))\n",
    "        vocabs.append(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(stop_lens)):\n",
    "    print('min', mindfs[i], 'accuracy', accuracies_stop[i],'std',stds_stop[i],  '\\n')\n",
    "for i in range(len(stop_lens)):\n",
    "    print('number of stop words', stop_lens[i], 'lenght of vocabolary', len(vocabs[i]),'sum for checking',stop_lens[i]+len(vocabs[i]),  '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the best combination with the simple and the complex neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords, vocab= TO.get_dynamic_stopwords(best_corpus, MinDf=5, MaxDf=0.8)\n",
    "final_corpus= TO.remove_stopwords(best_corpus, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_score=VP.classify_with_neural_networks(NN.basic_model_adam, global_vectors, final_corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "\n",
    "print('Applying the best combination of preprocessing, using pre-trained global vectors with 200 dimensions, an cros-validatino accuracy of', model_score[0][0],'+-',model_score[0][1], 'was achieved using the simple neural net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_score=VP.classify_with_neural_networks(NN.complex_model, global_vectors, final_corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "\n",
    "print('Applying the best combination of preprocessing, using pre-trained global vectors with 200 dimensions, an cros-validatino accuracy of', model_score[0][0],'+-',model_score[0][1], 'was achieved using the compelx neural net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
