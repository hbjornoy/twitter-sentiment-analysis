{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Best Combination of Preprocessing Techniques on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/HeddaVik/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# internal imports\n",
    "import helpers as HL\n",
    "import glove_module as GV\n",
    "import neural_nets as NN\n",
    "#import tokenizing as TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word embeddings using the created gensim-.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pick one, the higher dimension, the better result and longer computational time. \n",
    "global_vectors=HL.get_global_vectors(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating corpus:\n",
    "In addition to the acutal corpus, some additional information is needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_corpus, nr_pos_tweets, nr_neg_tweets, total_training_tweets=HL.get_corpus(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the neural net\n",
    "At this stage, we want to use the simple neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural_nets=[NN.basic_model_adam]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables to apply all preprocessing techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing vectors:\n",
    "corpuses=[]\n",
    "corpuses.append(full_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining names of corpuses: \n",
    "names=['original_corpus','SH_corpus','SHM_corpus','H_corpus','HK_corpus','PS_corpus','NS__corpus','OS_corpus','N_corpus','NM_corpus','ST_corpus','SP_corpus','E_corpus','SN_corpus','RS_corpus','EX_corpus','N-2_corpus','N-3_corpus','N-4_corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining inputs to preprocessing function: \n",
    "inputs=[{'hashtag': True, 'segmentation_hash': True},\n",
    "        {'hashtag':True,'segmentation_hash': True,'hashtag_mention':True},\n",
    "        {'hearts':True},\n",
    "        {'hugs_and_kisses':True},\n",
    "        {'pos_smilies':True},\n",
    "        {'neg_smilies':True},\n",
    "        {'other_smilies':True},\n",
    "        {'numbers':True},\n",
    "        {'numbers':True,'number_mention':True},\n",
    "        {'stemming':True},\n",
    "        {'spelling':True},#Warning: When True, it takes app  2.5 h on test set. Recomended to always set to false \n",
    "        {'elongation':True},\n",
    "        {'set_to_not':True},\n",
    "        {'remove_signs':True},\n",
    "        {'exclamation':True}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying all preprocessing techniques to the original corpus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for input_ in inputs: \n",
    "        corpus=TO.preprocess_corpus(full_corpus, **input_)\n",
    "        corpuses.append(corpus)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns=[2,3,4]\n",
    "for n in ns: \n",
    "    corpus=HL.creating_n_grams_corpus(n,full_corpus)\n",
    "    corpuses.append(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing all preprocessing techniques: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets processed: 0  of total number of tweets: 200000\n",
      "tweets processed: 50000  of total number of tweets: 200000\n",
      "tweets processed: 100000  of total number of tweets: 200000\n",
      "tweets processed: 150000  of total number of tweets: 200000\n",
      "Train on 133332 samples, validate on 66668 samples\n",
      "Epoch 1/100\n",
      "121856/133332 [==========================>...] - ETA: 0s - loss: 0.5722 - acc: 0.6793Epoch 00001: val_loss improved from inf to 0.51334, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 2s 16us/step - loss: 0.5685 - acc: 0.6814 - val_loss: 0.5133 - val_acc: 0.7253\n",
      "Epoch 2/100\n",
      "121856/133332 [==========================>...] - ETA: 0s - loss: 0.5217 - acc: 0.7207Epoch 00002: val_loss improved from 0.51334 to 0.50126, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.5205 - acc: 0.7217 - val_loss: 0.5013 - val_acc: 0.7361\n",
      "Epoch 3/100\n",
      "121856/133332 [==========================>...] - ETA: 0s - loss: 0.5120 - acc: 0.7289Epoch 00003: val_loss improved from 0.50126 to 0.49594, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 5us/step - loss: 0.5116 - acc: 0.7294 - val_loss: 0.4959 - val_acc: 0.7399\n",
      "Epoch 4/100\n",
      "120832/133332 [==========================>...] - ETA: 0s - loss: 0.5071 - acc: 0.7325Epoch 00004: val_loss improved from 0.49594 to 0.49333, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.5070 - acc: 0.7326 - val_loss: 0.4933 - val_acc: 0.7406\n",
      "Epoch 5/100\n",
      "120832/133332 [==========================>...] - ETA: 0s - loss: 0.5036 - acc: 0.7351Epoch 00005: val_loss improved from 0.49333 to 0.49012, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.5033 - acc: 0.7356 - val_loss: 0.4901 - val_acc: 0.7440\n",
      "Epoch 6/100\n",
      "119808/133332 [=========================>....] - ETA: 0s - loss: 0.5005 - acc: 0.7388Epoch 00006: val_loss improved from 0.49012 to 0.48864, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.5005 - acc: 0.7386 - val_loss: 0.4886 - val_acc: 0.7441\n",
      "Epoch 7/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.7401Epoch 00007: val_loss improved from 0.48864 to 0.48678, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 5us/step - loss: 0.4979 - acc: 0.7402 - val_loss: 0.4868 - val_acc: 0.7471\n",
      "Epoch 8/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.7411Epoch 00008: val_loss improved from 0.48678 to 0.48545, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4959 - acc: 0.7411 - val_loss: 0.4855 - val_acc: 0.7454\n",
      "Epoch 9/100\n",
      "118784/133332 [=========================>....] - ETA: 0s - loss: 0.4945 - acc: 0.7430Epoch 00009: val_loss improved from 0.48545 to 0.48445, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4945 - acc: 0.7425 - val_loss: 0.4845 - val_acc: 0.7462\n",
      "Epoch 10/100\n",
      "120832/133332 [==========================>...] - ETA: 0s - loss: 0.4928 - acc: 0.7436Epoch 00010: val_loss improved from 0.48445 to 0.48339, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4932 - acc: 0.7431 - val_loss: 0.4834 - val_acc: 0.7476\n",
      "Epoch 11/100\n",
      "119808/133332 [=========================>....] - ETA: 0s - loss: 0.4918 - acc: 0.7441Epoch 00011: val_loss improved from 0.48339 to 0.48310, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4919 - acc: 0.7442 - val_loss: 0.4831 - val_acc: 0.7481\n",
      "Epoch 12/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4908 - acc: 0.7456Epoch 00012: val_loss improved from 0.48310 to 0.48192, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4908 - acc: 0.7457 - val_loss: 0.4819 - val_acc: 0.7478\n",
      "Epoch 13/100\n",
      "118784/133332 [=========================>....] - ETA: 0s - loss: 0.4898 - acc: 0.7454Epoch 00013: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4895 - acc: 0.7453 - val_loss: 0.4828 - val_acc: 0.7488\n",
      "Epoch 14/100\n",
      "120832/133332 [==========================>...] - ETA: 0s - loss: 0.4879 - acc: 0.7473Epoch 00014: val_loss improved from 0.48192 to 0.48170, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4886 - acc: 0.7467 - val_loss: 0.4817 - val_acc: 0.7481\n",
      "Epoch 15/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4879 - acc: 0.7470Epoch 00015: val_loss improved from 0.48170 to 0.47963, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4877 - acc: 0.7471 - val_loss: 0.4796 - val_acc: 0.7485\n",
      "Epoch 16/100\n",
      "118784/133332 [=========================>....] - ETA: 0s - loss: 0.4871 - acc: 0.7481Epoch 00016: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4868 - acc: 0.7486 - val_loss: 0.4800 - val_acc: 0.7497\n",
      "Epoch 17/100\n",
      "118784/133332 [=========================>....] - ETA: 0s - loss: 0.4862 - acc: 0.7476Epoch 00017: val_loss improved from 0.47963 to 0.47926, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4860 - acc: 0.7478 - val_loss: 0.4793 - val_acc: 0.7504\n",
      "Epoch 18/100\n",
      "118784/133332 [=========================>....] - ETA: 0s - loss: 0.4847 - acc: 0.7488Epoch 00018: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4850 - acc: 0.7483 - val_loss: 0.4793 - val_acc: 0.7503\n",
      "Epoch 19/100\n",
      "133120/133332 [============================>.] - ETA: 0s - loss: 0.4845 - acc: 0.7490Epoch 00019: val_loss improved from 0.47926 to 0.47834, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4845 - acc: 0.7490 - val_loss: 0.4783 - val_acc: 0.7498\n",
      "Epoch 20/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.7499Epoch 00020: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4838 - acc: 0.7499 - val_loss: 0.4792 - val_acc: 0.7507\n",
      "Epoch 21/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.4829 - acc: 0.7498Epoch 00021: val_loss improved from 0.47834 to 0.47756, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 5us/step - loss: 0.4831 - acc: 0.7498 - val_loss: 0.4776 - val_acc: 0.7513\n",
      "Epoch 22/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.4822 - acc: 0.7500Epoch 00022: val_loss improved from 0.47756 to 0.47638, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 5us/step - loss: 0.4824 - acc: 0.7498 - val_loss: 0.4764 - val_acc: 0.7512\n",
      "Epoch 23/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.4815 - acc: 0.7510Epoch 00023: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4817 - acc: 0.7509 - val_loss: 0.4765 - val_acc: 0.7521\n",
      "Epoch 24/100\n",
      "129024/133332 [============================>.] - ETA: 0s - loss: 0.4809 - acc: 0.7515Epoch 00024: val_loss improved from 0.47638 to 0.47621, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 5us/step - loss: 0.4811 - acc: 0.7512 - val_loss: 0.4762 - val_acc: 0.7516\n",
      "Epoch 25/100\n",
      "131072/133332 [============================>.] - ETA: 0s - loss: 0.4808 - acc: 0.7509Epoch 00025: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4807 - acc: 0.7512 - val_loss: 0.4768 - val_acc: 0.7525\n",
      "Epoch 26/100\n",
      "130048/133332 [============================>.] - ETA: 0s - loss: 0.4799 - acc: 0.7516Epoch 00026: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4801 - acc: 0.7516 - val_loss: 0.4768 - val_acc: 0.7530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "121856/133332 [==========================>...] - ETA: 0s - loss: 0.4794 - acc: 0.7532Epoch 00027: val_loss improved from 0.47621 to 0.47571, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4797 - acc: 0.7526 - val_loss: 0.4757 - val_acc: 0.7526\n",
      "Epoch 28/100\n",
      "120832/133332 [==========================>...] - ETA: 0s - loss: 0.4792 - acc: 0.7523Epoch 00028: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4793 - acc: 0.7523 - val_loss: 0.4767 - val_acc: 0.7520\n",
      "Epoch 29/100\n",
      "122880/133332 [==========================>...] - ETA: 0s - loss: 0.4787 - acc: 0.7535Epoch 00029: val_loss improved from 0.47571 to 0.47557, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4786 - acc: 0.7534 - val_loss: 0.4756 - val_acc: 0.7533\n",
      "Epoch 30/100\n",
      "121856/133332 [==========================>...] - ETA: 0s - loss: 0.4781 - acc: 0.7532Epoch 00030: val_loss improved from 0.47557 to 0.47540, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4781 - acc: 0.7531 - val_loss: 0.4754 - val_acc: 0.7521\n",
      "Epoch 31/100\n",
      "122880/133332 [==========================>...] - ETA: 0s - loss: 0.4778 - acc: 0.7536Epoch 00031: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4779 - acc: 0.7533 - val_loss: 0.4755 - val_acc: 0.7536\n",
      "Epoch 32/100\n",
      "122880/133332 [==========================>...] - ETA: 0s - loss: 0.4776 - acc: 0.7534Epoch 00032: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4775 - acc: 0.7533 - val_loss: 0.4757 - val_acc: 0.7527\n",
      "Epoch 33/100\n",
      "122880/133332 [==========================>...] - ETA: 0s - loss: 0.4776 - acc: 0.7531Epoch 00033: val_loss improved from 0.47540 to 0.47523, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4772 - acc: 0.7535 - val_loss: 0.4752 - val_acc: 0.7527\n",
      "Epoch 34/100\n",
      "122880/133332 [==========================>...] - ETA: 0s - loss: 0.4764 - acc: 0.7550Epoch 00034: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4765 - acc: 0.7548 - val_loss: 0.4754 - val_acc: 0.7523\n",
      "Epoch 35/100\n",
      "121856/133332 [==========================>...] - ETA: 0s - loss: 0.4757 - acc: 0.7559Epoch 00035: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4764 - acc: 0.7550 - val_loss: 0.4758 - val_acc: 0.7536\n",
      "Epoch 36/100\n",
      "119808/133332 [=========================>....] - ETA: 0s - loss: 0.4760 - acc: 0.7547Epoch 00036: val_loss improved from 0.47523 to 0.47461, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4759 - acc: 0.7546 - val_loss: 0.4746 - val_acc: 0.7532\n",
      "Epoch 37/100\n",
      "122880/133332 [==========================>...] - ETA: 0s - loss: 0.4753 - acc: 0.7549Epoch 00037: val_loss improved from 0.47461 to 0.47435, saving model to best_neural_model_save.hdf5\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4755 - acc: 0.7549 - val_loss: 0.4743 - val_acc: 0.7544\n",
      "Epoch 38/100\n",
      "122880/133332 [==========================>...] - ETA: 0s - loss: 0.4757 - acc: 0.7543Epoch 00038: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4753 - acc: 0.7546 - val_loss: 0.4744 - val_acc: 0.7538\n",
      "Epoch 39/100\n",
      "118784/133332 [=========================>....] - ETA: 0s - loss: 0.4741 - acc: 0.7558Epoch 00039: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4748 - acc: 0.7558 - val_loss: 0.4758 - val_acc: 0.7532\n",
      "Epoch 40/100\n",
      "120832/133332 [==========================>...] - ETA: 0s - loss: 0.4748 - acc: 0.7567Epoch 00040: val_loss did not improve\n",
      "133332/133332 [==============================] - 1s 4us/step - loss: 0.4746 - acc: 0.7567 - val_loss: 0.4747 - val_acc: 0.7534\n",
      "Epoch 00040: early stopping\n",
      "66668/66668 [==============================] - 2s 34us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.5638 - acc: 0.6888Epoch 00001: val_loss improved from inf to 0.52552, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 2s 14us/step - loss: 0.5632 - acc: 0.6892 - val_loss: 0.5255 - val_acc: 0.7121\n",
      "Epoch 2/100\n",
      "123904/133334 [==========================>...] - ETA: 0s - loss: 0.5151 - acc: 0.7259Epoch 00002: val_loss improved from 0.52552 to 0.51371, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.5141 - acc: 0.7266 - val_loss: 0.5137 - val_acc: 0.7222\n",
      "Epoch 3/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.5054 - acc: 0.7328Epoch 00003: val_loss improved from 0.51371 to 0.50947, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.5053 - acc: 0.7327 - val_loss: 0.5095 - val_acc: 0.7256\n",
      "Epoch 4/100\n",
      "123904/133334 [==========================>...] - ETA: 0s - loss: 0.5005 - acc: 0.7364Epoch 00004: val_loss improved from 0.50947 to 0.50630, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.5003 - acc: 0.7369 - val_loss: 0.5063 - val_acc: 0.7298\n",
      "Epoch 5/100\n",
      "122880/133334 [==========================>...] - ETA: 0s - loss: 0.4973 - acc: 0.7385Epoch 00005: val_loss improved from 0.50630 to 0.50393, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4967 - acc: 0.7391 - val_loss: 0.5039 - val_acc: 0.7311\n",
      "Epoch 6/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4932 - acc: 0.7419Epoch 00006: val_loss improved from 0.50393 to 0.50174, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4938 - acc: 0.7413 - val_loss: 0.5017 - val_acc: 0.7329\n",
      "Epoch 7/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.7429Epoch 00007: val_loss improved from 0.50174 to 0.50050, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4914 - acc: 0.7430 - val_loss: 0.5005 - val_acc: 0.7346\n",
      "Epoch 8/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4894 - acc: 0.7446Epoch 00008: val_loss improved from 0.50050 to 0.49982, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4893 - acc: 0.7446 - val_loss: 0.4998 - val_acc: 0.7359\n",
      "Epoch 9/100\n",
      "120832/133334 [==========================>...] - ETA: 0s - loss: 0.4878 - acc: 0.7463Epoch 00009: val_loss improved from 0.49982 to 0.49872, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4877 - acc: 0.7464 - val_loss: 0.4987 - val_acc: 0.7354\n",
      "Epoch 10/100\n",
      "121856/133334 [==========================>...] - ETA: 0s - loss: 0.4866 - acc: 0.7467Epoch 00010: val_loss improved from 0.49872 to 0.49827, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4865 - acc: 0.7467 - val_loss: 0.4983 - val_acc: 0.7372\n",
      "Epoch 11/100\n",
      "120832/133334 [==========================>...] - ETA: 0s - loss: 0.4853 - acc: 0.7484Epoch 00011: val_loss improved from 0.49827 to 0.49730, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4851 - acc: 0.7485 - val_loss: 0.4973 - val_acc: 0.7370\n",
      "Epoch 12/100\n",
      "120832/133334 [==========================>...] - ETA: 0s - loss: 0.4844 - acc: 0.7489Epoch 00012: val_loss improved from 0.49730 to 0.49654, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4840 - acc: 0.7491 - val_loss: 0.4965 - val_acc: 0.7362\n",
      "Epoch 13/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4829 - acc: 0.7499Epoch 00013: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4830 - acc: 0.7498 - val_loss: 0.4977 - val_acc: 0.7364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "123904/133334 [==========================>...] - ETA: 0s - loss: 0.4821 - acc: 0.7497Epoch 00014: val_loss improved from 0.49654 to 0.49597, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4820 - acc: 0.7497 - val_loss: 0.4960 - val_acc: 0.7384\n",
      "Epoch 15/100\n",
      "120832/133334 [==========================>...] - ETA: 0s - loss: 0.4812 - acc: 0.7505Epoch 00015: val_loss improved from 0.49597 to 0.49559, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4813 - acc: 0.7503 - val_loss: 0.4956 - val_acc: 0.7381\n",
      "Epoch 16/100\n",
      "123904/133334 [==========================>...] - ETA: 0s - loss: 0.4808 - acc: 0.7516Epoch 00016: val_loss improved from 0.49559 to 0.49550, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4803 - acc: 0.7518 - val_loss: 0.4955 - val_acc: 0.7378\n",
      "Epoch 17/100\n",
      "122880/133334 [==========================>...] - ETA: 0s - loss: 0.4795 - acc: 0.7520Epoch 00017: val_loss improved from 0.49550 to 0.49483, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4794 - acc: 0.7522 - val_loss: 0.4948 - val_acc: 0.7381\n",
      "Epoch 18/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.7521Epoch 00018: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 7us/step - loss: 0.4790 - acc: 0.7522 - val_loss: 0.4950 - val_acc: 0.7374\n",
      "Epoch 19/100\n",
      "126976/133334 [===========================>..] - ETA: 0s - loss: 0.4780 - acc: 0.7531Epoch 00019: val_loss improved from 0.49483 to 0.49477, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4781 - acc: 0.7530 - val_loss: 0.4948 - val_acc: 0.7383\n",
      "Epoch 20/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.4771 - acc: 0.7537Epoch 00020: val_loss improved from 0.49477 to 0.49385, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4773 - acc: 0.7533 - val_loss: 0.4938 - val_acc: 0.7385\n",
      "Epoch 21/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.7535Epoch 00021: val_loss improved from 0.49385 to 0.49377, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4767 - acc: 0.7534 - val_loss: 0.4938 - val_acc: 0.7388\n",
      "Epoch 22/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.4761 - acc: 0.7542Epoch 00022: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4759 - acc: 0.7543 - val_loss: 0.4942 - val_acc: 0.7392\n",
      "Epoch 23/100\n",
      "122880/133334 [==========================>...] - ETA: 0s - loss: 0.4752 - acc: 0.7553Epoch 00023: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4752 - acc: 0.7549 - val_loss: 0.4949 - val_acc: 0.7383\n",
      "Epoch 24/100\n",
      "121856/133334 [==========================>...] - ETA: 0s - loss: 0.4737 - acc: 0.7556Epoch 00024: val_loss improved from 0.49377 to 0.49341, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4749 - acc: 0.7549 - val_loss: 0.4934 - val_acc: 0.7385\n",
      "Epoch 25/100\n",
      "122880/133334 [==========================>...] - ETA: 0s - loss: 0.4740 - acc: 0.7558Epoch 00025: val_loss improved from 0.49341 to 0.49298, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4742 - acc: 0.7559 - val_loss: 0.4930 - val_acc: 0.7393\n",
      "Epoch 26/100\n",
      "122880/133334 [==========================>...] - ETA: 0s - loss: 0.4728 - acc: 0.7562Epoch 00026: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4736 - acc: 0.7558 - val_loss: 0.4934 - val_acc: 0.7394\n",
      "Epoch 27/100\n",
      "122880/133334 [==========================>...] - ETA: 0s - loss: 0.4727 - acc: 0.7561Epoch 00027: val_loss improved from 0.49298 to 0.49263, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4730 - acc: 0.7558 - val_loss: 0.4926 - val_acc: 0.7407\n",
      "Epoch 28/100\n",
      "121856/133334 [==========================>...] - ETA: 0s - loss: 0.4734 - acc: 0.7556Epoch 00028: val_loss improved from 0.49263 to 0.49174, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 4us/step - loss: 0.4726 - acc: 0.7561 - val_loss: 0.4917 - val_acc: 0.7409\n",
      "Epoch 29/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.7561Epoch 00029: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4720 - acc: 0.7561 - val_loss: 0.4922 - val_acc: 0.7403\n",
      "Epoch 30/100\n",
      "123904/133334 [==========================>...] - ETA: 0s - loss: 0.4712 - acc: 0.7571Epoch 00030: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4715 - acc: 0.7567 - val_loss: 0.4932 - val_acc: 0.7401\n",
      "Epoch 31/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4713 - acc: 0.7573Epoch 00031: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4711 - acc: 0.7574 - val_loss: 0.4927 - val_acc: 0.7412\n",
      "Epoch 00031: early stopping\n",
      "66666/66666 [==============================] - 2s 28us/step\n",
      "Train on 133334 samples, validate on 66666 samples\n",
      "Epoch 1/100\n",
      "120832/133334 [==========================>...] - ETA: 0s - loss: 0.5650 - acc: 0.6880Epoch 00001: val_loss improved from inf to 0.53340, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 10us/step - loss: 0.5609 - acc: 0.6908 - val_loss: 0.5334 - val_acc: 0.7093\n",
      "Epoch 2/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.5115 - acc: 0.7275Epoch 00002: val_loss improved from 0.53340 to 0.52117, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.5111 - acc: 0.7279 - val_loss: 0.5212 - val_acc: 0.7195\n",
      "Epoch 3/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.5027 - acc: 0.7342Epoch 00003: val_loss improved from 0.52117 to 0.51626, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.5022 - acc: 0.7343 - val_loss: 0.5163 - val_acc: 0.7234\n",
      "Epoch 4/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.4974 - acc: 0.7378Epoch 00004: val_loss improved from 0.51626 to 0.51243, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4971 - acc: 0.7386 - val_loss: 0.5124 - val_acc: 0.7304\n",
      "Epoch 5/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4936 - acc: 0.7416Epoch 00005: val_loss improved from 0.51243 to 0.50993, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4935 - acc: 0.7416 - val_loss: 0.5099 - val_acc: 0.7315\n",
      "Epoch 6/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4903 - acc: 0.7440Epoch 00006: val_loss improved from 0.50993 to 0.50812, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4903 - acc: 0.7438 - val_loss: 0.5081 - val_acc: 0.7330\n",
      "Epoch 7/100\n",
      "124928/133334 [===========================>..] - ETA: 0s - loss: 0.4882 - acc: 0.7449Epoch 00007: val_loss improved from 0.50812 to 0.50616, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4878 - acc: 0.7452 - val_loss: 0.5062 - val_acc: 0.7349\n",
      "Epoch 8/100\n",
      "130048/133334 [============================>.] - ETA: 0s - loss: 0.4859 - acc: 0.7470Epoch 00008: val_loss improved from 0.50616 to 0.50522, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4858 - acc: 0.7472 - val_loss: 0.5052 - val_acc: 0.7357\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124928/133334 [===========================>..] - ETA: 0s - loss: 0.4841 - acc: 0.7478Epoch 00009: val_loss improved from 0.50522 to 0.50458, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4838 - acc: 0.7482 - val_loss: 0.5046 - val_acc: 0.7367\n",
      "Epoch 10/100\n",
      "123904/133334 [==========================>...] - ETA: 0s - loss: 0.4828 - acc: 0.7484Epoch 00010: val_loss improved from 0.50458 to 0.50363, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4823 - acc: 0.7489 - val_loss: 0.5036 - val_acc: 0.7364\n",
      "Epoch 11/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4810 - acc: 0.7504Epoch 00011: val_loss improved from 0.50363 to 0.50205, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4812 - acc: 0.7504 - val_loss: 0.5021 - val_acc: 0.7380\n",
      "Epoch 12/100\n",
      "133120/133334 [============================>.] - ETA: 0s - loss: 0.4799 - acc: 0.7513Epoch 00012: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4799 - acc: 0.7513 - val_loss: 0.5026 - val_acc: 0.7382\n",
      "Epoch 13/100\n",
      "122880/133334 [==========================>...] - ETA: 0s - loss: 0.4784 - acc: 0.7521Epoch 00013: val_loss improved from 0.50205 to 0.50176, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4789 - acc: 0.7520 - val_loss: 0.5018 - val_acc: 0.7378\n",
      "Epoch 14/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4781 - acc: 0.7528Epoch 00014: val_loss improved from 0.50176 to 0.50060, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4781 - acc: 0.7530 - val_loss: 0.5006 - val_acc: 0.7386\n",
      "Epoch 15/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.7537Epoch 00015: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4770 - acc: 0.7536 - val_loss: 0.5008 - val_acc: 0.7393\n",
      "Epoch 16/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.7535Epoch 00016: val_loss improved from 0.50060 to 0.50051, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4763 - acc: 0.7539 - val_loss: 0.5005 - val_acc: 0.7381\n",
      "Epoch 17/100\n",
      "122880/133334 [==========================>...] - ETA: 0s - loss: 0.4756 - acc: 0.7539Epoch 00017: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4753 - acc: 0.7545 - val_loss: 0.5006 - val_acc: 0.7388\n",
      "Epoch 18/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.4751 - acc: 0.7550Epoch 00018: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4748 - acc: 0.7550 - val_loss: 0.5005 - val_acc: 0.7395\n",
      "Epoch 19/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4738 - acc: 0.7545Epoch 00019: val_loss improved from 0.50051 to 0.49987, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4738 - acc: 0.7545 - val_loss: 0.4999 - val_acc: 0.7389\n",
      "Epoch 20/100\n",
      "132096/133334 [============================>.] - ETA: 0s - loss: 0.4731 - acc: 0.7557Epoch 00020: val_loss improved from 0.49987 to 0.49884, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4731 - acc: 0.7557 - val_loss: 0.4988 - val_acc: 0.7397\n",
      "Epoch 21/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4726 - acc: 0.7564Epoch 00021: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4727 - acc: 0.7564 - val_loss: 0.4990 - val_acc: 0.7405\n",
      "Epoch 22/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.4723 - acc: 0.7565Epoch 00022: val_loss improved from 0.49884 to 0.49841, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4721 - acc: 0.7569 - val_loss: 0.4984 - val_acc: 0.7404\n",
      "Epoch 23/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4712 - acc: 0.7578Epoch 00023: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4715 - acc: 0.7575 - val_loss: 0.4986 - val_acc: 0.7388\n",
      "Epoch 24/100\n",
      "124928/133334 [===========================>..] - ETA: 0s - loss: 0.4707 - acc: 0.7573Epoch 00024: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 6us/step - loss: 0.4708 - acc: 0.7574 - val_loss: 0.4986 - val_acc: 0.7392\n",
      "Epoch 25/100\n",
      "131072/133334 [============================>.] - ETA: 0s - loss: 0.4705 - acc: 0.7583Epoch 00025: val_loss improved from 0.49841 to 0.49829, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4704 - acc: 0.7584 - val_loss: 0.4983 - val_acc: 0.7400\n",
      "Epoch 26/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.4692 - acc: 0.7584Epoch 00026: val_loss improved from 0.49829 to 0.49808, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4698 - acc: 0.7586 - val_loss: 0.4981 - val_acc: 0.7406\n",
      "Epoch 27/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.4697 - acc: 0.7590Epoch 00027: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4695 - acc: 0.7589 - val_loss: 0.4983 - val_acc: 0.7393\n",
      "Epoch 28/100\n",
      "124928/133334 [===========================>..] - ETA: 0s - loss: 0.4690 - acc: 0.7589Epoch 00028: val_loss improved from 0.49808 to 0.49765, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4691 - acc: 0.7586 - val_loss: 0.4976 - val_acc: 0.7402\n",
      "Epoch 29/100\n",
      "125952/133334 [===========================>..] - ETA: 0s - loss: 0.4682 - acc: 0.7592Epoch 00029: val_loss improved from 0.49765 to 0.49709, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4683 - acc: 0.7590 - val_loss: 0.4971 - val_acc: 0.7410\n",
      "Epoch 30/100\n",
      "126976/133334 [===========================>..] - ETA: 0s - loss: 0.4682 - acc: 0.7594Epoch 00030: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4680 - acc: 0.7597 - val_loss: 0.4971 - val_acc: 0.7410\n",
      "Epoch 31/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.7596Epoch 00031: val_loss improved from 0.49709 to 0.49643, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4675 - acc: 0.7595 - val_loss: 0.4964 - val_acc: 0.7414\n",
      "Epoch 32/100\n",
      "129024/133334 [============================>.] - ETA: 0s - loss: 0.4672 - acc: 0.7598Epoch 00032: val_loss improved from 0.49643 to 0.49625, saving model to best_neural_model_save.hdf5\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4671 - acc: 0.7601 - val_loss: 0.4962 - val_acc: 0.7412\n",
      "Epoch 33/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4669 - acc: 0.7601Epoch 00033: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4667 - acc: 0.7602 - val_loss: 0.4966 - val_acc: 0.7412\n",
      "Epoch 34/100\n",
      "126976/133334 [===========================>..] - ETA: 0s - loss: 0.4661 - acc: 0.7613Epoch 00034: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4662 - acc: 0.7611 - val_loss: 0.4964 - val_acc: 0.7398\n",
      "Epoch 35/100\n",
      "128000/133334 [===========================>..] - ETA: 0s - loss: 0.4660 - acc: 0.7598Epoch 00035: val_loss did not improve\n",
      "133334/133334 [==============================] - 1s 5us/step - loss: 0.4658 - acc: 0.7599 - val_loss: 0.4966 - val_acc: 0.7411\n",
      "Epoch 00035: early stopping\n",
      "66666/66666 [==============================] - 2s 35us/step\n",
      "Model:  basic_model_adam\n",
      "0.75% (+/- 0.01%)\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "stds=[]\n",
    "\n",
    "for corpus in corpuses: \n",
    "    model_score=GV.classify_with_neural_networks(neural_nets, global_vectors, corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "    accuracies.append(model_score[0][0])\n",
    "    stds.append(model_score[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0062775931606721784]\n"
     ]
    }
   ],
   "source": [
    "print(stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to determine which preprocessing techniques that improved the accuracy, and keep them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpuses_1=[]\n",
    "names_1=[]\n",
    "stds_1=[]\n",
    "acc_1=[]\n",
    "print('The original corpus gave accuracy of: ',accuracies[0], 'std:', stds[0],'\\n')\n",
    "for i in range(1,len(accuracies)):\n",
    "    if accuracies[i]>=accuracies[0]:\n",
    "        corpuses_1.append(corpuses[i])\n",
    "        names_1.append(names[i])\n",
    "        stds_1.append(stds[i])\n",
    "        acc_1.append(accuracies[i])\n",
    "        print('IMPROVED:  ',names[i],', score:',accuracies[i],'std:',stds[i])\n",
    "    else:\n",
    "        print('Not better:',names[i],', score:',accuracies[i],'std:',stds[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We do not keep SH, as SHM is better. \n",
    "# We do not keep N as NM is better \n",
    "# We do not keep SP due to time  (158.26 min)\n",
    "# We do not keep techniques that imporved less than 0.05 percentage points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply all techniques that contributed positively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_={'hashtag': True, 'segmentation_hash': True, 'hashtag_mention':True,\n",
    "        'hearts':True,'hugs_and_kisses':True,'elongation':True, 'set_to_not':True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applying the techniques that we have decided to keep:\n",
    "best_prepr_corpus=TO.preprocess_corpus(full_corpus, **input_)\n",
    "best_corpus=HL.creating_n_grams_corpus(2,best_prepr_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross validating:\n",
    "model_score=GV.classify_with_neural_networks(neural_nets, global_vectors, corpus, \n",
    "                                             total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy:',  model_score[0][0], 'std:',model_score[0][1],'\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mindfs= [0,2,3,5,10,20, 40, 60,100,140,200]\n",
    "maxdfs=[0.8] \n",
    "accuracies_stop=[]\n",
    "stds_stop=[]\n",
    "stop_lens=[]\n",
    "vocabs=[]\n",
    "\n",
    "\n",
    "for max_ in maxdfs:\n",
    "    for min_ in mindfs: \n",
    "        stopwords, vocab= TO.get_dynamic_stopwords(best_corpus, MinDf=min_, MaxDf=max_)\n",
    "        stopword_corpus=TO.remove_stopwords(best_corpus, stopwords)\n",
    "        model_score=GV.classify_with_neural_networks(neural_nets, global_vectors, stopword_corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "        accuracies_stop.append(model_score[0][0])\n",
    "        stds_stop.append(model_score[0][1])\n",
    "        stop_lens.append(len(stopwords))\n",
    "        vocabs.append(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(stop_lens)):\n",
    "    print('min', mindfs[i], 'accuracy', accuracies_stop[i],'std',stds_stop[i],  '\\n')\n",
    "for i in range(len(stop_lens)):\n",
    "    print('number of stop words', stop_lens[i], 'lenght of vocabolary', len(vocabs[i]),'sum for checking',stop_lens[i]+len(vocabs[i]),  '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the best combination with the simple and the complex neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords, vocab= TO.get_dynamic_stopwords(best_corpus, MinDf=5, MaxDf=0.8)\n",
    "final_corpus= TO.remove_stopwords(best_corpus, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_score=GV.classify_with_neural_networks(NN.basic_model_adam, global_vectors, final_corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "\n",
    "print('Applying the best combination of preprocessing, using pre-trained global vectors with 200 dimensions, an cros-validatino accuracy of', model_score[0][0],'+-',model_score[0][1], 'was achieved using the simple neural net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_score=GV.classify_with_neural_networks(NN.complex_model, global_vectors, final_corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=3)\n",
    "\n",
    "print('Applying the best combination of preprocessing, using pre-trained global vectors with 200 dimensions, an cros-validatino accuracy of', model_score[0][0],'+-',model_score[0][1], 'was achieved using the compelx neural net')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
