{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating files for submission to Kaggle  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import pickle\n",
    "# internal imports\n",
    "import helpers as HL\n",
    "import glove_module as GV\n",
    "import neural_nets as NN\n",
    "import pickle\n",
    "\n",
    "#FOR THOMAS\n",
    "#import tokenizing as TO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_corpus, nr_pos_tweets, nr_neg_tweets, total_training_tweets = HL.get_corpus(full=False, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word embeddings using the created gensim-.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pick one, the higher dimension, the better result and longer computational time. \n",
    "global_vectors=HL.get_global_vectors(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing unprepocessed full dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3ce0d80c47d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkaggle_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"keggle_glove_unprepro_simple.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mGV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_model_adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_training_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_pos_tweets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkaggle_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/HeddaVik/EPFL Machine learning/CD-433-Project-2/glove_module.py\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(neural_net, global_vectors, full_corpus, total_training_tweets, nr_pos_tweets, kaggle_name, epochs, patience, split)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Defining callbacks to be used under fitting process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearly_stopping_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_neural_model_prediction_model.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     history = model.fit(\n",
      "\u001b[0;32m/Users/HeddaVik/EPFL Machine learning/CD-433-Project-2/glove_module.py\u001b[0m in \u001b[0;36mearly_stopping_callback\u001b[0;34m(patience_, verbose_)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneural_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_training_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_pos_tweets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkaggle_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \"\"\" Creates a csv file with kaggle predictions and returns the predictions.\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "kaggle_name=\"keggle_glove_unprepro_simple.csv\"\n",
    "pred= GV.get_prediction(NN.basic_model_adam, global_vectors, full_corpus, total_training_tweets, nr_pos_tweets,kaggle_name, patience=3, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing best preprocessing with full dataset: \n",
    "## Applying the preorocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Create on your own:\n",
    "\n",
    "input_=[{'hashtag': True, 'segmentation_hash': True, 'hashtag_mention':True,\n",
    "        'hearts':True,'hugs_and_kisses':True,'elongation':True, 'set_to_not':True}]\n",
    "final_corpus=TO.preprocess_corpus(full_corpus, input_)\n",
    "final_corpus_ngram=HL.creating_n_grams_corpus(2,final_corpus)\n",
    "stopwords=TO.get_dynamic_stopwords(best_corpus, MinDf=100, MaxDf=0.8)\n",
    "final_corpus_ngram_stopwords=TO.remove_stopwords(final_corpus_ngram, stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Upload from pickle\n",
    "final_corpus_ngram_stopwords=pickle.load( open( \"stopword100_corpus_n2_SHM_E_SN_H_HK.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making kaggle submission using simple neural net: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_corpus_ngram_stopwords=pickle.load(open(\"stopword100_corpus_n2_SHM_E_SN_H_HK.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000000 samples, validate on 500000 samples\n",
      "Epoch 1/100\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8215Epoch 00001: val_loss improved from inf to 0.36676, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 30s 15us/step - loss: 0.3813 - acc: 0.8215 - val_loss: 0.3668 - val_acc: 0.8302\n",
      "Epoch 2/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3594 - acc: 0.8342Epoch 00002: val_loss improved from 0.36676 to 0.35837, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 25s 12us/step - loss: 0.3594 - acc: 0.8342 - val_loss: 0.3584 - val_acc: 0.8347\n",
      "Epoch 3/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3536 - acc: 0.8375Epoch 00003: val_loss improved from 0.35837 to 0.35587, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 23s 12us/step - loss: 0.3536 - acc: 0.8375 - val_loss: 0.3559 - val_acc: 0.8364\n",
      "Epoch 4/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3502 - acc: 0.8394Epoch 00004: val_loss improved from 0.35587 to 0.35253, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 24s 12us/step - loss: 0.3502 - acc: 0.8395 - val_loss: 0.3525 - val_acc: 0.8387\n",
      "Epoch 5/100\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3477 - acc: 0.8406Epoch 00005: val_loss improved from 0.35253 to 0.35089, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 24s 12us/step - loss: 0.3477 - acc: 0.8406 - val_loss: 0.3509 - val_acc: 0.8390\n",
      "Epoch 6/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3461 - acc: 0.8414Epoch 00006: val_loss improved from 0.35089 to 0.35046, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 24s 12us/step - loss: 0.3461 - acc: 0.8414 - val_loss: 0.3505 - val_acc: 0.8397\n",
      "Epoch 7/100\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3449 - acc: 0.8421Epoch 00007: val_loss improved from 0.35046 to 0.34991, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 24s 12us/step - loss: 0.3449 - acc: 0.8421 - val_loss: 0.3499 - val_acc: 0.8399\n",
      "Epoch 8/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3437 - acc: 0.8428Epoch 00008: val_loss improved from 0.34991 to 0.34977, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 24s 12us/step - loss: 0.3437 - acc: 0.8428 - val_loss: 0.3498 - val_acc: 0.8399\n",
      "Epoch 9/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3426 - acc: 0.8434Epoch 00009: val_loss improved from 0.34977 to 0.34839, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 21s 10us/step - loss: 0.3427 - acc: 0.8433 - val_loss: 0.3484 - val_acc: 0.8408\n",
      "Epoch 10/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3420 - acc: 0.8438Epoch 00010: val_loss improved from 0.34839 to 0.34839, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 17s 8us/step - loss: 0.3419 - acc: 0.8438 - val_loss: 0.3484 - val_acc: 0.8405\n",
      "Epoch 11/100\n",
      "1993728/2000000 [============================>.] - ETA: 0s - loss: 0.3412 - acc: 0.8441Epoch 00011: val_loss improved from 0.34839 to 0.34759, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 16s 8us/step - loss: 0.3412 - acc: 0.8441 - val_loss: 0.3476 - val_acc: 0.8413\n",
      "Epoch 12/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8446Epoch 00012: val_loss improved from 0.34759 to 0.34740, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 16s 8us/step - loss: 0.3406 - acc: 0.8446 - val_loss: 0.3474 - val_acc: 0.8412\n",
      "Epoch 13/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3400 - acc: 0.8449Epoch 00013: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 17s 9us/step - loss: 0.3400 - acc: 0.8449 - val_loss: 0.3487 - val_acc: 0.8411\n",
      "Epoch 14/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3394 - acc: 0.8451Epoch 00014: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 22s 11us/step - loss: 0.3394 - acc: 0.8451 - val_loss: 0.3475 - val_acc: 0.8410\n",
      "Epoch 15/100\n",
      "1992704/2000000 [============================>.] - ETA: 0s - loss: 0.3390 - acc: 0.8454Epoch 00015: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 15s 7us/step - loss: 0.3389 - acc: 0.8454 - val_loss: 0.3475 - val_acc: 0.8414\n",
      "Epoch 16/100\n",
      "1993728/2000000 [============================>.] - ETA: 0s - loss: 0.3385 - acc: 0.8457Epoch 00016: val_loss improved from 0.34740 to 0.34686, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 15s 7us/step - loss: 0.3385 - acc: 0.8457 - val_loss: 0.3469 - val_acc: 0.8412\n",
      "Epoch 17/100\n",
      "1993728/2000000 [============================>.] - ETA: 0s - loss: 0.3382 - acc: 0.8457Epoch 00017: val_loss improved from 0.34686 to 0.34649, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 15s 7us/step - loss: 0.3382 - acc: 0.8457 - val_loss: 0.3465 - val_acc: 0.8416\n",
      "Epoch 18/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.8460Epoch 00018: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 15s 8us/step - loss: 0.3377 - acc: 0.8461 - val_loss: 0.3469 - val_acc: 0.8416\n",
      "Epoch 19/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.8462Epoch 00019: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 24s 12us/step - loss: 0.3373 - acc: 0.8462 - val_loss: 0.3469 - val_acc: 0.8415\n",
      "Epoch 20/100\n",
      "1994752/2000000 [============================>.] - ETA: 0s - loss: 0.3370 - acc: 0.8463Epoch 00020: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 16s 8us/step - loss: 0.3370 - acc: 0.8463 - val_loss: 0.3468 - val_acc: 0.8419\n",
      "Epoch 21/100\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3367 - acc: 0.8465Epoch 00021: val_loss improved from 0.34649 to 0.34611, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 15s 7us/step - loss: 0.3367 - acc: 0.8465 - val_loss: 0.3461 - val_acc: 0.8420\n",
      "Epoch 22/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3364 - acc: 0.8467Epoch 00022: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 25s 12us/step - loss: 0.3364 - acc: 0.8468 - val_loss: 0.3481 - val_acc: 0.8408\n",
      "Epoch 23/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3362 - acc: 0.8468Epoch 00023: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 22s 11us/step - loss: 0.3362 - acc: 0.8468 - val_loss: 0.3464 - val_acc: 0.8415\n",
      "Epoch 24/100\n",
      "1993728/2000000 [============================>.] - ETA: 0s - loss: 0.3360 - acc: 0.8469Epoch 00024: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 20s 10us/step - loss: 0.3359 - acc: 0.8469 - val_loss: 0.3467 - val_acc: 0.8417\n",
      "Epoch 25/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3357 - acc: 0.8471Epoch 00025: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 19s 9us/step - loss: 0.3357 - acc: 0.8471 - val_loss: 0.3468 - val_acc: 0.8415\n",
      "Epoch 26/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3355 - acc: 0.8470Epoch 00026: val_loss improved from 0.34611 to 0.34593, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 22s 11us/step - loss: 0.3355 - acc: 0.8470 - val_loss: 0.3459 - val_acc: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3353 - acc: 0.8473Epoch 00027: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 21s 10us/step - loss: 0.3353 - acc: 0.8473 - val_loss: 0.3460 - val_acc: 0.8422\n",
      "Epoch 28/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3350 - acc: 0.8475Epoch 00028: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 22s 11us/step - loss: 0.3350 - acc: 0.8475 - val_loss: 0.3460 - val_acc: 0.8418\n",
      "Epoch 29/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3349 - acc: 0.8476Epoch 00029: val_loss improved from 0.34593 to 0.34568, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 17s 9us/step - loss: 0.3349 - acc: 0.8476 - val_loss: 0.3457 - val_acc: 0.8423\n",
      "Epoch 30/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3347 - acc: 0.8476Epoch 00030: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 16s 8us/step - loss: 0.3347 - acc: 0.8476 - val_loss: 0.3465 - val_acc: 0.8417\n",
      "Epoch 31/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.8479Epoch 00031: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 20s 10us/step - loss: 0.3344 - acc: 0.8479 - val_loss: 0.3458 - val_acc: 0.8421\n",
      "Epoch 32/100\n",
      "1994752/2000000 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.8478Epoch 00032: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 18s 9us/step - loss: 0.3343 - acc: 0.8478 - val_loss: 0.3459 - val_acc: 0.8419\n",
      "Epoch 33/100\n",
      "1993728/2000000 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.8479Epoch 00033: val_loss improved from 0.34568 to 0.34557, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 17s 9us/step - loss: 0.3342 - acc: 0.8479 - val_loss: 0.3456 - val_acc: 0.8422\n",
      "Epoch 34/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.8479Epoch 00034: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 18s 9us/step - loss: 0.3341 - acc: 0.8479 - val_loss: 0.3458 - val_acc: 0.8423\n",
      "Epoch 35/100\n",
      "1994752/2000000 [============================>.] - ETA: 0s - loss: 0.3339 - acc: 0.8481Epoch 00035: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 16s 8us/step - loss: 0.3339 - acc: 0.8481 - val_loss: 0.3460 - val_acc: 0.8418\n",
      "Epoch 36/100\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3337 - acc: 0.8481Epoch 00036: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 20s 10us/step - loss: 0.3337 - acc: 0.8481 - val_loss: 0.3464 - val_acc: 0.8421\n",
      "Epoch 37/100\n",
      "1994752/2000000 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.8483Epoch 00037: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 18s 9us/step - loss: 0.3335 - acc: 0.8483 - val_loss: 0.3460 - val_acc: 0.8423\n",
      "Epoch 38/100\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.8481Epoch 00038: val_loss improved from 0.34557 to 0.34521, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 17s 9us/step - loss: 0.3335 - acc: 0.8481 - val_loss: 0.3452 - val_acc: 0.8424\n",
      "Epoch 39/100\n",
      "1994752/2000000 [============================>.] - ETA: 0s - loss: 0.3333 - acc: 0.8482Epoch 00039: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 20s 10us/step - loss: 0.3333 - acc: 0.8482 - val_loss: 0.3466 - val_acc: 0.8414\n",
      "Epoch 40/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3332 - acc: 0.8485Epoch 00040: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 18s 9us/step - loss: 0.3332 - acc: 0.8485 - val_loss: 0.3453 - val_acc: 0.8419\n",
      "Epoch 41/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3331 - acc: 0.8484Epoch 00041: val_loss improved from 0.34521 to 0.34466, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 19s 9us/step - loss: 0.3331 - acc: 0.8484 - val_loss: 0.3447 - val_acc: 0.8425\n",
      "Epoch 42/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8485Epoch 00042: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 19s 10us/step - loss: 0.3330 - acc: 0.8485 - val_loss: 0.3450 - val_acc: 0.8427\n",
      "Epoch 43/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8486Epoch 00043: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 18s 9us/step - loss: 0.3329 - acc: 0.8486 - val_loss: 0.3459 - val_acc: 0.8421\n",
      "Epoch 44/100\n",
      "1991680/2000000 [============================>.] - ETA: 0s - loss: 0.3327 - acc: 0.8485Epoch 00044: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 17s 8us/step - loss: 0.3327 - acc: 0.8485 - val_loss: 0.3449 - val_acc: 0.8426\n",
      "Epoch 45/100\n",
      "1993728/2000000 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.8487Epoch 00045: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 16s 8us/step - loss: 0.3326 - acc: 0.8487 - val_loss: 0.3454 - val_acc: 0.8424\n",
      "Epoch 46/100\n",
      "1992704/2000000 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.8487Epoch 00046: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 16s 8us/step - loss: 0.3326 - acc: 0.8487 - val_loss: 0.3451 - val_acc: 0.8423\n",
      "Epoch 47/100\n",
      "1997824/2000000 [============================>.] - ETA: 0s - loss: 0.3324 - acc: 0.8487Epoch 00047: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 16s 8us/step - loss: 0.3325 - acc: 0.8487 - val_loss: 0.3452 - val_acc: 0.8426\n",
      "Epoch 48/100\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3323 - acc: 0.8489Epoch 00048: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 18s 9us/step - loss: 0.3323 - acc: 0.8489 - val_loss: 0.3452 - val_acc: 0.8423\n",
      "Epoch 49/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3323 - acc: 0.8488Epoch 00049: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 17s 9us/step - loss: 0.3323 - acc: 0.8488 - val_loss: 0.3455 - val_acc: 0.8425\n",
      "Epoch 50/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8490Epoch 00050: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 18s 9us/step - loss: 0.3321 - acc: 0.8490 - val_loss: 0.3448 - val_acc: 0.8427\n",
      "Epoch 51/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8489Epoch 00051: val_loss improved from 0.34466 to 0.34426, saving model to best_neural_model_prediction_model.hdf5\n",
      "2000000/2000000 [==============================] - 17s 9us/step - loss: 0.3321 - acc: 0.8489 - val_loss: 0.3443 - val_acc: 0.8432\n",
      "Epoch 52/100\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3319 - acc: 0.8491Epoch 00052: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 15s 8us/step - loss: 0.3319 - acc: 0.8491 - val_loss: 0.3456 - val_acc: 0.8425\n",
      "Epoch 53/100\n",
      "1992704/2000000 [============================>.] - ETA: 0s - loss: 0.3319 - acc: 0.8491Epoch 00053: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 17s 8us/step - loss: 0.3319 - acc: 0.8491 - val_loss: 0.3445 - val_acc: 0.8426\n",
      "Epoch 54/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3318 - acc: 0.8492Epoch 00054: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 24s 12us/step - loss: 0.3318 - acc: 0.8492 - val_loss: 0.3461 - val_acc: 0.8419\n",
      "Epoch 55/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3318 - acc: 0.8490Epoch 00055: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 22s 11us/step - loss: 0.3318 - acc: 0.8490 - val_loss: 0.3448 - val_acc: 0.8424\n",
      "Epoch 56/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3317 - acc: 0.8492Epoch 00056: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 20s 10us/step - loss: 0.3316 - acc: 0.8492 - val_loss: 0.3444 - val_acc: 0.8430\n",
      "Epoch 57/100\n",
      "1995776/2000000 [============================>.] - ETA: 0s - loss: 0.3317 - acc: 0.8492Epoch 00057: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 20s 10us/step - loss: 0.3316 - acc: 0.8492 - val_loss: 0.3450 - val_acc: 0.8425\n",
      "Epoch 58/100\n",
      "1998848/2000000 [============================>.] - ETA: 0s - loss: 0.3315 - acc: 0.8492Epoch 00058: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 20s 10us/step - loss: 0.3315 - acc: 0.8492 - val_loss: 0.3458 - val_acc: 0.8418\n",
      "Epoch 59/100\n",
      "1992704/2000000 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8493Epoch 00059: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 23s 11us/step - loss: 0.3314 - acc: 0.8493 - val_loss: 0.3453 - val_acc: 0.8424\n",
      "Epoch 60/100\n",
      "1999872/2000000 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8493Epoch 00060: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 19s 9us/step - loss: 0.3314 - acc: 0.8493 - val_loss: 0.3444 - val_acc: 0.8430\n",
      "Epoch 61/100\n",
      "1996800/2000000 [============================>.] - ETA: 0s - loss: 0.3313 - acc: 0.8493Epoch 00061: val_loss did not improve\n",
      "2000000/2000000 [==============================] - 19s 9us/step - loss: 0.3313 - acc: 0.8493 - val_loss: 0.3448 - val_acc: 0.8425\n"
     ]
    }
   ],
   "source": [
    "kaggle_name=\"keggle_glove_best_simple.csv\"\n",
    "pred= GV.get_prediction(NN.basic_model_adam, global_vectors, final_corpus_ngram_stopwords, total_training_tweets, nr_pos_tweets,kaggle_name, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making kaggle submission using complex neural net: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_name=\"keggle_glove_best_complex.csv\"\n",
    "#final_corpus=n_grams_corpus\n",
    "pred= GV.get_prediction(NN.complex_model, global_vectors, final_corpus_ngram_stopwords, total_training_tweets, nr_pos_tweets,kaggle_name, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
