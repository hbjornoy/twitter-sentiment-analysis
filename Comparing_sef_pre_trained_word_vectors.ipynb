{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Self- and Pre-trained Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# external imports\n",
    "import numpy as np\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "import glove_solution as GS\n",
    "import glove_module as GV\n",
    "import helpers as HL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and creating corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_pos = \"train_pos.txt\" \n",
    "training_set_neg = \"train_neg.txt\"\n",
    "training_set_pos_full = \"train_pos_full.txt\"\n",
    "training_set_neg_full = \"train_neg_full.txt\"\n",
    "test_set = \"test_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When testing\n",
    "inputfiles=[training_set_pos,training_set_neg,test_set]\n",
    "\n",
    "#when using full data set:\n",
    "#inputfiles=[training_set_pos_full,training_set_neg_full,test_set]\n",
    "\n",
    "full_corpus, file_lengths=HL.create_corpus(inputfiles)\n",
    "nr_pos_tweets = file_lengths[0]\n",
    "nr_neg_tweets = file_lengths[1]\n",
    "total_training_tweets =file_lengths [0]+file_lengths[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural net used to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural_nets=[MODEL!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating global vectors from the co-occurence matrix \n",
    "Only have to be done once. Assumes that the cooc_full.pkl file is created and availiable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GS.glove('cooc_full.pkl',100, 'embeddings_full50')\n",
    "GS.glove('cooc_full.pkl',100, 'embeddings_full100')\n",
    "GS.glove('cooc_full.pkl',100, 'embeddings_full200')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datafiles of the embeddings: \n",
    "Only have to be done once, assumes that the embedding files and vocab_full.pkl file are availiable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MT.make_file('embeddings_full50.npy','vocab_full.pkl', 'global_vectors_full_unprepro50.txt')\n",
    "MT.make_file('embeddings_full100.npy','vocab_full.pkl', 'global_vectors_full_unprepro100.txt')\n",
    "MT.make_file('embeddings_full200.npy','vocab_full.pkl', 'global_vectors_full_unprepro200.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make global vectors of all embeddings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_vectors_pre_50=GV.make_glove(\"gensim_global_vectors_50dim.txt\")\n",
    "global_vectors_pre_100=GV.make_glove(\"gensim_global_vectors_100dim.txt\")\n",
    "global_vectors_pre_200=GV.make_glove(\"gensim_global_vectors_200dim.txt\")\n",
    "\n",
    "global_vectors_self_50=GV.make_glove('global_vectors_full_unprepro50.txt)\n",
    "global_vectors_self_100=GV.make_glove('global_vectors_full_unprepro100.txt)\n",
    "global_vectors_self_200=GV.make_glove('global_vectors_full_unprepro200.txt)\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_vectors=[global_vectors_pre_50,global_vectors_pre_100,global_vectors_pre_200,global_vectors_self_50, global_vectors_self_100, global_vectors_self_200 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names=['pre50','pre100','pre200','self50','self100','self200']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do cross validation using all global vectors, to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stds=[]\n",
    "accs=[]\n",
    "\n",
    "for global_vector in global_vectors: \n",
    "    model_score=GV.classify_with_neural_networks(neural_nets, global_vector, full_corpus, total_training_tweets, nr_pos_tweets, epochs=5, n_folds=3)\n",
    "    accs.append(model_score[0][0])\n",
    "    stds.append(model_score[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in rang(len(accs)):\n",
    "    print('Global vectors: ', names(i), 'Accuracy: ', accs[i], '+- :', stds[i],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
