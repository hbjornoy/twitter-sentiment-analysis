{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Self- and Pre-trained Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# external imports\n",
    "import numpy as np\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "import glove_solution as GS\n",
    "import glove_module as GV\n",
    "import helpers as HL\n",
    "import neural_nets as NN\n",
    "import maketextfile as MT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_corpus, nr_pos_tweets, nr_neg_tweets, total_training_tweets=HL.get_corpus(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural net used to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural_nets=[NN.basic_model_adam]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating global vectors from the co-occurence matrix \n",
    "Only have to be done once. Assumes that the cooc_full.pkl file is created and availiable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS.glove('cooc_full.pkl',50, 'embeddings_full50')\n",
    "GS.glove('cooc_full.pkl',100, 'embeddings_full100')\n",
    "GS.glove('cooc_full.pkl',200, 'embeddings_full200')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datafiles of the embeddings: \n",
    "Only have to be done once, assumes that the embedding files and vocab_full.pkl file are availiable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MT.make_file('embeddings_full50.npy','vocab_full.pkl', 'global_vectors_full_unprepro50.txt')\n",
    "MT.make_file('embeddings_full100.npy','vocab_full.pkl', 'global_vectors_full_unprepro100.txt')\n",
    "MT.make_file('embeddings_full200.npy','vocab_full.pkl', 'global_vectors_full_unprepro200.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make global vectors of all embeddings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_vectors_pre_50=GV.make_glove(\"gensim_global_vectors_50dim.txt\")\n",
    "global_vectors_pre_100=GV.make_glove(\"gensim_global_vectors_100dim.txt\")\n",
    "global_vectors_pre_200=GV.make_glove(\"gensim_global_vectors_200dim.txt\")\n",
    "\n",
    "global_vectors_self_50=GV.make_glove('global_vectors_full_unprepro50.txt')\n",
    "global_vectors_self_100=GV.make_glove('global_vectors_full_unprepro100.txt')\n",
    "global_vectors_self_200=GV.make_glove('global_vectors_full_unprepro200.txt')\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "global_vectors=[global_vectors_pre_50,global_vectors_pre_100,global_vectors_pre_200,global_vectors_self_50, global_vectors_self_100, global_vectors_self_200 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names=['pre50','pre100','pre200','self50','self100','self200']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do cross validation using all global vectors, to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds=[]\n",
    "accs=[]\n",
    "\n",
    "for global_vector in global_vectors: \n",
    "    model_score=GV.classify_with_neural_networks(neural_nets, global_vector, full_corpus, total_training_tweets, nr_pos_tweets, epochs=100, n_folds=5)\n",
    "    accs.append(model_score[0][0])\n",
    "    stds.append(model_score[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(accs)):\n",
    "    print('Global vectors: ', names[i], 'Accuracy: ', accs[i], '+- :', stds[i],'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
